{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FG2511/ARE/blob/master/model1%2BTN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hu-_5aP7LlL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "d7e265c0-40b0-449f-e280-c72a2524bfb9"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@File name: model1.ipynb\n",
        "@Created on 2018-12-20\n",
        "@Authors: Federica Gerina, Francesca Moi, Silvia Maria Massa\n",
        "@Description: Given a time-series dataset that contains minute-by-minute data \n",
        "about different kind of gases, collected by the uHoo air quality sensor, train\n",
        "a NN that classifies if a minute belongs to the class \"Pasto\" (1) otherwise to\n",
        "the class \"Other\" (0).\n",
        "'''\n",
        "\n",
        "!pip install liac-arff\n",
        "\n",
        "import arff\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import compute_class_weight\n",
        "\n",
        "import sys\n",
        "sys.path.append('local_modules')\n",
        "\n",
        "import mlp\n",
        "import postprocessing_sw\n",
        "import cooking_inst_mod\n",
        "import utils\n",
        "\n",
        "#fix random seed for reproducibility\n",
        "seed = 5\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting liac-arff\n",
            "  Downloading https://files.pythonhosted.org/packages/e9/35/fbc9217cfa91d98888b43e1a19c03a50d716108c58494c558c65e308f372/liac-arff-2.4.0.tar.gz\n",
            "Building wheels for collected packages: liac-arff\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25ldone\n",
            "\u001b[?25h  Stored in directory: /root/.cache/pip/wheels/d1/6a/e7/529dc54d76ecede4346164a09ae3168df358945612710f5203\n",
            "Successfully built liac-arff\n",
            "Installing collected packages: liac-arff\n",
            "Successfully installed liac-arff-2.4.0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o99ibbgGHANE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1040
        },
        "outputId": "60258c40-072c-4d2a-c31e-5e9be80a41a9"
      },
      "cell_type": "code",
      "source": [
        "#@title CHOOSE\n",
        "\n",
        "'''\n",
        "@Description: MAIN\n",
        "'''\n",
        "\n",
        "#LOAD DATA\n",
        "print(\"Loading data...\")\n",
        "\n",
        "dataset = '/root/data/uHooComplete_featureDataset_Past_Only.arff' #@param {type:\"string\"}\n",
        "\n",
        "with open (dataset, encoding='utf-8') as f:\n",
        "  dataDictionary = arff.load(f)\n",
        "\n",
        "data = np.array(dataDictionary['data'])\n",
        "print(\"DATASET LOADED\")\n",
        "\n",
        "#CONVERTING VALUES\n",
        "print(\"\\nConverting values...\")\n",
        "for i in data:\n",
        "  if(i[-1] == 'Other'): i[-1] = 0\n",
        "  elif(i[-1] == 'Pasto') : i[-1] = 1\n",
        "\n",
        "dataset = data.astype('float32')\n",
        "print(\"CONVERSION DONE\")\n",
        "\n",
        "#SPLIT INTO INPUT (X) AND OUTPUT (Y) VARIABLES\n",
        "s = dataset.shape[-1]\n",
        "\n",
        "X = dataset[:,0:s-1]\n",
        "Y = dataset[:,s-1]\n",
        "\n",
        "n_features = s-1\n",
        "\n",
        "#SPLIT INTO TRAINING, VALIDATION AND TEST SETS\n",
        "print(\"\\nSplit into training, validation and test sets...\")\n",
        "\n",
        "train_rate = 80\n",
        "val_rate = 10\n",
        "train = round(int((dataset.shape[0]*train_rate)/100))\n",
        "val = round(int((dataset.shape[0]*(train_rate+val_rate))/100))\n",
        "\n",
        "train_data = X[:train]\n",
        "train_label = Y[:train]\n",
        "\n",
        "val_data = X[train+1:val]\n",
        "val_label = Y[train+1:val]\n",
        "\n",
        "test_data = X[val+1:]\n",
        "test_label = Y[val+1:]\n",
        "print(\"DATASET SPLITTED\")\n",
        "\n",
        "#COMPUTE CLASS WEIGHT\n",
        "labels = np.unique(train_label)\n",
        "classWeight = compute_class_weight('balanced', labels, train_label)\n",
        "classWeight = dict(zip(labels,classWeight))\n",
        "\n",
        "#GENERATE MODEL\n",
        "print(\"\\nGenerate model...\")\n",
        "model = mlp.generate_model_leaky(train_data.shape[-1], n_features)\n",
        "\n",
        "#OPTIMIZERS\n",
        "adm = optimizers.Adam(lr=0.0001)\n",
        "\n",
        "#COMPILE MODEL\n",
        "print(\"\\nCompile model...\")\n",
        "model.compile(loss='binary_crossentropy', optimizer = adm , metrics=['accuracy'])\n",
        "\n",
        "#EARLY STOPPING\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
        "\n",
        "#FIT MODEL\n",
        "print(\"\\nFit model...\")\n",
        "history = model.fit(train_data, train_label, epochs=10, validation_data = (val_data, val_label), batch_size = 128, shuffle = True, class_weight = classWeight, verbose=1, callbacks = [es])\n",
        "\n",
        "#EVALUATE MODEL\n",
        "print(\"\\nEvaluate model...\")\n",
        "scores_test = model.evaluate(test_data, test_label, batch_size=128, verbose = 1)\n",
        "print(\"Test loss: %.2f%%\" % (scores_test[0] * 100))\n",
        "print(\"Test accuracy: %.2f%%\" % (scores_test[1] * 100))\n",
        "\n",
        "#CALCULATE PREDICTIONS\n",
        "print(\"\\nCalculate predictions...\")\n",
        "pred = model.predict_classes(test_data, batch_size=128, verbose=0)\n",
        "flat_pred = [item for sublist in pred for item in sublist]\n",
        "\n",
        "#CONFUSION MATRIX BEFORE POST PROCESSING\n",
        "print(\"\\n\\nCompute confusion matrix BEFORE POST PROCESSING...\")\n",
        "utils.compute_metrics(test_label, flat_pred)\n",
        "\n",
        "#STORE DATETIME\n",
        "time = []\n",
        "for i in test_data:\n",
        "  time.append(i[-5])"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "DATASET LOADED\n",
            "\n",
            "Converting values...\n",
            "CONVERSION DONE\n",
            "\n",
            "Split into training, validation and test sets...\n",
            "DATASET SPLITTED\n",
            "\n",
            "Generate model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Colocations handled automatically by placer.\n",
            "\n",
            "Compile model...\n",
            "\n",
            "Fit model...\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.cast instead.\n",
            "Train on 280416 samples, validate on 35051 samples\n",
            "Epoch 1/10\n",
            "280416/280416 [==============================] - 9s 33us/step - loss: 0.5959 - acc: 0.7245 - val_loss: 0.5980 - val_acc: 0.7076\n",
            "Epoch 2/10\n",
            "280416/280416 [==============================] - 8s 27us/step - loss: 0.4938 - acc: 0.8008 - val_loss: 0.5099 - val_acc: 0.7815\n",
            "Epoch 3/10\n",
            "280416/280416 [==============================] - 8s 27us/step - loss: 0.4612 - acc: 0.8088 - val_loss: 0.4618 - val_acc: 0.8106\n",
            "Epoch 4/10\n",
            "280416/280416 [==============================] - 8s 27us/step - loss: 0.4495 - acc: 0.8070 - val_loss: 0.4301 - val_acc: 0.8253\n",
            "Epoch 5/10\n",
            "280416/280416 [==============================] - 8s 27us/step - loss: 0.4410 - acc: 0.8101 - val_loss: 0.4470 - val_acc: 0.8274\n",
            "Epoch 6/10\n",
            "280416/280416 [==============================] - 8s 27us/step - loss: 0.4346 - acc: 0.8092 - val_loss: 0.4218 - val_acc: 0.8341\n",
            "Epoch 7/10\n",
            "280416/280416 [==============================] - 8s 27us/step - loss: 0.4301 - acc: 0.8071 - val_loss: 0.4728 - val_acc: 0.8009\n",
            "Epoch 8/10\n",
            "280416/280416 [==============================] - 8s 28us/step - loss: 0.4281 - acc: 0.8044 - val_loss: 0.4605 - val_acc: 0.8126\n",
            "\n",
            "Evaluate model...\n",
            "35052/35052 [==============================] - 0s 8us/step\n",
            "Test loss: 57.76%\n",
            "Test accuracy: 76.47%\n",
            "\n",
            "Calculate predictions...\n",
            "\n",
            "\n",
            "Compute confusion matrix BEFORE POST PROCESSING...\n",
            "TN 24943\n",
            "FP 8043\n",
            "FN 206\n",
            "TP 1860\n",
            "ACCURACY: 76.47 %\n",
            "TRUE NEGATIVE RATE (SPECIFICITY): 75.62 %\n",
            "TRUE POSITIVE RATE (RECALL): 90.03 %\n",
            "PRECISION: 18.78 %\n",
            "F1 SCORE: 31.08 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hdkk1t9J6oTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "c1d6f96d-a690-435d-c8d3-88dd4dd1479b"
      },
      "cell_type": "code",
      "source": [
        "#POST PROCESSING WITH SLIDING WINDOWS (MINUTE BY MINUTE)\n",
        "new_pred = postprocessing_sw.sliding_windows(flat_pred,35)\n",
        "\n",
        "#CONFUSION MATRIX AFTER POST PROCESSING\n",
        "print(\"\\n\\nCompute NEW confusion matrix AFTER POST PROCESSING...\")\n",
        "utils.compute_metrics(test_label, new_pred)\n"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "SLIDING WINDOWS FUNCTION...\n",
            "\n",
            "\n",
            "Compute NEW confusion matrix AFTER POST PROCESSING...\n",
            "TN 25272\n",
            "FP 7714\n",
            "FN 137\n",
            "TP 1929\n",
            "ACCURACY: 77.60 %\n",
            "TRUE NEGATIVE RATE (SPECIFICITY): 76.61 %\n",
            "TRUE POSITIVE RATE (RECALL): 93.37 %\n",
            "PRECISION: 20.00 %\n",
            "F1 SCORE: 32.95 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zN3qfOeFxhK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_precision_recall_f1(p, r): \n",
        "  index_pred = []\n",
        "  index_real = []\n",
        "\n",
        "  prediction_meals = []\n",
        "  real_meals = []\n",
        "\n",
        "  #p = flat_pred\n",
        "  #r = test_label\n",
        "\n",
        "  #COSTRUZIONE LISTE DI INDICI\n",
        "\n",
        "  #Una lista di pasti predetti e una di pasti reali\n",
        "\n",
        "  for i in range(0, len(p)-1):\n",
        "    if p[i] == 1:\n",
        "      index_pred.append(i)\n",
        "      if (p[i+1] == 0): \n",
        "        if(len(index_pred)>5):        \n",
        "          prediction_meals.append(index_pred)\n",
        "        index_pred = []\n",
        "    if r[i] == 1:\n",
        "      index_real.append(i)\n",
        "      if (r[i+1] == 0): \n",
        "        real_meals.append(index_real)\n",
        "        index_real = []\n",
        "\n",
        "  #Una lista di other predetti e una di other reali\n",
        "  prediction_others = []\n",
        "  real_others = []\n",
        "\n",
        "  index_pred = []\n",
        "  index_real = []\n",
        "\n",
        "  for i in range(0, len(p)):\n",
        "    if p[i] == 0:\n",
        "      index_pred.append(i)\n",
        "      if ((i+1) in range(0, len(p)) and p[i+1] == 1) or (i+1) not in range(0, len(p)): \n",
        "        prediction_others.append(index_pred)\n",
        "        index_pred = []\n",
        "    if r[i] == 0:\n",
        "      index_real.append(i)\n",
        "      if ((i+1) in range(0, len(p)) and r[i+1] == 1) or (i+1) not in range(0, len(p)): \n",
        "        real_others.append(index_real)\n",
        "        index_real = []\n",
        " \n",
        "  \n",
        "  \n",
        "  #Ricerca delle intersezioni, e quindi dei true positive e dei false positive\n",
        "\n",
        "  intersection = [] #contiene 1 se per un pasto reale j è stata già segnata un'intersezione \n",
        "  tp = 0\n",
        "  fp = 0\n",
        "\n",
        "  for i in range(0, len(real_meals)): #inizializzazione a 0 per l'array di intersezioni\n",
        "    intersection.append(0)\n",
        "\n",
        "  for i in range(0, len(prediction_meals)): #per ogni pasto predetto\n",
        "    flag_found = 0 #per tenere conto se l'intersezione è già stata trovata all'interno dei pasti reali\n",
        "    count_int = 0 #tiene conto del numero di intersezioni che un pasto predetto ha con i pasti reali (per il caso in cui un pasto pred intersechi due pasti reali)\n",
        "\n",
        "    for j in range(0, len(real_meals)):# per ogni pasto reale    \n",
        "      flag_visited = 0 #tiene conto se un pasto di prediction meals è già stato analizzato (per il caso in cui due pasti pred intersechino un unico pasto reale)\n",
        "\n",
        "      for x in prediction_meals[i]: #per ogni minuto di pasto controllo se esiste un'intersezione dentro real meals\n",
        "\n",
        "        if x in real_meals[j]: #se c'è l'intersezione        \n",
        "\n",
        "          if intersection[j]==0: #ciò significa che non è mai stata trovata un intersezione per il pasto reale j-esimo\n",
        "\n",
        "            if count_int == 0: #controlla che non siano ancora state trovate intersezioni  \n",
        "              count_int = count_int + 1\n",
        "              intersection[j] = 1\n",
        "              flag_visited = 1 #imposta il flag a uno per indicare che il pasto reale è stato già analizzato e per non contare più di una volta il tp trovato\n",
        "              flag_found = 1 #imposta il flag a uno per indicare che il pasto predetto è stato trovato nei pasti reali\n",
        "              tp=tp+1\n",
        "\n",
        "            elif count_int > 0: #caso in cui un pasto pred interseca due pasti reali e quindi un tp è già stato trovato in precedenza (produce un falso positivo e un vero positivo)           \n",
        "              intersection[j] = 1\n",
        "              flag_visited = 1 #imposta il flag a uno per indicare che il pasto reale è stato già analizzato e per non contare più di una volta il tp e il fp trovati\n",
        "              flag_found = 1            \n",
        "              fp=fp+1\n",
        "              tp=tp+1\n",
        "\n",
        "          elif flag_visited == 0: #caso in cui l'intersezione per il pasto reale j-esimo è già stata trovata ma tale pasto non è ancora stato analizzato con il pasto predetto i-esimo\n",
        "                                  #risolve il caso in cui più pasti pred intersecano un unico pasto reale\n",
        "            flag_found = 1\n",
        "            flag_visited = 1\n",
        "    #end for j\n",
        "\n",
        "    if flag_found == 0: #se l'intersezione nn è stata trovata nei pasti reali il pasto predetto è falso positivo\n",
        "      fp=fp+1\n",
        "    \n",
        "    \n",
        "  #Ricerca falsi negativi\n",
        "\n",
        "  fn = 0\n",
        "\n",
        "  for i in range(0, len(real_meals)): #per ogni pasto reale\n",
        "    j=0\n",
        "    flag_found = 0\n",
        "    while j in range(0, len(prediction_meals)) and flag_found==0: # per ogni pasto predetto finchè non viene trovato tra questi l'intersezione con il pasto i-esimo\n",
        "\n",
        "      for x in real_meals[i]: #per ogni minuto di pasto controllo se esiste un'intersezione dentro prediction_meals\n",
        "\n",
        "        if x in prediction_meals[j]: #se c'è l'intersezione        \n",
        "          flag_found = 1 #imposta il flag a uno per indicare che il pasto reale è stato trovato nei pasti predetti\n",
        "\n",
        "      j = j + 1  \n",
        "    #end while j\n",
        "\n",
        "    if flag_found == 0: #se l'intersezione del pasto reale non è stata trovata nei pasti predetti siamo in corrispondenza di un falso negativo\n",
        "      fn=fn+1\n",
        "      \n",
        "      \n",
        "      \n",
        "  #Ricerca intersezioni tra other (true negative)\n",
        "\n",
        "  tn=0\n",
        "  print(real_others)\n",
        "  print(prediction_meals)\n",
        "  for i in range(0, len(real_others)): #per ogni pasto reale\n",
        "    j=0\n",
        "    flag_found = 0\n",
        "    while j in range(0, len(prediction_meals)) and flag_found==0: # per ogni pasto predetto finchè non viene trovato tra questi l'intersezione con il pasto i-esimo\n",
        "\n",
        "      for x in real_others[i]: #per ogni minuto di pasto controllo se esiste un'intersezione dentro prediction_meals\n",
        "\n",
        "        if x in prediction_meals[j]: #se c'è l'intersezione        \n",
        "          flag_found = 1 #imposta il flag a uno per indicare che il pasto reale è stato trovato nei pasti predetti\n",
        "\n",
        "      j = j + 1  \n",
        "    #end while j\n",
        "    print(j)\n",
        "    if flag_found == 0: #se l'intersezione del pasto reale non è stata trovata nei pasti predetti siamo in corrispondenza di un falso negativo\n",
        "      tn=tn+1\n",
        "    \n",
        "\n",
        "\n",
        "\n",
        "  print(\"N° pasti reali:\", len(real_meals))\n",
        "  print(\"N° other reali:\", len(real_others))\n",
        "  print(\"N° pasti predetti:\", len(prediction_meals))\n",
        "  print(\"N° other predetti:\", len(prediction_others))\n",
        "\n",
        "  print(\"TP:\", tp)\n",
        "  print(\"FP:\", fp)\n",
        "  print(\"FN:\", fn)\n",
        "  print(\"TN:\", tn)\n",
        "  \n",
        "\n",
        "  somma = tp+fp\n",
        "  precision = (tp/(tp+fp))*100\n",
        "  TPR = (tp/(tp+fn))*100\n",
        "  TNR = (tn/(tn+fp))*100\n",
        "  F1 = 2*((precision*TPR)/(precision+TPR))\n",
        "  acc = (tp+tn)/(tp+tn+fp+fn)*100\n",
        "  print(\"Recall: %.2f %%\" % TPR)\n",
        "  print(\"Specificity: %.2f %%\" % TNR)\n",
        "  print(\"Accuracy: %.2f %%\" % acc)\n",
        "  \n",
        "  print(\"Precision: %.2f %%\" % precision)\n",
        "  print(\"F1 score: %.2f %%\" % F1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHk6Ho1b1ZiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3545
        },
        "outputId": "f249a915-c105-4862-c575-c4a624748adb"
      },
      "cell_type": "code",
      "source": [
        "#COOKING INSTANCE MODALITY\n",
        "\n",
        "#before post-processing\n",
        "print(\"\\nCOOKING INSTANCE MODALITY BEFORE POST PROCESSING\")\n",
        "#cooking_inst_mod.get_precision_recall_f1(flat_pred,test_label)\n",
        "get_precision_recall_f1(flat_pred,test_label)\n",
        "#after post-processing\n",
        "print(\"\\nCOOKING INSTANCE MODALITY AFTER POST PROCESSING\")\n",
        "#cooking_inst_mod.get_precision_recall_f1(new_pred,test_label)\n",
        "get_precision_recall_f1(new_pred,test_label)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "COOKING INSTANCE MODALITY BEFORE POST PROCESSING\n",
            "1\n",
            "3\n",
            "8\n",
            "13\n",
            "17\n",
            "19\n",
            "20\n",
            "22\n",
            "24\n",
            "28\n",
            "29\n",
            "33\n",
            "35\n",
            "37\n",
            "39\n",
            "42\n",
            "44\n",
            "46\n",
            "46\n",
            "49\n",
            "52\n",
            "55\n",
            "58\n",
            "62\n",
            "63\n",
            "64\n",
            "67\n",
            "75\n",
            "76\n",
            "82\n",
            "88\n",
            "90\n",
            "93\n",
            "95\n",
            "98\n",
            "99\n",
            "104\n",
            "111\n",
            "113\n",
            "114\n",
            "116\n",
            "125\n",
            "127\n",
            "132\n",
            "135\n",
            "139\n",
            "147\n",
            "150\n",
            "150\n",
            "153\n",
            "160\n",
            "161\n",
            "162\n",
            "166\n",
            "170\n",
            "174\n",
            "177\n",
            "182\n",
            "184\n",
            "184\n",
            "188\n",
            "197\n",
            "199\n",
            "200\n",
            "202\n",
            "210\n",
            "212\n",
            "212\n",
            "213\n",
            "215\n",
            "216\n",
            "218\n",
            "225\n",
            "226\n",
            "229\n",
            "233\n",
            "234\n",
            "238\n",
            "241\n",
            "244\n",
            "248\n",
            "251\n",
            "N° pasti reali: 81\n",
            "N° other reali: 82\n",
            "N° pasti predetti: 265\n",
            "N° other predetti: 907\n",
            "TP: 77\n",
            "FP: 179\n",
            "FN: 4\n",
            "TN: 0\n",
            "Recall: 95.06 %\n",
            "Specificity: 0.00 %\n",
            "Accuracy: 29.62 %\n",
            "Precision: 30.08 %\n",
            "F1 score: 45.70 %\n",
            "\n",
            "COOKING INSTANCE MODALITY AFTER POST PROCESSING\n",
            "1\n",
            "3\n",
            "5\n",
            "8\n",
            "10\n",
            "11\n",
            "12\n",
            "13\n",
            "14\n",
            "16\n",
            "17\n",
            "21\n",
            "23\n",
            "25\n",
            "27\n",
            "30\n",
            "31\n",
            "33\n",
            "33\n",
            "35\n",
            "36\n",
            "38\n",
            "39\n",
            "40\n",
            "41\n",
            "42\n",
            "46\n",
            "49\n",
            "50\n",
            "54\n",
            "57\n",
            "58\n",
            "60\n",
            "62\n",
            "64\n",
            "65\n",
            "68\n",
            "72\n",
            "73\n",
            "74\n",
            "75\n",
            "78\n",
            "80\n",
            "82\n",
            "83\n",
            "86\n",
            "89\n",
            "91\n",
            "91\n",
            "92\n",
            "95\n",
            "96\n",
            "97\n",
            "98\n",
            "100\n",
            "103\n",
            "106\n",
            "108\n",
            "109\n",
            "109\n",
            "111\n",
            "116\n",
            "117\n",
            "117\n",
            "118\n",
            "121\n",
            "123\n",
            "123\n",
            "124\n",
            "124\n",
            "125\n",
            "126\n",
            "128\n",
            "129\n",
            "132\n",
            "134\n",
            "135\n",
            "137\n",
            "139\n",
            "142\n",
            "146\n",
            "147\n",
            "N° pasti reali: 81\n",
            "N° other reali: 82\n",
            "N° pasti predetti: 156\n",
            "N° other predetti: 159\n",
            "TP: 75\n",
            "FP: 87\n",
            "FN: 6\n",
            "TN: 0\n",
            "Recall: 92.59 %\n",
            "Specificity: 0.00 %\n",
            "Accuracy: 44.64 %\n",
            "Precision: 46.30 %\n",
            "F1 score: 61.73 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}