{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1_cross_validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FG2511/ARE/blob/master/model1_cross_validation_Silvia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5xC7KT-lYae2",
        "colab_type": "code",
        "outputId": "9da8aecd-29ff-4243-8a1b-93c8286a1760",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@File name: model1.ipynb\n",
        "@Created on 2018-12-20\n",
        "@Authors: Federica Gerina, Francesca Moi, Silvia Maria Massa\n",
        "@Description: Given a time-series dataset that contains minute-by-minute data \n",
        "about different kind of gases, collected by the uHoo air quality sensor, train\n",
        "a NN that classifies if a minute belongs to the class \"Pasto\" (1) otherwise to\n",
        "the class \"Other\" (0).\n",
        "'''\n",
        "\n",
        "!pip install liac-arff\n",
        "\n",
        "import arff\n",
        "import csv\n",
        "\n",
        "'''Provides a high-performance multidimensional array object, \n",
        "and tools for working with these arrays'''\n",
        "import numpy as np\n",
        "'''Save an array to a text file.'''\n",
        "from numpy import savetxt\n",
        "\n",
        "'''Providing high-performance, easy-to-use data structures and data analysis tools'''\n",
        "import pandas as pd\n",
        "'''Two-dimensional size-mutable, \n",
        "potentially heterogeneous tabular data structure with labeled axes (rows and columns). \n",
        "Arithmetic operations align on both row and column labels.'''\n",
        "from pandas import DataFrame\n",
        "'''Read CSV file into DataFrame.\n",
        "Supports optionally iterating or breaking of the file into chunks.'''\n",
        "from pandas import read_csv\n",
        "'''Concatenate pandas objects along a particular axis with optional set logic along the other axes.\n",
        "Can also add a layer of hierarchical indexing on the concatenation axis, \n",
        "which may be useful if the labels are the same (or overlapping) on the passed axis number'''\n",
        "from pandas import concat\n",
        "\n",
        "from keras import optimizers\n",
        "'''Linear stack of layers.'''\n",
        "from keras.models import Sequential\n",
        "'''Loads a model saved via save_model.'''\n",
        "from keras.models import load_model\n",
        "'''Dense: just your regular densely-connected NN layer.\n",
        "Dropout: applies Dropout to the input.'''\n",
        "from keras.layers import Dense, Dropout, BatchNormalization,Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.model_selection import KFold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import legend\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (2.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HWFtL_iIYf25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_model(shape):\n",
        "  \n",
        "  model = Sequential()\n",
        " \n",
        "  '''model.add(Dense(113, input_dim=shape, kernel_initializer='random_uniform',  bias_initializer='zeros', activation='relu'))'''\n",
        "  model.add(Dense(113, input_dim=shape, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  '''model.add(Dense(229, kernel_initializer='random_uniform',  bias_initializer='zeros', activation='relu'))'''\n",
        "  model.add(Dense(229, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  '''model.add(Dense(153, kernel_initializer='random_uniform',  bias_initializer='zeros', activation='relu'))'''\n",
        "  model.add(Dense(153, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  #print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUfQeqZVYk7H",
        "colab_type": "code",
        "outputId": "5346c671-a55c-4377-8607-cc237d5b7e92",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "#LOAD DATA\n",
        "print(\"Loading data...\")\n",
        "\n",
        "dataset = '/root/data/6_uHoo_featureDataset.arff'\n",
        "\n",
        "with open (dataset, encoding='utf-8') as f:\n",
        "  dataDictionary = arff.load(f)\n",
        "\n",
        "data = np.array(dataDictionary['data'])\n",
        "print(\"DATASET LOADED\")\n",
        "\n",
        "#CONVERTING VALUES\n",
        "print(\"Converting values...\")\n",
        "for i in data:\n",
        "  if(i[-1] == 'Other'): i[-1] = 0\n",
        "  elif(i[-1] == 'Pasto') : i[-1] = 1\n",
        "\n",
        "dataset = data.astype('float32')\n",
        "print(\"CONVERSION DONE\")\n",
        "\n",
        "#SPLIT INTO INPUT (X) AND OUTPUT (Y) VARIABLES\n",
        "s = dataset.shape[-1]\n",
        "X = dataset[:,0:s-1]\n",
        "Y = dataset[:,s-1]"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "DATASET LOADED\n",
            "Converting values...\n",
            "CONVERSION DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fpBXmGFPYoHA",
        "colab_type": "code",
        "outputId": "9658d247-3b1c-43e1-9f69-ebf970b37f0c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 7127
        }
      },
      "cell_type": "code",
      "source": [
        "#OPTIMIZERS\n",
        "#sgd = optimizers.SGD(lr=0.0001)\n",
        "adm = optimizers.Adam(lr=0.0001)\n",
        "#ada = optimizers.Adadelta(lr=0.0001)\n",
        "#rms = optimizers.RMSprop(lr=0.001)\n",
        "\n",
        "#DEFINE 10-FOLD CROSS-VALIDATION\n",
        "kfold = KFold(n_splits=10, shuffle=False)\n",
        "cvscores = []\n",
        "predictions = []\n",
        "\n",
        "i = 1\n",
        "\n",
        "for train, test in kfold.split(X, Y):\n",
        "  \n",
        "  print(\"\\nFOLD: %d\" %i)\n",
        "  #COMPUTE CLASS WEIGHT\n",
        "  labels = np.unique(Y[train])\n",
        "  classWeight = compute_class_weight('balanced', labels, Y[train])\n",
        "  classWeight = dict(zip(labels,classWeight))\n",
        "\n",
        "  #GENERATE MODEL\n",
        "  model = generate_model(X[train].shape[-1])\n",
        "\n",
        "  #COMPILE MODEL\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = adm , metrics=['accuracy'])\n",
        "  \n",
        "  #EARLY STOPPING\n",
        "  #es = EarlyStopping(monitor='val_acc', min_delta=0, patience=2, verbose=0, mode='auto')\n",
        "\n",
        "  #FIT MODEL\n",
        "  history = model.fit(X[train], Y[train], epochs=18, batch_size = 128, shuffle = True, verbose=1, class_weight = classWeight) #callbacks = [es])\n",
        "\n",
        "  #EVALUATE MODEL\n",
        "  scores_test = model.evaluate(X[test], Y[test], batch_size= 128, verbose = 1)\n",
        "  print(\"Test loss: %.2f%%\" % (scores_test[0] * 100))\n",
        "  print(\"Test accuracy: %.2f%%\" % (scores_test[1] * 100))\n",
        "  \n",
        "  cvscores.append(scores_test[1] * 100)\n",
        "  \n",
        "  #CALCULATE PREDICTIONS AND SAVE IN A CSV FILE\n",
        "  pred = model.predict_classes(X[test], batch_size=128, verbose=1)\n",
        "  predictions.append([i,pred])\n",
        "  actual.append([i,Y[test]])\n",
        "  \n",
        "  i+=1\n",
        "\n",
        "print(\"MEAN ACCURACY: %.2f%% (STANDARD DEVIATION: +/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "FOLD: 1\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 25s 123us/step - loss: 0.4289 - acc: 0.7842\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 18s 87us/step - loss: 0.3590 - acc: 0.8204\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 18s 88us/step - loss: 0.3327 - acc: 0.8337\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 18s 88us/step - loss: 0.3116 - acc: 0.8464\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 18s 87us/step - loss: 0.3005 - acc: 0.8516\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 18s 88us/step - loss: 0.2845 - acc: 0.8597\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 18s 87us/step - loss: 0.2774 - acc: 0.8630\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 18s 88us/step - loss: 0.2629 - acc: 0.8709\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 18s 88us/step - loss: 0.2602 - acc: 0.8720\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 18s 88us/step - loss: 0.2530 - acc: 0.8764\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 18s 87us/step - loss: 0.2411 - acc: 0.8830\n",
            "Epoch 12/18\n",
            "206937/206937 [==============================] - 20s 95us/step - loss: 0.2345 - acc: 0.8867\n",
            "Epoch 13/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2262 - acc: 0.8909\n",
            "Epoch 14/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2234 - acc: 0.8917\n",
            "Epoch 15/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2156 - acc: 0.8959\n",
            "Epoch 16/18\n",
            "206937/206937 [==============================] - 19s 94us/step - loss: 0.2095 - acc: 0.8982\n",
            "Epoch 17/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2028 - acc: 0.9031\n",
            "Epoch 18/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.1996 - acc: 0.9036\n",
            "22993/22993 [==============================] - 4s 172us/step\n",
            "Test loss: 25.46%\n",
            "Test accuracy: 91.15%\n",
            "22993/22993 [==============================] - 4s 166us/step\n",
            "\n",
            "FOLD: 2\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 26s 126us/step - loss: 0.4205 - acc: 0.7814\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.3556 - acc: 0.8216\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.3337 - acc: 0.8331\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.3152 - acc: 0.8435\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.3029 - acc: 0.8510\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 18s 89us/step - loss: 0.2897 - acc: 0.8571\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2818 - acc: 0.8617\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2679 - acc: 0.8692\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2621 - acc: 0.8717\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2504 - acc: 0.8787\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2443 - acc: 0.8808\n",
            "Epoch 12/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2366 - acc: 0.8852\n",
            "Epoch 13/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2321 - acc: 0.8874\n",
            "Epoch 14/18\n",
            "206937/206937 [==============================] - 23s 109us/step - loss: 0.2218 - acc: 0.8945\n",
            "Epoch 15/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2201 - acc: 0.8942\n",
            "Epoch 16/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2167 - acc: 0.8962\n",
            "Epoch 17/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2120 - acc: 0.8977\n",
            "Epoch 18/18\n",
            "206937/206937 [==============================] - 18s 89us/step - loss: 0.2064 - acc: 0.9009\n",
            "22993/22993 [==============================] - 4s 176us/step\n",
            "Test loss: 27.41%\n",
            "Test accuracy: 87.24%\n",
            "22993/22993 [==============================] - 4s 170us/step\n",
            "\n",
            "FOLD: 3\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 26s 127us/step - loss: 0.4192 - acc: 0.7816\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.3518 - acc: 0.8228\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.3290 - acc: 0.8337\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.3098 - acc: 0.8448\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2951 - acc: 0.8532\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2939 - acc: 0.8546\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 19s 94us/step - loss: 0.2795 - acc: 0.8607\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2680 - acc: 0.8682\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2626 - acc: 0.8681\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2549 - acc: 0.8738\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 20s 94us/step - loss: 0.2498 - acc: 0.8765\n",
            "Epoch 12/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2433 - acc: 0.8800\n",
            "Epoch 13/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2386 - acc: 0.8839\n",
            "Epoch 14/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2322 - acc: 0.8865\n",
            "Epoch 15/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2289 - acc: 0.8869\n",
            "Epoch 16/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2229 - acc: 0.8914\n",
            "Epoch 17/18\n",
            "206937/206937 [==============================] - 18s 89us/step - loss: 0.2191 - acc: 0.8929\n",
            "Epoch 18/18\n",
            "206937/206937 [==============================] - 18s 89us/step - loss: 0.2150 - acc: 0.8950\n",
            "22993/22993 [==============================] - 4s 180us/step\n",
            "Test loss: 37.10%\n",
            "Test accuracy: 85.73%\n",
            "22993/22993 [==============================] - 4s 177us/step\n",
            "\n",
            "FOLD: 4\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 27s 129us/step - loss: 0.4267 - acc: 0.7797\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.3630 - acc: 0.8171\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.3458 - acc: 0.8253\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 20s 96us/step - loss: 0.3241 - acc: 0.8388\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.3110 - acc: 0.8450\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.3024 - acc: 0.8488\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2904 - acc: 0.8556\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2795 - acc: 0.8614\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 20s 96us/step - loss: 0.2708 - acc: 0.8661\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2633 - acc: 0.8696\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2557 - acc: 0.8747\n",
            "Epoch 12/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2503 - acc: 0.8757\n",
            "Epoch 13/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2468 - acc: 0.8790\n",
            "Epoch 14/18\n",
            "206937/206937 [==============================] - 18s 89us/step - loss: 0.2387 - acc: 0.8839\n",
            "Epoch 15/18\n",
            "206937/206937 [==============================] - 18s 89us/step - loss: 0.2315 - acc: 0.8869\n",
            "Epoch 16/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2220 - acc: 0.8905\n",
            "Epoch 17/18\n",
            "206937/206937 [==============================] - 18s 89us/step - loss: 0.2231 - acc: 0.8915\n",
            "Epoch 18/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2169 - acc: 0.8951\n",
            "22993/22993 [==============================] - 4s 183us/step\n",
            "Test loss: 37.66%\n",
            "Test accuracy: 83.70%\n",
            "22993/22993 [==============================] - 4s 176us/step\n",
            "\n",
            "FOLD: 5\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 27s 130us/step - loss: 0.4236 - acc: 0.7795\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.3571 - acc: 0.8158\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.3335 - acc: 0.8306\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.3179 - acc: 0.8389\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.3040 - acc: 0.8485\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 20s 97us/step - loss: 0.2960 - acc: 0.8523\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2816 - acc: 0.8612\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2729 - acc: 0.8652\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 19s 89us/step - loss: 0.2601 - acc: 0.8715\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2584 - acc: 0.8725\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2465 - acc: 0.8782\n",
            "Epoch 12/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2444 - acc: 0.8798\n",
            "Epoch 13/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2376 - acc: 0.8842\n",
            "Epoch 14/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2280 - acc: 0.8869\n",
            "Epoch 15/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2298 - acc: 0.8878\n",
            "Epoch 16/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2192 - acc: 0.8930\n",
            "Epoch 17/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2162 - acc: 0.8949\n",
            "Epoch 18/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2098 - acc: 0.8979\n",
            "22993/22993 [==============================] - 4s 186us/step\n",
            "Test loss: 33.22%\n",
            "Test accuracy: 86.07%\n",
            "22993/22993 [==============================] - 4s 184us/step\n",
            "\n",
            "FOLD: 6\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 27s 131us/step - loss: 0.4235 - acc: 0.7796\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.3583 - acc: 0.8135\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.3354 - acc: 0.8286\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 20s 97us/step - loss: 0.3219 - acc: 0.8342\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.3090 - acc: 0.8421\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.3002 - acc: 0.8489\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2888 - acc: 0.8542\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2809 - acc: 0.8590\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2695 - acc: 0.8634\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2619 - acc: 0.8690\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2570 - acc: 0.8715\n",
            "Epoch 12/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2507 - acc: 0.8742\n",
            "Epoch 13/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2432 - acc: 0.8789\n",
            "Epoch 14/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2384 - acc: 0.8809\n",
            "Epoch 15/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2345 - acc: 0.8845\n",
            "Epoch 16/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2270 - acc: 0.8883\n",
            "Epoch 17/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2222 - acc: 0.8888\n",
            "Epoch 18/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2217 - acc: 0.8904\n",
            "22993/22993 [==============================] - 4s 190us/step\n",
            "Test loss: 29.81%\n",
            "Test accuracy: 87.77%\n",
            "22993/22993 [==============================] - 4s 185us/step\n",
            "\n",
            "FOLD: 7\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 28s 136us/step - loss: 0.4215 - acc: 0.7811\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.3591 - acc: 0.8175\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.3334 - acc: 0.8302\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.3200 - acc: 0.8412\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.3029 - acc: 0.8486\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2936 - acc: 0.8531\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2800 - acc: 0.8590\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2743 - acc: 0.8635\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2655 - acc: 0.8685\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2534 - acc: 0.8740\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2536 - acc: 0.8738\n",
            "Epoch 12/18\n",
            "206937/206937 [==============================] - 20s 95us/step - loss: 0.2429 - acc: 0.8793\n",
            "Epoch 13/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2418 - acc: 0.8805\n",
            "Epoch 14/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2347 - acc: 0.8848\n",
            "Epoch 15/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2289 - acc: 0.8878\n",
            "Epoch 16/18\n",
            "206937/206937 [==============================] - 21s 101us/step - loss: 0.2230 - acc: 0.8897\n",
            "Epoch 17/18\n",
            "206937/206937 [==============================] - 20s 95us/step - loss: 0.2144 - acc: 0.8937\n",
            "Epoch 18/18\n",
            "206937/206937 [==============================] - 19s 94us/step - loss: 0.2143 - acc: 0.8953\n",
            "22993/22993 [==============================] - 5s 197us/step\n",
            "Test loss: 35.50%\n",
            "Test accuracy: 85.80%\n",
            "22993/22993 [==============================] - 4s 190us/step\n",
            "\n",
            "FOLD: 8\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 28s 134us/step - loss: 0.4217 - acc: 0.7782\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.3594 - acc: 0.8143\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.3332 - acc: 0.8303\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 19s 94us/step - loss: 0.3183 - acc: 0.8376\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.3039 - acc: 0.8467\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2903 - acc: 0.8535\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2827 - acc: 0.8580\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2743 - acc: 0.8641\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 20s 95us/step - loss: 0.2641 - acc: 0.8679\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2552 - acc: 0.8728\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2445 - acc: 0.8791\n",
            "Epoch 12/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2420 - acc: 0.8807\n",
            "Epoch 13/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2339 - acc: 0.8849\n",
            "Epoch 14/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2280 - acc: 0.8878\n",
            "Epoch 15/18\n",
            "206937/206937 [==============================] - 20s 95us/step - loss: 0.2215 - acc: 0.8907\n",
            "Epoch 16/18\n",
            "206937/206937 [==============================] - 20s 94us/step - loss: 0.2203 - acc: 0.8921\n",
            "Epoch 17/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2084 - acc: 0.8980\n",
            "Epoch 18/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2062 - acc: 0.8992\n",
            "22993/22993 [==============================] - 5s 197us/step\n",
            "Test loss: 32.30%\n",
            "Test accuracy: 87.09%\n",
            "22993/22993 [==============================] - 4s 194us/step\n",
            "\n",
            "FOLD: 9\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 28s 133us/step - loss: 0.4218 - acc: 0.7806\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.3570 - acc: 0.8149\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 19s 94us/step - loss: 0.3332 - acc: 0.8294\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 19s 94us/step - loss: 0.3196 - acc: 0.8371\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.3072 - acc: 0.8447\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 20s 95us/step - loss: 0.2971 - acc: 0.8508\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2846 - acc: 0.8568\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2767 - acc: 0.8619\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2660 - acc: 0.8663\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 20s 97us/step - loss: 0.2617 - acc: 0.8712\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2535 - acc: 0.8754\n",
            "Epoch 12/18\n",
            "206937/206937 [==============================] - 20s 96us/step - loss: 0.2444 - acc: 0.8793\n",
            "Epoch 13/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2408 - acc: 0.8825\n",
            "Epoch 14/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2356 - acc: 0.8843\n",
            "Epoch 15/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2259 - acc: 0.8888\n",
            "Epoch 16/18\n",
            "206937/206937 [==============================] - 19s 92us/step - loss: 0.2236 - acc: 0.8906\n",
            "Epoch 17/18\n",
            "206937/206937 [==============================] - 19s 91us/step - loss: 0.2194 - acc: 0.8936\n",
            "Epoch 18/18\n",
            "206937/206937 [==============================] - 19s 90us/step - loss: 0.2094 - acc: 0.8984\n",
            "22993/22993 [==============================] - 5s 201us/step\n",
            "Test loss: 42.77%\n",
            "Test accuracy: 82.35%\n",
            "22993/22993 [==============================] - 5s 199us/step\n",
            "\n",
            "FOLD: 10\n",
            "Epoch 1/18\n",
            "206937/206937 [==============================] - 28s 137us/step - loss: 0.4109 - acc: 0.7914\n",
            "Epoch 2/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.3467 - acc: 0.8251\n",
            "Epoch 3/18\n",
            "206937/206937 [==============================] - 20s 97us/step - loss: 0.3229 - acc: 0.8373\n",
            "Epoch 4/18\n",
            "206937/206937 [==============================] - 19s 94us/step - loss: 0.3103 - acc: 0.8450\n",
            "Epoch 5/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2943 - acc: 0.8515\n",
            "Epoch 6/18\n",
            "206937/206937 [==============================] - 21s 100us/step - loss: 0.2854 - acc: 0.8586\n",
            "Epoch 7/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2750 - acc: 0.8619\n",
            "Epoch 8/18\n",
            "206937/206937 [==============================] - 19s 93us/step - loss: 0.2698 - acc: 0.8667\n",
            "Epoch 9/18\n",
            "206937/206937 [==============================] - 21s 100us/step - loss: 0.2606 - acc: 0.8711\n",
            "Epoch 10/18\n",
            "206937/206937 [==============================] - 20s 95us/step - loss: 0.2540 - acc: 0.8745\n",
            "Epoch 11/18\n",
            "206937/206937 [==============================] - 20s 95us/step - loss: 0.2484 - acc: 0.8764\n",
            "Epoch 12/18\n",
            "170240/206937 [=======================>......] - ETA: 3s - loss: 0.2439 - acc: 0.8794Buffered data was truncated after reaching the output size limit."
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gAdSdADmUm5S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_vL2BWwjIgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.save('my_model1_cv.h5')\n",
        "\n",
        "#model = load_model('my_model1_cv.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}