{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1_cross_validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FG2511/ARE/blob/master/model1_cross_validation_Silvia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5xC7KT-lYae2",
        "colab_type": "code",
        "outputId": "86f6d5c7-48cc-42ab-c8ea-e87d8aa993f1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@File name: model1.ipynb\n",
        "@Created on 2018-12-20\n",
        "@Authors: Federica Gerina, Francesca Moi, Silvia Maria Massa\n",
        "@Description: Given a time-series dataset that contains minute-by-minute data \n",
        "about different kind of gases, collected by the uHoo air quality sensor, train\n",
        "a NN that classifies if a minute belongs to the class \"Pasto\" (1) otherwise to\n",
        "the class \"Other\" (0).\n",
        "'''\n",
        "\n",
        "!pip install liac-arff\n",
        "\n",
        "import arff\n",
        "\n",
        "import numpy as np\n",
        "from numpy import savetxt\n",
        "\n",
        "import pandas as pd\n",
        "from pandas import DataFrame\n",
        "from pandas import read_csv\n",
        "from pandas import concat\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Dropout, LeakyReLU, BatchNormalization\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import legend\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (2.3.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "HWFtL_iIYf25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_model(shape):\n",
        "  \n",
        "  model = Sequential()\n",
        "  model.add(BatchNormalization())\n",
        " \n",
        "  model.add(Dense(113, input_dim=shape, kernel_initializer='random_uniform',  bias_initializer='zeros', activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(177, kernel_initializer='random_uniform',  bias_initializer='zeros', activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(102, kernel_initializer='random_uniform',  bias_initializer='zeros', activation='relu'))\n",
        "  model.add(Dropout(0.5))\n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  #print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUfQeqZVYk7H",
        "colab_type": "code",
        "outputId": "72089f5c-fade-4bdb-ce62-9e17310eb837",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "#LOAD DATA\n",
        "print(\"Loading data...\")\n",
        "\n",
        "dataset = '/root/data/Half_uHoo_featureDataset.arff'\n",
        "\n",
        "with open (dataset, encoding='utf-8') as f:\n",
        "  dataDictionary = arff.load(f)\n",
        "\n",
        "data = np.array(dataDictionary['data'])\n",
        "print(\"DATASET LOADED\")\n",
        "\n",
        "#CONVERTING VALUES\n",
        "print(\"Converting values...\")\n",
        "for i in data:\n",
        "  if(i[-1] == 'Other'): i[-1] = 0\n",
        "  elif(i[-1] == 'Pasto') : i[-1] = 1\n",
        "\n",
        "dataset = data.astype('float32')\n",
        "print(\"CONVERSION DONE\")\n",
        "\n",
        "#SPLIT INTO INPUT (X) AND OUTPUT (Y) VARIABLES\n",
        "s = dataset.shape[-1]\n",
        "X = dataset[:,0:s-1]\n",
        "Y = dataset[:,s-1]"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "DATASET LOADED\n",
            "Converting values...\n",
            "CONVERSION DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fpBXmGFPYoHA",
        "colab_type": "code",
        "outputId": "e1d25822-bb7f-49b2-803a-aed45969fd78",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 29426
        }
      },
      "cell_type": "code",
      "source": [
        "#OPTIMIZERS\n",
        "sgd = optimizers.SGD(lr=0.0001)\n",
        "adm = optimizers.Adam(lr=0.0001)\n",
        "ada = optimizers.Adadelta(lr=0.0001)\n",
        "#rms = optimizers.RMSprop(lr=0.001)\n",
        "\n",
        "#DEFINE 10-FOLD CROSS-VALIDATION\n",
        "kfold = StratifiedKFold(n_splits=10, shuffle=True, random_state=seed)\n",
        "cvscores = []\n",
        "predictions = []\n",
        "\n",
        "i = 1\n",
        "\n",
        "for train, test in kfold.split(X, Y):\n",
        "  \n",
        "  print(\"\\nFOLD: %d\" %i)\n",
        "  #COMPUTE CLASS WEIGHT\n",
        "  labels = np.unique(Y[train])\n",
        "  classWeight = compute_class_weight('balanced', labels, Y[train])\n",
        "  classWeight = dict(zip(labels,classWeight))\n",
        "\n",
        "  #GENERATE MODEL\n",
        "  model = generate_model(X[train].shape[-1])\n",
        "\n",
        "  #COMPILE MODEL\n",
        "  model.compile(loss='binary_crossentropy', optimizer = adm , metrics=['accuracy'])\n",
        "  \n",
        "  #EARLY STOPPING\n",
        "  #es = EarlyStopping(monitor='val_acc', min_delta=0, patience=2, verbose=0, mode='auto')\n",
        "\n",
        "  #FIT MODEL\n",
        "  history = model.fit(X[train], Y[train], epochs=80, validation_split=0.33, batch_size = 128, shuffle = True, verbose=1, class_weight = classWeight)#, callbacks = [es])\n",
        "\n",
        "  #EVALUATE MODEL\n",
        "  scores_test = model.evaluate(X[test], Y[test], batch_size= 128, verbose = 1)\n",
        "  print(\"Test loss: %.2f%%\" % (scores_test[0] * 100))\n",
        "  print(\"Test accuracy: %.2f%%\" % (scores_test[1] * 100))\n",
        "  \n",
        "  cvscores.append(scores_test[1] * 100)\n",
        "  \n",
        "  #CALCULATE PREDICTIONS\n",
        "  pred = model.predict_classes(X[test], batch_size=128, verbose=1)\n",
        "  predictions.append(pred)\n",
        "  \n",
        "  if(i==10): predictions.append(Y[test])\n",
        "  \n",
        "  i+=1\n",
        "\n",
        "print(\"MEAN ACCURACY: %.2f%% (STANDARD DEVIATION: +/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "FOLD: 1\n",
            "Train on 88410 samples, validate on 43546 samples\n",
            "Epoch 1/80\n",
            "88410/88410 [==============================] - 5s 52us/step - loss: 0.6808 - acc: 0.4718 - val_loss: 0.4534 - val_acc: 0.6104\n",
            "Epoch 2/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5951 - acc: 0.6539 - val_loss: 0.4511 - val_acc: 0.5525\n",
            "Epoch 3/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5708 - acc: 0.6648 - val_loss: 0.4403 - val_acc: 0.6134\n",
            "Epoch 4/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.5473 - acc: 0.6861 - val_loss: 0.4354 - val_acc: 0.6424\n",
            "Epoch 5/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5320 - acc: 0.6901 - val_loss: 0.4266 - val_acc: 0.7365\n",
            "Epoch 6/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.5285 - acc: 0.6953 - val_loss: 0.4212 - val_acc: 0.7298\n",
            "Epoch 7/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5141 - acc: 0.7093 - val_loss: 0.4322 - val_acc: 0.7145\n",
            "Epoch 8/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5073 - acc: 0.7092 - val_loss: 0.4171 - val_acc: 0.7517\n",
            "Epoch 9/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5052 - acc: 0.7113 - val_loss: 0.4230 - val_acc: 0.7544\n",
            "Epoch 10/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4992 - acc: 0.7146 - val_loss: 0.4288 - val_acc: 0.7542\n",
            "Epoch 11/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4959 - acc: 0.7204 - val_loss: 0.4268 - val_acc: 0.7435\n",
            "Epoch 12/80\n",
            "88410/88410 [==============================] - 4s 45us/step - loss: 0.4910 - acc: 0.7237 - val_loss: 0.4288 - val_acc: 0.7686\n",
            "Epoch 13/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.4852 - acc: 0.7261 - val_loss: 0.4305 - val_acc: 0.7766\n",
            "Epoch 14/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4840 - acc: 0.7308 - val_loss: 0.4366 - val_acc: 0.7724\n",
            "Epoch 15/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4793 - acc: 0.7370 - val_loss: 0.4291 - val_acc: 0.7865\n",
            "Epoch 16/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4741 - acc: 0.7421 - val_loss: 0.4289 - val_acc: 0.7897\n",
            "Epoch 17/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4721 - acc: 0.7498 - val_loss: 0.4318 - val_acc: 0.7767\n",
            "Epoch 18/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4691 - acc: 0.7401 - val_loss: 0.4274 - val_acc: 0.8157\n",
            "Epoch 19/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4622 - acc: 0.7502 - val_loss: 0.4429 - val_acc: 0.7964\n",
            "Epoch 20/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.4629 - acc: 0.7535 - val_loss: 0.4362 - val_acc: 0.7967\n",
            "Epoch 21/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.4576 - acc: 0.7582 - val_loss: 0.4336 - val_acc: 0.8018\n",
            "Epoch 22/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.4524 - acc: 0.7594 - val_loss: 0.4501 - val_acc: 0.7949\n",
            "Epoch 23/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.4523 - acc: 0.7606 - val_loss: 0.4383 - val_acc: 0.7917\n",
            "Epoch 24/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4437 - acc: 0.7631 - val_loss: 0.4335 - val_acc: 0.8105\n",
            "Epoch 25/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.4422 - acc: 0.7681 - val_loss: 0.4510 - val_acc: 0.8156\n",
            "Epoch 26/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4413 - acc: 0.7634 - val_loss: 0.4688 - val_acc: 0.7970\n",
            "Epoch 27/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.4411 - acc: 0.7619 - val_loss: 0.4519 - val_acc: 0.8184\n",
            "Epoch 28/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.4386 - acc: 0.7673 - val_loss: 0.4713 - val_acc: 0.7946\n",
            "Epoch 29/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4295 - acc: 0.7707 - val_loss: 0.4530 - val_acc: 0.8185\n",
            "Epoch 30/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4255 - acc: 0.7743 - val_loss: 0.4790 - val_acc: 0.7971\n",
            "Epoch 31/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4272 - acc: 0.7762 - val_loss: 0.4716 - val_acc: 0.7914\n",
            "Epoch 32/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.4236 - acc: 0.7748 - val_loss: 0.4705 - val_acc: 0.8238\n",
            "Epoch 33/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4223 - acc: 0.7806 - val_loss: 0.4812 - val_acc: 0.8132\n",
            "Epoch 34/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4213 - acc: 0.7792 - val_loss: 0.4796 - val_acc: 0.8039\n",
            "Epoch 35/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4142 - acc: 0.7821 - val_loss: 0.4815 - val_acc: 0.8242\n",
            "Epoch 36/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4146 - acc: 0.7837 - val_loss: 0.4784 - val_acc: 0.8246\n",
            "Epoch 37/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4132 - acc: 0.7846 - val_loss: 0.4746 - val_acc: 0.8301\n",
            "Epoch 38/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4102 - acc: 0.7862 - val_loss: 0.4812 - val_acc: 0.8340\n",
            "Epoch 39/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4108 - acc: 0.7828 - val_loss: 0.4785 - val_acc: 0.8275\n",
            "Epoch 40/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4062 - acc: 0.7899 - val_loss: 0.4637 - val_acc: 0.8242\n",
            "Epoch 41/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4054 - acc: 0.7905 - val_loss: 0.4897 - val_acc: 0.8268\n",
            "Epoch 42/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4049 - acc: 0.7887 - val_loss: 0.4890 - val_acc: 0.8465\n",
            "Epoch 43/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3968 - acc: 0.7965 - val_loss: 0.5020 - val_acc: 0.8176\n",
            "Epoch 44/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3980 - acc: 0.7932 - val_loss: 0.4824 - val_acc: 0.8212\n",
            "Epoch 45/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3991 - acc: 0.7939 - val_loss: 0.5013 - val_acc: 0.8451\n",
            "Epoch 46/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3975 - acc: 0.7951 - val_loss: 0.5052 - val_acc: 0.8421\n",
            "Epoch 47/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3919 - acc: 0.7969 - val_loss: 0.4825 - val_acc: 0.8353\n",
            "Epoch 48/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3906 - acc: 0.7969 - val_loss: 0.5073 - val_acc: 0.8448\n",
            "Epoch 49/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3889 - acc: 0.8001 - val_loss: 0.5189 - val_acc: 0.8360\n",
            "Epoch 50/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3842 - acc: 0.8032 - val_loss: 0.5292 - val_acc: 0.8442\n",
            "Epoch 51/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3871 - acc: 0.7966 - val_loss: 0.4953 - val_acc: 0.8416\n",
            "Epoch 52/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3838 - acc: 0.8023 - val_loss: 0.5103 - val_acc: 0.8524\n",
            "Epoch 53/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3791 - acc: 0.8057 - val_loss: 0.5412 - val_acc: 0.8596\n",
            "Epoch 54/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3851 - acc: 0.8021 - val_loss: 0.5036 - val_acc: 0.8527\n",
            "Epoch 55/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3826 - acc: 0.8041 - val_loss: 0.5273 - val_acc: 0.8400\n",
            "Epoch 56/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3846 - acc: 0.8023 - val_loss: 0.5026 - val_acc: 0.8291\n",
            "Epoch 57/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3801 - acc: 0.8036 - val_loss: 0.5283 - val_acc: 0.8390\n",
            "Epoch 58/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3770 - acc: 0.8048 - val_loss: 0.5144 - val_acc: 0.8409\n",
            "Epoch 59/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3754 - acc: 0.8036 - val_loss: 0.5239 - val_acc: 0.8338\n",
            "Epoch 60/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3738 - acc: 0.8072 - val_loss: 0.5225 - val_acc: 0.8416\n",
            "Epoch 61/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3771 - acc: 0.8075 - val_loss: 0.5183 - val_acc: 0.8458\n",
            "Epoch 62/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3732 - acc: 0.8099 - val_loss: 0.5023 - val_acc: 0.8360\n",
            "Epoch 63/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3706 - acc: 0.8072 - val_loss: 0.5368 - val_acc: 0.8245\n",
            "Epoch 64/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3667 - acc: 0.8119 - val_loss: 0.5430 - val_acc: 0.8585\n",
            "Epoch 65/80\n",
            "88410/88410 [==============================] - 4s 44us/step - loss: 0.3667 - acc: 0.8136 - val_loss: 0.5154 - val_acc: 0.8464\n",
            "Epoch 66/80\n",
            "88410/88410 [==============================] - 4s 44us/step - loss: 0.3694 - acc: 0.8081 - val_loss: 0.5406 - val_acc: 0.8640\n",
            "Epoch 67/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3664 - acc: 0.8121 - val_loss: 0.5588 - val_acc: 0.8454\n",
            "Epoch 68/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3651 - acc: 0.8123 - val_loss: 0.5962 - val_acc: 0.8460\n",
            "Epoch 69/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3645 - acc: 0.8129 - val_loss: 0.5420 - val_acc: 0.8405\n",
            "Epoch 70/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3651 - acc: 0.8128 - val_loss: 0.5520 - val_acc: 0.8483\n",
            "Epoch 71/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3605 - acc: 0.8140 - val_loss: 0.5846 - val_acc: 0.8511\n",
            "Epoch 72/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3634 - acc: 0.8110 - val_loss: 0.5644 - val_acc: 0.8639\n",
            "Epoch 73/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3548 - acc: 0.8188 - val_loss: 0.5690 - val_acc: 0.8421\n",
            "Epoch 74/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3594 - acc: 0.8134 - val_loss: 0.5436 - val_acc: 0.8624\n",
            "Epoch 75/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3617 - acc: 0.8155 - val_loss: 0.5425 - val_acc: 0.8561\n",
            "Epoch 76/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3591 - acc: 0.8197 - val_loss: 0.5230 - val_acc: 0.8435\n",
            "Epoch 77/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3563 - acc: 0.8177 - val_loss: 0.5532 - val_acc: 0.8412\n",
            "Epoch 78/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3593 - acc: 0.8169 - val_loss: 0.5718 - val_acc: 0.8452\n",
            "Epoch 79/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3532 - acc: 0.8209 - val_loss: 0.5709 - val_acc: 0.8476\n",
            "Epoch 80/80\n",
            "88410/88410 [==============================] - 4s 41us/step - loss: 0.3571 - acc: 0.8182 - val_loss: 0.5282 - val_acc: 0.8358\n",
            "14663/14663 [==============================] - 0s 11us/step\n",
            "Test loss: 32.30%\n",
            "Test accuracy: 85.18%\n",
            "14663/14663 [==============================] - 0s 15us/step\n",
            "\n",
            "FOLD: 2\n",
            "Train on 88410 samples, validate on 43546 samples\n",
            "Epoch 1/80\n",
            "88410/88410 [==============================] - 4s 48us/step - loss: 0.6158 - acc: 0.5908 - val_loss: 0.4377 - val_acc: 0.6686\n",
            "Epoch 2/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5661 - acc: 0.6685 - val_loss: 0.4501 - val_acc: 0.6479\n",
            "Epoch 3/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5453 - acc: 0.6781 - val_loss: 0.4246 - val_acc: 0.7518\n",
            "Epoch 4/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5293 - acc: 0.7001 - val_loss: 0.4294 - val_acc: 0.7586\n",
            "Epoch 5/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5248 - acc: 0.7023 - val_loss: 0.4220 - val_acc: 0.7507\n",
            "Epoch 6/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5129 - acc: 0.7102 - val_loss: 0.4330 - val_acc: 0.7478\n",
            "Epoch 7/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.5087 - acc: 0.7121 - val_loss: 0.4234 - val_acc: 0.7616\n",
            "Epoch 8/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5036 - acc: 0.7168 - val_loss: 0.4228 - val_acc: 0.7614\n",
            "Epoch 9/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4932 - acc: 0.7244 - val_loss: 0.4238 - val_acc: 0.7795\n",
            "Epoch 10/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4939 - acc: 0.7288 - val_loss: 0.4140 - val_acc: 0.8091\n",
            "Epoch 11/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4892 - acc: 0.7270 - val_loss: 0.4307 - val_acc: 0.7665\n",
            "Epoch 12/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4824 - acc: 0.7354 - val_loss: 0.4379 - val_acc: 0.7707\n",
            "Epoch 13/80\n",
            "88410/88410 [==============================] - 4s 44us/step - loss: 0.4780 - acc: 0.7343 - val_loss: 0.4375 - val_acc: 0.7688\n",
            "Epoch 14/80\n",
            "88410/88410 [==============================] - 4s 45us/step - loss: 0.4777 - acc: 0.7380 - val_loss: 0.4392 - val_acc: 0.7773\n",
            "Epoch 15/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4692 - acc: 0.7495 - val_loss: 0.4351 - val_acc: 0.7873\n",
            "Epoch 16/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4725 - acc: 0.7474 - val_loss: 0.4475 - val_acc: 0.7960\n",
            "Epoch 17/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4615 - acc: 0.7578 - val_loss: 0.4407 - val_acc: 0.7759\n",
            "Epoch 18/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4626 - acc: 0.7528 - val_loss: 0.4472 - val_acc: 0.7795\n",
            "Epoch 19/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4560 - acc: 0.7623 - val_loss: 0.4663 - val_acc: 0.7872\n",
            "Epoch 20/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4534 - acc: 0.7595 - val_loss: 0.4476 - val_acc: 0.7945\n",
            "Epoch 21/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4501 - acc: 0.7649 - val_loss: 0.4552 - val_acc: 0.7935\n",
            "Epoch 22/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4491 - acc: 0.7630 - val_loss: 0.4602 - val_acc: 0.8041\n",
            "Epoch 23/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4430 - acc: 0.7670 - val_loss: 0.4544 - val_acc: 0.7788\n",
            "Epoch 24/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4460 - acc: 0.7622 - val_loss: 0.4606 - val_acc: 0.7880\n",
            "Epoch 25/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4416 - acc: 0.7667 - val_loss: 0.4671 - val_acc: 0.7973\n",
            "Epoch 26/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4375 - acc: 0.7681 - val_loss: 0.4652 - val_acc: 0.8067\n",
            "Epoch 27/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4391 - acc: 0.7700 - val_loss: 0.4588 - val_acc: 0.7906\n",
            "Epoch 28/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4354 - acc: 0.7726 - val_loss: 0.4842 - val_acc: 0.7772\n",
            "Epoch 29/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4359 - acc: 0.7721 - val_loss: 0.4876 - val_acc: 0.7833\n",
            "Epoch 30/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4250 - acc: 0.7774 - val_loss: 0.4959 - val_acc: 0.8061\n",
            "Epoch 31/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4259 - acc: 0.7741 - val_loss: 0.4836 - val_acc: 0.8052\n",
            "Epoch 32/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4238 - acc: 0.7761 - val_loss: 0.4847 - val_acc: 0.7701\n",
            "Epoch 33/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4254 - acc: 0.7781 - val_loss: 0.4946 - val_acc: 0.7775\n",
            "Epoch 34/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4192 - acc: 0.7813 - val_loss: 0.4706 - val_acc: 0.7972\n",
            "Epoch 35/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4129 - acc: 0.7863 - val_loss: 0.4984 - val_acc: 0.7907\n",
            "Epoch 36/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4175 - acc: 0.7812 - val_loss: 0.4837 - val_acc: 0.7738\n",
            "Epoch 37/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4131 - acc: 0.7799 - val_loss: 0.4988 - val_acc: 0.7831\n",
            "Epoch 38/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4132 - acc: 0.7829 - val_loss: 0.4928 - val_acc: 0.7775\n",
            "Epoch 39/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4070 - acc: 0.7849 - val_loss: 0.4970 - val_acc: 0.7855\n",
            "Epoch 40/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4044 - acc: 0.7876 - val_loss: 0.5138 - val_acc: 0.8056\n",
            "Epoch 41/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4022 - acc: 0.7878 - val_loss: 0.5081 - val_acc: 0.7981\n",
            "Epoch 42/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3996 - acc: 0.7874 - val_loss: 0.5281 - val_acc: 0.7886\n",
            "Epoch 43/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3963 - acc: 0.7920 - val_loss: 0.5267 - val_acc: 0.7857\n",
            "Epoch 44/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4005 - acc: 0.7882 - val_loss: 0.5246 - val_acc: 0.7756\n",
            "Epoch 45/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3972 - acc: 0.7870 - val_loss: 0.5181 - val_acc: 0.8063\n",
            "Epoch 46/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3923 - acc: 0.7888 - val_loss: 0.5469 - val_acc: 0.7929\n",
            "Epoch 47/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4018 - acc: 0.7867 - val_loss: 0.4988 - val_acc: 0.8033\n",
            "Epoch 48/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3896 - acc: 0.7931 - val_loss: 0.5199 - val_acc: 0.7894\n",
            "Epoch 49/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3868 - acc: 0.7926 - val_loss: 0.5292 - val_acc: 0.8014\n",
            "Epoch 50/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3900 - acc: 0.7918 - val_loss: 0.5233 - val_acc: 0.8004\n",
            "Epoch 51/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3853 - acc: 0.7951 - val_loss: 0.5341 - val_acc: 0.7808\n",
            "Epoch 52/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3837 - acc: 0.7951 - val_loss: 0.5364 - val_acc: 0.8143\n",
            "Epoch 53/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3846 - acc: 0.7949 - val_loss: 0.5406 - val_acc: 0.7910\n",
            "Epoch 54/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3858 - acc: 0.7962 - val_loss: 0.5399 - val_acc: 0.7882\n",
            "Epoch 55/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3758 - acc: 0.7989 - val_loss: 0.5680 - val_acc: 0.7817\n",
            "Epoch 56/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3808 - acc: 0.7955 - val_loss: 0.5886 - val_acc: 0.7932\n",
            "Epoch 57/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3709 - acc: 0.8014 - val_loss: 0.6190 - val_acc: 0.8020\n",
            "Epoch 58/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3763 - acc: 0.8020 - val_loss: 0.6212 - val_acc: 0.7692\n",
            "Epoch 59/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3763 - acc: 0.7989 - val_loss: 0.6240 - val_acc: 0.7958\n",
            "Epoch 60/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3720 - acc: 0.8021 - val_loss: 0.5671 - val_acc: 0.7764\n",
            "Epoch 61/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3708 - acc: 0.7997 - val_loss: 0.6112 - val_acc: 0.7803\n",
            "Epoch 62/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3734 - acc: 0.8056 - val_loss: 0.5749 - val_acc: 0.7956\n",
            "Epoch 63/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3689 - acc: 0.8069 - val_loss: 0.6015 - val_acc: 0.7894\n",
            "Epoch 64/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3705 - acc: 0.8064 - val_loss: 0.5750 - val_acc: 0.7873\n",
            "Epoch 65/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3697 - acc: 0.8042 - val_loss: 0.5812 - val_acc: 0.7928\n",
            "Epoch 66/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3665 - acc: 0.8062 - val_loss: 0.5973 - val_acc: 0.7906\n",
            "Epoch 67/80\n",
            "88410/88410 [==============================] - 4s 44us/step - loss: 0.3638 - acc: 0.8081 - val_loss: 0.6108 - val_acc: 0.7885\n",
            "Epoch 68/80\n",
            "88410/88410 [==============================] - 4s 45us/step - loss: 0.3688 - acc: 0.8039 - val_loss: 0.6199 - val_acc: 0.8067\n",
            "Epoch 69/80\n",
            "88410/88410 [==============================] - 4s 44us/step - loss: 0.3643 - acc: 0.8100 - val_loss: 0.6083 - val_acc: 0.7933\n",
            "Epoch 70/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3621 - acc: 0.8061 - val_loss: 0.6203 - val_acc: 0.8268\n",
            "Epoch 71/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3671 - acc: 0.8067 - val_loss: 0.6267 - val_acc: 0.7929\n",
            "Epoch 72/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3635 - acc: 0.8074 - val_loss: 0.6211 - val_acc: 0.8049\n",
            "Epoch 73/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3638 - acc: 0.8091 - val_loss: 0.6143 - val_acc: 0.7998\n",
            "Epoch 74/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3592 - acc: 0.8102 - val_loss: 0.5946 - val_acc: 0.8154\n",
            "Epoch 75/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3602 - acc: 0.8144 - val_loss: 0.5968 - val_acc: 0.8142\n",
            "Epoch 76/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3609 - acc: 0.8092 - val_loss: 0.6383 - val_acc: 0.8103\n",
            "Epoch 77/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3576 - acc: 0.8147 - val_loss: 0.6218 - val_acc: 0.8113\n",
            "Epoch 78/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3571 - acc: 0.8117 - val_loss: 0.6157 - val_acc: 0.8148\n",
            "Epoch 79/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3563 - acc: 0.8138 - val_loss: 0.6315 - val_acc: 0.8026\n",
            "Epoch 80/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3532 - acc: 0.8141 - val_loss: 0.6439 - val_acc: 0.8104\n",
            "14663/14663 [==============================] - 0s 12us/step\n",
            "Test loss: 33.05%\n",
            "Test accuracy: 84.26%\n",
            "14663/14663 [==============================] - 0s 17us/step\n",
            "\n",
            "FOLD: 3\n",
            "Train on 88410 samples, validate on 43546 samples\n",
            "Epoch 1/80\n",
            "88410/88410 [==============================] - 4s 49us/step - loss: 0.6169 - acc: 0.6269 - val_loss: 0.4578 - val_acc: 0.5866\n",
            "Epoch 2/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.5629 - acc: 0.6600 - val_loss: 0.4432 - val_acc: 0.6403\n",
            "Epoch 3/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5426 - acc: 0.6782 - val_loss: 0.4485 - val_acc: 0.6804\n",
            "Epoch 4/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5308 - acc: 0.6925 - val_loss: 0.4463 - val_acc: 0.6520\n",
            "Epoch 5/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5189 - acc: 0.6954 - val_loss: 0.4523 - val_acc: 0.7201\n",
            "Epoch 6/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5154 - acc: 0.7015 - val_loss: 0.4497 - val_acc: 0.6943\n",
            "Epoch 7/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5025 - acc: 0.7058 - val_loss: 0.4504 - val_acc: 0.7321\n",
            "Epoch 8/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.5029 - acc: 0.7098 - val_loss: 0.4399 - val_acc: 0.7515\n",
            "Epoch 9/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4952 - acc: 0.7153 - val_loss: 0.4461 - val_acc: 0.7157\n",
            "Epoch 10/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4907 - acc: 0.7170 - val_loss: 0.4438 - val_acc: 0.7390\n",
            "Epoch 11/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4856 - acc: 0.7217 - val_loss: 0.4524 - val_acc: 0.7643\n",
            "Epoch 12/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4847 - acc: 0.7284 - val_loss: 0.4460 - val_acc: 0.7931\n",
            "Epoch 13/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4808 - acc: 0.7310 - val_loss: 0.4524 - val_acc: 0.7802\n",
            "Epoch 14/80\n",
            "88410/88410 [==============================] - 4s 44us/step - loss: 0.4769 - acc: 0.7414 - val_loss: 0.4519 - val_acc: 0.7803\n",
            "Epoch 15/80\n",
            "88410/88410 [==============================] - 4s 45us/step - loss: 0.4693 - acc: 0.7368 - val_loss: 0.4687 - val_acc: 0.7861\n",
            "Epoch 16/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4694 - acc: 0.7419 - val_loss: 0.4654 - val_acc: 0.7583\n",
            "Epoch 17/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4672 - acc: 0.7418 - val_loss: 0.4747 - val_acc: 0.7482\n",
            "Epoch 18/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4629 - acc: 0.7416 - val_loss: 0.4660 - val_acc: 0.7840\n",
            "Epoch 19/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4591 - acc: 0.7541 - val_loss: 0.4707 - val_acc: 0.7647\n",
            "Epoch 20/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4523 - acc: 0.7546 - val_loss: 0.4762 - val_acc: 0.7575\n",
            "Epoch 21/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4529 - acc: 0.7483 - val_loss: 0.4821 - val_acc: 0.7677\n",
            "Epoch 22/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4465 - acc: 0.7578 - val_loss: 0.4652 - val_acc: 0.7573\n",
            "Epoch 23/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4434 - acc: 0.7621 - val_loss: 0.4701 - val_acc: 0.7714\n",
            "Epoch 24/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4362 - acc: 0.7650 - val_loss: 0.4946 - val_acc: 0.7645\n",
            "Epoch 25/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4414 - acc: 0.7602 - val_loss: 0.4794 - val_acc: 0.7452\n",
            "Epoch 26/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4324 - acc: 0.7685 - val_loss: 0.4849 - val_acc: 0.7502\n",
            "Epoch 27/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4335 - acc: 0.7656 - val_loss: 0.4721 - val_acc: 0.7625\n",
            "Epoch 28/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4242 - acc: 0.7695 - val_loss: 0.5011 - val_acc: 0.7651\n",
            "Epoch 29/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4279 - acc: 0.7672 - val_loss: 0.5140 - val_acc: 0.7607\n",
            "Epoch 30/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4272 - acc: 0.7696 - val_loss: 0.4970 - val_acc: 0.7698\n",
            "Epoch 31/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4209 - acc: 0.7696 - val_loss: 0.5120 - val_acc: 0.7770\n",
            "Epoch 32/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4224 - acc: 0.7729 - val_loss: 0.5150 - val_acc: 0.7695\n",
            "Epoch 33/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4181 - acc: 0.7774 - val_loss: 0.4983 - val_acc: 0.7664\n",
            "Epoch 34/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4128 - acc: 0.7761 - val_loss: 0.5049 - val_acc: 0.7889\n",
            "Epoch 35/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4094 - acc: 0.7806 - val_loss: 0.5291 - val_acc: 0.7780\n",
            "Epoch 36/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4087 - acc: 0.7793 - val_loss: 0.5124 - val_acc: 0.7953\n",
            "Epoch 37/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.4056 - acc: 0.7803 - val_loss: 0.5274 - val_acc: 0.7816\n",
            "Epoch 38/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4056 - acc: 0.7843 - val_loss: 0.5076 - val_acc: 0.7905\n",
            "Epoch 39/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4004 - acc: 0.7869 - val_loss: 0.5287 - val_acc: 0.7723\n",
            "Epoch 40/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4018 - acc: 0.7853 - val_loss: 0.5415 - val_acc: 0.7722\n",
            "Epoch 41/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.4058 - acc: 0.7811 - val_loss: 0.5450 - val_acc: 0.7753\n",
            "Epoch 42/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3974 - acc: 0.7878 - val_loss: 0.5289 - val_acc: 0.7913\n",
            "Epoch 43/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3979 - acc: 0.7882 - val_loss: 0.5575 - val_acc: 0.7974\n",
            "Epoch 44/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3920 - acc: 0.7931 - val_loss: 0.5264 - val_acc: 0.7997\n",
            "Epoch 45/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3948 - acc: 0.7883 - val_loss: 0.5419 - val_acc: 0.7953\n",
            "Epoch 46/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3892 - acc: 0.7941 - val_loss: 0.5332 - val_acc: 0.7926\n",
            "Epoch 47/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3907 - acc: 0.7894 - val_loss: 0.5493 - val_acc: 0.7950\n",
            "Epoch 48/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3909 - acc: 0.7919 - val_loss: 0.5513 - val_acc: 0.8047\n",
            "Epoch 49/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3864 - acc: 0.7950 - val_loss: 0.5706 - val_acc: 0.7803\n",
            "Epoch 50/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3831 - acc: 0.7948 - val_loss: 0.5649 - val_acc: 0.7837\n",
            "Epoch 51/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3862 - acc: 0.7935 - val_loss: 0.5805 - val_acc: 0.7885\n",
            "Epoch 52/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3828 - acc: 0.7940 - val_loss: 0.5664 - val_acc: 0.7946\n",
            "Epoch 53/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3773 - acc: 0.8049 - val_loss: 0.5726 - val_acc: 0.7830\n",
            "Epoch 54/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3784 - acc: 0.7959 - val_loss: 0.6006 - val_acc: 0.7778\n",
            "Epoch 55/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3729 - acc: 0.8026 - val_loss: 0.5837 - val_acc: 0.8067\n",
            "Epoch 56/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3715 - acc: 0.8038 - val_loss: 0.5846 - val_acc: 0.7967\n",
            "Epoch 57/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3741 - acc: 0.8032 - val_loss: 0.5884 - val_acc: 0.7937\n",
            "Epoch 58/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3750 - acc: 0.8020 - val_loss: 0.6070 - val_acc: 0.7981\n",
            "Epoch 59/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3767 - acc: 0.8010 - val_loss: 0.5912 - val_acc: 0.7962\n",
            "Epoch 60/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3697 - acc: 0.8059 - val_loss: 0.5847 - val_acc: 0.7940\n",
            "Epoch 61/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3709 - acc: 0.8056 - val_loss: 0.6067 - val_acc: 0.8013\n",
            "Epoch 62/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3737 - acc: 0.8016 - val_loss: 0.6037 - val_acc: 0.7974\n",
            "Epoch 63/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3625 - acc: 0.8089 - val_loss: 0.6101 - val_acc: 0.7983\n",
            "Epoch 64/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3684 - acc: 0.8059 - val_loss: 0.6252 - val_acc: 0.7841\n",
            "Epoch 65/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3696 - acc: 0.8026 - val_loss: 0.6193 - val_acc: 0.8048\n",
            "Epoch 66/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3595 - acc: 0.8122 - val_loss: 0.6443 - val_acc: 0.8259\n",
            "Epoch 67/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3586 - acc: 0.8138 - val_loss: 0.6303 - val_acc: 0.8103\n",
            "Epoch 68/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3630 - acc: 0.8089 - val_loss: 0.6363 - val_acc: 0.8058\n",
            "Epoch 69/80\n",
            "88410/88410 [==============================] - 4s 44us/step - loss: 0.3644 - acc: 0.8076 - val_loss: 0.6548 - val_acc: 0.8073\n",
            "Epoch 70/80\n",
            "88410/88410 [==============================] - 4s 44us/step - loss: 0.3652 - acc: 0.8072 - val_loss: 0.6166 - val_acc: 0.8041\n",
            "Epoch 71/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3628 - acc: 0.8074 - val_loss: 0.6225 - val_acc: 0.8133\n",
            "Epoch 72/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3608 - acc: 0.8103 - val_loss: 0.6225 - val_acc: 0.8033\n",
            "Epoch 73/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3621 - acc: 0.8122 - val_loss: 0.6558 - val_acc: 0.7954\n",
            "Epoch 74/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3610 - acc: 0.8060 - val_loss: 0.6675 - val_acc: 0.7972\n",
            "Epoch 75/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3632 - acc: 0.8084 - val_loss: 0.6748 - val_acc: 0.7828\n",
            "Epoch 76/80\n",
            "88410/88410 [==============================] - 4s 42us/step - loss: 0.3559 - acc: 0.8112 - val_loss: 0.6376 - val_acc: 0.7941\n",
            "Epoch 77/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3578 - acc: 0.8121 - val_loss: 0.6641 - val_acc: 0.7885\n",
            "Epoch 78/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3554 - acc: 0.8143 - val_loss: 0.6412 - val_acc: 0.7908\n",
            "Epoch 79/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3539 - acc: 0.8174 - val_loss: 0.6613 - val_acc: 0.7964\n",
            "Epoch 80/80\n",
            "88410/88410 [==============================] - 4s 43us/step - loss: 0.3557 - acc: 0.8128 - val_loss: 0.6931 - val_acc: 0.7967\n",
            "14663/14663 [==============================] - 0s 12us/step\n",
            "Test loss: 33.27%\n",
            "Test accuracy: 83.36%\n",
            "14663/14663 [==============================] - 0s 19us/step\n",
            "\n",
            "FOLD: 4\n",
            "Train on 88411 samples, validate on 43546 samples\n",
            "Epoch 1/80\n",
            "88411/88411 [==============================] - 5s 51us/step - loss: 0.6115 - acc: 0.6206 - val_loss: 0.4668 - val_acc: 0.5491\n",
            "Epoch 2/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5627 - acc: 0.6618 - val_loss: 0.4564 - val_acc: 0.6604\n",
            "Epoch 3/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5449 - acc: 0.6805 - val_loss: 0.4520 - val_acc: 0.6639\n",
            "Epoch 4/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5283 - acc: 0.6961 - val_loss: 0.4481 - val_acc: 0.7118\n",
            "Epoch 5/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5203 - acc: 0.6995 - val_loss: 0.4536 - val_acc: 0.7223\n",
            "Epoch 6/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5136 - acc: 0.7067 - val_loss: 0.4622 - val_acc: 0.6980\n",
            "Epoch 7/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5091 - acc: 0.7012 - val_loss: 0.4577 - val_acc: 0.7392\n",
            "Epoch 8/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4985 - acc: 0.7164 - val_loss: 0.4695 - val_acc: 0.7448\n",
            "Epoch 9/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4962 - acc: 0.7259 - val_loss: 0.4707 - val_acc: 0.7073\n",
            "Epoch 10/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4854 - acc: 0.7276 - val_loss: 0.4767 - val_acc: 0.7266\n",
            "Epoch 11/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4870 - acc: 0.7222 - val_loss: 0.4668 - val_acc: 0.7423\n",
            "Epoch 12/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4799 - acc: 0.7351 - val_loss: 0.4742 - val_acc: 0.7501\n",
            "Epoch 13/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4769 - acc: 0.7337 - val_loss: 0.4847 - val_acc: 0.7710\n",
            "Epoch 14/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4765 - acc: 0.7382 - val_loss: 0.4803 - val_acc: 0.7463\n",
            "Epoch 15/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4695 - acc: 0.7401 - val_loss: 0.5059 - val_acc: 0.7587\n",
            "Epoch 16/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4631 - acc: 0.7484 - val_loss: 0.5085 - val_acc: 0.7323\n",
            "Epoch 17/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4621 - acc: 0.7450 - val_loss: 0.4981 - val_acc: 0.7265\n",
            "Epoch 18/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4613 - acc: 0.7410 - val_loss: 0.4948 - val_acc: 0.7624\n",
            "Epoch 19/80\n",
            "88411/88411 [==============================] - 4s 42us/step - loss: 0.4533 - acc: 0.7560 - val_loss: 0.5025 - val_acc: 0.7677\n",
            "Epoch 20/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4526 - acc: 0.7523 - val_loss: 0.5238 - val_acc: 0.7826\n",
            "Epoch 21/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4499 - acc: 0.7629 - val_loss: 0.5229 - val_acc: 0.7228\n",
            "Epoch 22/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4424 - acc: 0.7611 - val_loss: 0.5123 - val_acc: 0.7710\n",
            "Epoch 23/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4459 - acc: 0.7661 - val_loss: 0.4972 - val_acc: 0.7559\n",
            "Epoch 24/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4453 - acc: 0.7583 - val_loss: 0.5117 - val_acc: 0.7453\n",
            "Epoch 25/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4345 - acc: 0.7671 - val_loss: 0.5057 - val_acc: 0.8119\n",
            "Epoch 26/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4317 - acc: 0.7729 - val_loss: 0.5245 - val_acc: 0.7800\n",
            "Epoch 27/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4347 - acc: 0.7686 - val_loss: 0.5236 - val_acc: 0.7910\n",
            "Epoch 28/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4276 - acc: 0.7716 - val_loss: 0.5315 - val_acc: 0.7889\n",
            "Epoch 29/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4253 - acc: 0.7770 - val_loss: 0.5381 - val_acc: 0.8143\n",
            "Epoch 30/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4210 - acc: 0.7762 - val_loss: 0.5191 - val_acc: 0.8062\n",
            "Epoch 31/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4179 - acc: 0.7821 - val_loss: 0.5399 - val_acc: 0.7959\n",
            "Epoch 32/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4116 - acc: 0.7875 - val_loss: 0.5680 - val_acc: 0.7865\n",
            "Epoch 33/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4182 - acc: 0.7798 - val_loss: 0.5412 - val_acc: 0.7891\n",
            "Epoch 34/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4153 - acc: 0.7848 - val_loss: 0.5380 - val_acc: 0.8014\n",
            "Epoch 35/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4101 - acc: 0.7878 - val_loss: 0.5129 - val_acc: 0.8114\n",
            "Epoch 36/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4082 - acc: 0.7867 - val_loss: 0.5415 - val_acc: 0.8020\n",
            "Epoch 37/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4029 - acc: 0.7886 - val_loss: 0.5737 - val_acc: 0.8067\n",
            "Epoch 38/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4004 - acc: 0.7890 - val_loss: 0.5673 - val_acc: 0.7956\n",
            "Epoch 39/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4035 - acc: 0.7880 - val_loss: 0.5464 - val_acc: 0.7973\n",
            "Epoch 40/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3986 - acc: 0.7900 - val_loss: 0.5457 - val_acc: 0.8102\n",
            "Epoch 41/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3966 - acc: 0.7932 - val_loss: 0.5809 - val_acc: 0.7973\n",
            "Epoch 42/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3937 - acc: 0.7934 - val_loss: 0.5589 - val_acc: 0.8195\n",
            "Epoch 43/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3945 - acc: 0.7954 - val_loss: 0.5768 - val_acc: 0.8219\n",
            "Epoch 44/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3891 - acc: 0.7994 - val_loss: 0.5815 - val_acc: 0.8087\n",
            "Epoch 45/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3919 - acc: 0.7950 - val_loss: 0.5741 - val_acc: 0.8380\n",
            "Epoch 46/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3840 - acc: 0.8007 - val_loss: 0.6077 - val_acc: 0.8205\n",
            "Epoch 47/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3846 - acc: 0.7987 - val_loss: 0.5560 - val_acc: 0.8155\n",
            "Epoch 48/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3921 - acc: 0.7955 - val_loss: 0.5638 - val_acc: 0.8358\n",
            "Epoch 49/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3812 - acc: 0.8023 - val_loss: 0.5782 - val_acc: 0.8247\n",
            "Epoch 50/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3799 - acc: 0.8050 - val_loss: 0.5744 - val_acc: 0.8087\n",
            "Epoch 51/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3764 - acc: 0.8023 - val_loss: 0.5754 - val_acc: 0.8230\n",
            "Epoch 52/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3751 - acc: 0.8036 - val_loss: 0.6354 - val_acc: 0.8352\n",
            "Epoch 53/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3816 - acc: 0.8035 - val_loss: 0.5691 - val_acc: 0.8365\n",
            "Epoch 54/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3721 - acc: 0.8105 - val_loss: 0.5921 - val_acc: 0.8009\n",
            "Epoch 55/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3722 - acc: 0.8055 - val_loss: 0.6118 - val_acc: 0.8201\n",
            "Epoch 56/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3755 - acc: 0.8042 - val_loss: 0.6157 - val_acc: 0.8369\n",
            "Epoch 57/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3745 - acc: 0.8080 - val_loss: 0.5876 - val_acc: 0.8367\n",
            "Epoch 58/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3690 - acc: 0.8086 - val_loss: 0.6168 - val_acc: 0.8478\n",
            "Epoch 59/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3742 - acc: 0.8075 - val_loss: 0.5984 - val_acc: 0.8214\n",
            "Epoch 60/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3700 - acc: 0.8101 - val_loss: 0.6056 - val_acc: 0.8174\n",
            "Epoch 61/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3689 - acc: 0.8091 - val_loss: 0.6178 - val_acc: 0.8185\n",
            "Epoch 62/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3676 - acc: 0.8107 - val_loss: 0.6500 - val_acc: 0.8182\n",
            "Epoch 63/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3662 - acc: 0.8137 - val_loss: 0.6221 - val_acc: 0.8149\n",
            "Epoch 64/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3697 - acc: 0.8123 - val_loss: 0.6098 - val_acc: 0.8222\n",
            "Epoch 65/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3743 - acc: 0.8077 - val_loss: 0.5766 - val_acc: 0.8238\n",
            "Epoch 66/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3599 - acc: 0.8146 - val_loss: 0.5870 - val_acc: 0.8344\n",
            "Epoch 67/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3628 - acc: 0.8190 - val_loss: 0.5741 - val_acc: 0.8161\n",
            "Epoch 68/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3638 - acc: 0.8132 - val_loss: 0.6143 - val_acc: 0.8349\n",
            "Epoch 69/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3593 - acc: 0.8153 - val_loss: 0.6122 - val_acc: 0.8514\n",
            "Epoch 70/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3565 - acc: 0.8182 - val_loss: 0.6316 - val_acc: 0.8242\n",
            "Epoch 71/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3575 - acc: 0.8178 - val_loss: 0.6657 - val_acc: 0.8324\n",
            "Epoch 72/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3595 - acc: 0.8179 - val_loss: 0.6488 - val_acc: 0.8440\n",
            "Epoch 73/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3598 - acc: 0.8161 - val_loss: 0.6051 - val_acc: 0.8302\n",
            "Epoch 74/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3526 - acc: 0.8214 - val_loss: 0.6299 - val_acc: 0.8144\n",
            "Epoch 75/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3564 - acc: 0.8168 - val_loss: 0.6368 - val_acc: 0.8291\n",
            "Epoch 76/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3541 - acc: 0.8206 - val_loss: 0.6304 - val_acc: 0.8276\n",
            "Epoch 77/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3523 - acc: 0.8202 - val_loss: 0.6160 - val_acc: 0.8349\n",
            "Epoch 78/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3576 - acc: 0.8174 - val_loss: 0.6021 - val_acc: 0.8196\n",
            "Epoch 79/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3493 - acc: 0.8223 - val_loss: 0.5892 - val_acc: 0.8201\n",
            "Epoch 80/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3489 - acc: 0.8232 - val_loss: 0.6176 - val_acc: 0.8490\n",
            "14662/14662 [==============================] - 0s 13us/step\n",
            "Test loss: 28.41%\n",
            "Test accuracy: 87.63%\n",
            "14662/14662 [==============================] - 0s 22us/step\n",
            "\n",
            "FOLD: 5\n",
            "Train on 88411 samples, validate on 43546 samples\n",
            "Epoch 1/80\n",
            "88411/88411 [==============================] - 5s 51us/step - loss: 0.6110 - acc: 0.6289 - val_loss: 0.4501 - val_acc: 0.6348\n",
            "Epoch 2/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5584 - acc: 0.6841 - val_loss: 0.4444 - val_acc: 0.6643\n",
            "Epoch 3/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5436 - acc: 0.6838 - val_loss: 0.4319 - val_acc: 0.7116\n",
            "Epoch 4/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5241 - acc: 0.7004 - val_loss: 0.4486 - val_acc: 0.6848\n",
            "Epoch 5/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5224 - acc: 0.7015 - val_loss: 0.4343 - val_acc: 0.7107\n",
            "Epoch 6/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.5120 - acc: 0.7092 - val_loss: 0.4361 - val_acc: 0.7493\n",
            "Epoch 7/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5068 - acc: 0.7163 - val_loss: 0.4384 - val_acc: 0.7508\n",
            "Epoch 8/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4992 - acc: 0.7226 - val_loss: 0.4525 - val_acc: 0.7163\n",
            "Epoch 9/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4987 - acc: 0.7183 - val_loss: 0.4449 - val_acc: 0.7566\n",
            "Epoch 10/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4901 - acc: 0.7309 - val_loss: 0.4608 - val_acc: 0.7274\n",
            "Epoch 11/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4845 - acc: 0.7350 - val_loss: 0.4597 - val_acc: 0.7546\n",
            "Epoch 12/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4834 - acc: 0.7309 - val_loss: 0.4436 - val_acc: 0.7469\n",
            "Epoch 13/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4788 - acc: 0.7398 - val_loss: 0.4614 - val_acc: 0.7406\n",
            "Epoch 14/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4720 - acc: 0.7481 - val_loss: 0.4841 - val_acc: 0.7245\n",
            "Epoch 15/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4676 - acc: 0.7459 - val_loss: 0.4784 - val_acc: 0.7936\n",
            "Epoch 16/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4718 - acc: 0.7521 - val_loss: 0.4710 - val_acc: 0.7629\n",
            "Epoch 17/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4622 - acc: 0.7522 - val_loss: 0.4689 - val_acc: 0.7879\n",
            "Epoch 18/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4635 - acc: 0.7581 - val_loss: 0.4736 - val_acc: 0.7163\n",
            "Epoch 19/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4554 - acc: 0.7549 - val_loss: 0.4877 - val_acc: 0.7673\n",
            "Epoch 20/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4498 - acc: 0.7610 - val_loss: 0.4715 - val_acc: 0.7687\n",
            "Epoch 21/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4484 - acc: 0.7596 - val_loss: 0.4844 - val_acc: 0.7902\n",
            "Epoch 22/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4473 - acc: 0.7616 - val_loss: 0.4854 - val_acc: 0.7820\n",
            "Epoch 23/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4454 - acc: 0.7647 - val_loss: 0.4738 - val_acc: 0.7784\n",
            "Epoch 24/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4410 - acc: 0.7679 - val_loss: 0.4927 - val_acc: 0.7853\n",
            "Epoch 25/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4396 - acc: 0.7679 - val_loss: 0.4975 - val_acc: 0.7951\n",
            "Epoch 26/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4353 - acc: 0.7693 - val_loss: 0.5091 - val_acc: 0.8103\n",
            "Epoch 27/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4310 - acc: 0.7740 - val_loss: 0.4933 - val_acc: 0.7909\n",
            "Epoch 28/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4331 - acc: 0.7731 - val_loss: 0.4910 - val_acc: 0.8015\n",
            "Epoch 29/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4240 - acc: 0.7806 - val_loss: 0.5020 - val_acc: 0.7773\n",
            "Epoch 30/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4259 - acc: 0.7765 - val_loss: 0.4943 - val_acc: 0.7970\n",
            "Epoch 31/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4220 - acc: 0.7768 - val_loss: 0.5374 - val_acc: 0.7905\n",
            "Epoch 32/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4194 - acc: 0.7772 - val_loss: 0.5284 - val_acc: 0.7748\n",
            "Epoch 33/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4170 - acc: 0.7789 - val_loss: 0.5103 - val_acc: 0.7846\n",
            "Epoch 34/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4058 - acc: 0.7840 - val_loss: 0.5429 - val_acc: 0.8020\n",
            "Epoch 35/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4110 - acc: 0.7817 - val_loss: 0.5291 - val_acc: 0.7761\n",
            "Epoch 36/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4097 - acc: 0.7848 - val_loss: 0.5293 - val_acc: 0.7976\n",
            "Epoch 37/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4068 - acc: 0.7852 - val_loss: 0.5251 - val_acc: 0.7963\n",
            "Epoch 38/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4092 - acc: 0.7853 - val_loss: 0.5356 - val_acc: 0.7970\n",
            "Epoch 39/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.4037 - acc: 0.7906 - val_loss: 0.5180 - val_acc: 0.7966\n",
            "Epoch 40/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4031 - acc: 0.7902 - val_loss: 0.5180 - val_acc: 0.7769\n",
            "Epoch 41/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3958 - acc: 0.7920 - val_loss: 0.5439 - val_acc: 0.8035\n",
            "Epoch 42/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3933 - acc: 0.7906 - val_loss: 0.5550 - val_acc: 0.8130\n",
            "Epoch 43/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3999 - acc: 0.7934 - val_loss: 0.5178 - val_acc: 0.7832\n",
            "Epoch 44/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3920 - acc: 0.7917 - val_loss: 0.5289 - val_acc: 0.8195\n",
            "Epoch 45/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3882 - acc: 0.7973 - val_loss: 0.5322 - val_acc: 0.8126\n",
            "Epoch 46/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3886 - acc: 0.7916 - val_loss: 0.5327 - val_acc: 0.8218\n",
            "Epoch 47/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3835 - acc: 0.8014 - val_loss: 0.5433 - val_acc: 0.8034\n",
            "Epoch 48/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3852 - acc: 0.7935 - val_loss: 0.5387 - val_acc: 0.8365\n",
            "Epoch 49/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3832 - acc: 0.8010 - val_loss: 0.5708 - val_acc: 0.8117\n",
            "Epoch 50/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3858 - acc: 0.7978 - val_loss: 0.5519 - val_acc: 0.7909\n",
            "Epoch 51/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3857 - acc: 0.7988 - val_loss: 0.5629 - val_acc: 0.7869\n",
            "Epoch 52/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3792 - acc: 0.8003 - val_loss: 0.5627 - val_acc: 0.7931\n",
            "Epoch 53/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3792 - acc: 0.8021 - val_loss: 0.5593 - val_acc: 0.8029\n",
            "Epoch 54/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3762 - acc: 0.8041 - val_loss: 0.5557 - val_acc: 0.8223\n",
            "Epoch 55/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3772 - acc: 0.8002 - val_loss: 0.5531 - val_acc: 0.8176\n",
            "Epoch 56/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3778 - acc: 0.8058 - val_loss: 0.5587 - val_acc: 0.8238\n",
            "Epoch 57/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3754 - acc: 0.8082 - val_loss: 0.5832 - val_acc: 0.8219\n",
            "Epoch 58/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3771 - acc: 0.8042 - val_loss: 0.5628 - val_acc: 0.8195\n",
            "Epoch 59/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3720 - acc: 0.8051 - val_loss: 0.5743 - val_acc: 0.8188\n",
            "Epoch 60/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3635 - acc: 0.8113 - val_loss: 0.5692 - val_acc: 0.8072\n",
            "Epoch 61/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3652 - acc: 0.8089 - val_loss: 0.5710 - val_acc: 0.8074\n",
            "Epoch 62/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3616 - acc: 0.8091 - val_loss: 0.6080 - val_acc: 0.8225\n",
            "Epoch 63/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3673 - acc: 0.8091 - val_loss: 0.6034 - val_acc: 0.8151\n",
            "Epoch 64/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3691 - acc: 0.8082 - val_loss: 0.5789 - val_acc: 0.8187\n",
            "Epoch 65/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3703 - acc: 0.8086 - val_loss: 0.5739 - val_acc: 0.8132\n",
            "Epoch 66/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3564 - acc: 0.8145 - val_loss: 0.5944 - val_acc: 0.8236\n",
            "Epoch 67/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3642 - acc: 0.8127 - val_loss: 0.6116 - val_acc: 0.8170\n",
            "Epoch 68/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3621 - acc: 0.8115 - val_loss: 0.6161 - val_acc: 0.8391\n",
            "Epoch 69/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3585 - acc: 0.8159 - val_loss: 0.5735 - val_acc: 0.8179\n",
            "Epoch 70/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3555 - acc: 0.8172 - val_loss: 0.6065 - val_acc: 0.8249\n",
            "Epoch 71/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3583 - acc: 0.8164 - val_loss: 0.5885 - val_acc: 0.8091\n",
            "Epoch 72/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3538 - acc: 0.8136 - val_loss: 0.5801 - val_acc: 0.8340\n",
            "Epoch 73/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3554 - acc: 0.8159 - val_loss: 0.5947 - val_acc: 0.8220\n",
            "Epoch 74/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3545 - acc: 0.8155 - val_loss: 0.6112 - val_acc: 0.8178\n",
            "Epoch 75/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3530 - acc: 0.8201 - val_loss: 0.6104 - val_acc: 0.8372\n",
            "Epoch 76/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3492 - acc: 0.8199 - val_loss: 0.6464 - val_acc: 0.8257\n",
            "Epoch 77/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3554 - acc: 0.8209 - val_loss: 0.6172 - val_acc: 0.8010\n",
            "Epoch 78/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3550 - acc: 0.8170 - val_loss: 0.6026 - val_acc: 0.8267\n",
            "Epoch 79/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3493 - acc: 0.8203 - val_loss: 0.6171 - val_acc: 0.8258\n",
            "Epoch 80/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3540 - acc: 0.8188 - val_loss: 0.6165 - val_acc: 0.8080\n",
            "14662/14662 [==============================] - 0s 13us/step\n",
            "Test loss: 31.41%\n",
            "Test accuracy: 84.44%\n",
            "14662/14662 [==============================] - 0s 26us/step\n",
            "\n",
            "FOLD: 6\n",
            "Train on 88411 samples, validate on 43546 samples\n",
            "Epoch 1/80\n",
            "88411/88411 [==============================] - 5s 54us/step - loss: 0.6152 - acc: 0.6175 - val_loss: 0.4664 - val_acc: 0.5785\n",
            "Epoch 2/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5654 - acc: 0.6761 - val_loss: 0.4525 - val_acc: 0.6390\n",
            "Epoch 3/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5462 - acc: 0.6900 - val_loss: 0.4384 - val_acc: 0.6981\n",
            "Epoch 4/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5336 - acc: 0.6972 - val_loss: 0.4430 - val_acc: 0.6491\n",
            "Epoch 5/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5239 - acc: 0.6978 - val_loss: 0.4318 - val_acc: 0.7051\n",
            "Epoch 6/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5137 - acc: 0.7078 - val_loss: 0.4355 - val_acc: 0.6861\n",
            "Epoch 7/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5093 - acc: 0.7050 - val_loss: 0.4308 - val_acc: 0.6949\n",
            "Epoch 8/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4995 - acc: 0.7085 - val_loss: 0.4361 - val_acc: 0.7251\n",
            "Epoch 9/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4947 - acc: 0.7140 - val_loss: 0.4474 - val_acc: 0.6949\n",
            "Epoch 10/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4918 - acc: 0.7194 - val_loss: 0.4439 - val_acc: 0.7292\n",
            "Epoch 11/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4867 - acc: 0.7206 - val_loss: 0.4579 - val_acc: 0.7231\n",
            "Epoch 12/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4870 - acc: 0.7199 - val_loss: 0.4426 - val_acc: 0.7408\n",
            "Epoch 13/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4788 - acc: 0.7271 - val_loss: 0.4546 - val_acc: 0.7454\n",
            "Epoch 14/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4737 - acc: 0.7381 - val_loss: 0.4696 - val_acc: 0.7424\n",
            "Epoch 15/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4739 - acc: 0.7323 - val_loss: 0.4616 - val_acc: 0.7529\n",
            "Epoch 16/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4696 - acc: 0.7390 - val_loss: 0.4665 - val_acc: 0.7263\n",
            "Epoch 17/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4631 - acc: 0.7419 - val_loss: 0.4489 - val_acc: 0.7631\n",
            "Epoch 18/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4579 - acc: 0.7406 - val_loss: 0.4660 - val_acc: 0.7617\n",
            "Epoch 19/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4516 - acc: 0.7479 - val_loss: 0.4623 - val_acc: 0.7870\n",
            "Epoch 20/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4535 - acc: 0.7473 - val_loss: 0.4764 - val_acc: 0.7788\n",
            "Epoch 21/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4493 - acc: 0.7521 - val_loss: 0.4776 - val_acc: 0.7808\n",
            "Epoch 22/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4479 - acc: 0.7547 - val_loss: 0.4832 - val_acc: 0.7878\n",
            "Epoch 23/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4425 - acc: 0.7585 - val_loss: 0.5061 - val_acc: 0.7930\n",
            "Epoch 24/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4400 - acc: 0.7613 - val_loss: 0.4965 - val_acc: 0.8091\n",
            "Epoch 25/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4302 - acc: 0.7706 - val_loss: 0.5056 - val_acc: 0.8002\n",
            "Epoch 26/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4331 - acc: 0.7633 - val_loss: 0.5197 - val_acc: 0.8136\n",
            "Epoch 27/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4309 - acc: 0.7667 - val_loss: 0.5203 - val_acc: 0.8091\n",
            "Epoch 28/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4252 - acc: 0.7703 - val_loss: 0.5235 - val_acc: 0.8215\n",
            "Epoch 29/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4263 - acc: 0.7744 - val_loss: 0.5158 - val_acc: 0.8272\n",
            "Epoch 30/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4230 - acc: 0.7706 - val_loss: 0.5324 - val_acc: 0.7906\n",
            "Epoch 31/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4196 - acc: 0.7745 - val_loss: 0.5287 - val_acc: 0.8382\n",
            "Epoch 32/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4170 - acc: 0.7786 - val_loss: 0.5364 - val_acc: 0.8301\n",
            "Epoch 33/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4108 - acc: 0.7861 - val_loss: 0.5327 - val_acc: 0.8441\n",
            "Epoch 34/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4142 - acc: 0.7867 - val_loss: 0.5400 - val_acc: 0.7915\n",
            "Epoch 35/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4096 - acc: 0.7842 - val_loss: 0.5622 - val_acc: 0.8246\n",
            "Epoch 36/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4036 - acc: 0.7884 - val_loss: 0.5373 - val_acc: 0.8213\n",
            "Epoch 37/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4013 - acc: 0.7908 - val_loss: 0.5237 - val_acc: 0.8284\n",
            "Epoch 38/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3996 - acc: 0.7944 - val_loss: 0.5485 - val_acc: 0.8294\n",
            "Epoch 39/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4008 - acc: 0.7933 - val_loss: 0.5766 - val_acc: 0.8204\n",
            "Epoch 40/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4013 - acc: 0.7956 - val_loss: 0.5085 - val_acc: 0.8265\n",
            "Epoch 41/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4005 - acc: 0.7921 - val_loss: 0.5291 - val_acc: 0.8326\n",
            "Epoch 42/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3871 - acc: 0.7995 - val_loss: 0.5777 - val_acc: 0.8224\n",
            "Epoch 43/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3894 - acc: 0.7966 - val_loss: 0.5588 - val_acc: 0.8228\n",
            "Epoch 44/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3885 - acc: 0.7968 - val_loss: 0.5808 - val_acc: 0.8429\n",
            "Epoch 45/80\n",
            "88411/88411 [==============================] - 4s 43us/step - loss: 0.3882 - acc: 0.8002 - val_loss: 0.5758 - val_acc: 0.8452\n",
            "Epoch 46/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3877 - acc: 0.7976 - val_loss: 0.5703 - val_acc: 0.8512\n",
            "Epoch 47/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3790 - acc: 0.8067 - val_loss: 0.6188 - val_acc: 0.8431\n",
            "Epoch 48/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3816 - acc: 0.8058 - val_loss: 0.5716 - val_acc: 0.8592\n",
            "Epoch 49/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3802 - acc: 0.8059 - val_loss: 0.6140 - val_acc: 0.8477\n",
            "Epoch 50/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3827 - acc: 0.8045 - val_loss: 0.6089 - val_acc: 0.8321\n",
            "Epoch 51/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3722 - acc: 0.8084 - val_loss: 0.6117 - val_acc: 0.8331\n",
            "Epoch 52/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3719 - acc: 0.8107 - val_loss: 0.6624 - val_acc: 0.8294\n",
            "Epoch 53/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3788 - acc: 0.8059 - val_loss: 0.6104 - val_acc: 0.8455\n",
            "Epoch 54/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3690 - acc: 0.8117 - val_loss: 0.6157 - val_acc: 0.8412\n",
            "Epoch 55/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3725 - acc: 0.8118 - val_loss: 0.5715 - val_acc: 0.8344\n",
            "Epoch 56/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3696 - acc: 0.8108 - val_loss: 0.5906 - val_acc: 0.8463\n",
            "Epoch 57/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3690 - acc: 0.8100 - val_loss: 0.6044 - val_acc: 0.8437\n",
            "Epoch 58/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3719 - acc: 0.8122 - val_loss: 0.5906 - val_acc: 0.8520\n",
            "Epoch 59/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3675 - acc: 0.8133 - val_loss: 0.5930 - val_acc: 0.8536\n",
            "Epoch 60/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3655 - acc: 0.8148 - val_loss: 0.6279 - val_acc: 0.8439\n",
            "Epoch 61/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3621 - acc: 0.8165 - val_loss: 0.6241 - val_acc: 0.8355\n",
            "Epoch 62/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3629 - acc: 0.8147 - val_loss: 0.6348 - val_acc: 0.8384\n",
            "Epoch 63/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3579 - acc: 0.8184 - val_loss: 0.6331 - val_acc: 0.8404\n",
            "Epoch 64/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3584 - acc: 0.8188 - val_loss: 0.6529 - val_acc: 0.8488\n",
            "Epoch 65/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3527 - acc: 0.8220 - val_loss: 0.6552 - val_acc: 0.8466\n",
            "Epoch 66/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3571 - acc: 0.8200 - val_loss: 0.6619 - val_acc: 0.8466\n",
            "Epoch 67/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3560 - acc: 0.8172 - val_loss: 0.7002 - val_acc: 0.8461\n",
            "Epoch 68/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3587 - acc: 0.8159 - val_loss: 0.6849 - val_acc: 0.8482\n",
            "Epoch 69/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3569 - acc: 0.8176 - val_loss: 0.6365 - val_acc: 0.8480\n",
            "Epoch 70/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3478 - acc: 0.8241 - val_loss: 0.6732 - val_acc: 0.8570\n",
            "Epoch 71/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3494 - acc: 0.8217 - val_loss: 0.6643 - val_acc: 0.8683\n",
            "Epoch 72/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3541 - acc: 0.8223 - val_loss: 0.6358 - val_acc: 0.8531\n",
            "Epoch 73/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3511 - acc: 0.8233 - val_loss: 0.6223 - val_acc: 0.8541\n",
            "Epoch 74/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3524 - acc: 0.8219 - val_loss: 0.6298 - val_acc: 0.8576\n",
            "Epoch 75/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3527 - acc: 0.8226 - val_loss: 0.6111 - val_acc: 0.8605\n",
            "Epoch 76/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3432 - acc: 0.8272 - val_loss: 0.6238 - val_acc: 0.8702\n",
            "Epoch 77/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3490 - acc: 0.8258 - val_loss: 0.6262 - val_acc: 0.8604\n",
            "Epoch 78/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3476 - acc: 0.8231 - val_loss: 0.6266 - val_acc: 0.8678\n",
            "Epoch 79/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3391 - acc: 0.8291 - val_loss: 0.6750 - val_acc: 0.8463\n",
            "Epoch 80/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3411 - acc: 0.8263 - val_loss: 0.6745 - val_acc: 0.8683\n",
            "14662/14662 [==============================] - 0s 13us/step\n",
            "Test loss: 24.87%\n",
            "Test accuracy: 89.67%\n",
            "14662/14662 [==============================] - 0s 28us/step\n",
            "\n",
            "FOLD: 7\n",
            "Train on 88411 samples, validate on 43547 samples\n",
            "Epoch 1/80\n",
            "88411/88411 [==============================] - 5s 56us/step - loss: 0.6169 - acc: 0.6000 - val_loss: 0.4531 - val_acc: 0.5607\n",
            "Epoch 2/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5654 - acc: 0.6607 - val_loss: 0.4314 - val_acc: 0.6752\n",
            "Epoch 3/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5451 - acc: 0.6875 - val_loss: 0.4161 - val_acc: 0.7079\n",
            "Epoch 4/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5303 - acc: 0.6929 - val_loss: 0.4281 - val_acc: 0.6988\n",
            "Epoch 5/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5195 - acc: 0.6925 - val_loss: 0.4266 - val_acc: 0.7444\n",
            "Epoch 6/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5158 - acc: 0.7054 - val_loss: 0.4260 - val_acc: 0.7325\n",
            "Epoch 7/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5054 - acc: 0.7091 - val_loss: 0.4328 - val_acc: 0.7484\n",
            "Epoch 8/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.5010 - acc: 0.7067 - val_loss: 0.4266 - val_acc: 0.7838\n",
            "Epoch 9/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4947 - acc: 0.7145 - val_loss: 0.4489 - val_acc: 0.7713\n",
            "Epoch 10/80\n",
            "88411/88411 [==============================] - 4s 47us/step - loss: 0.4923 - acc: 0.7148 - val_loss: 0.4382 - val_acc: 0.7735\n",
            "Epoch 11/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4883 - acc: 0.7238 - val_loss: 0.4571 - val_acc: 0.7627\n",
            "Epoch 12/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4842 - acc: 0.7287 - val_loss: 0.4501 - val_acc: 0.7639\n",
            "Epoch 13/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4825 - acc: 0.7259 - val_loss: 0.4496 - val_acc: 0.7730\n",
            "Epoch 14/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4766 - acc: 0.7317 - val_loss: 0.4629 - val_acc: 0.7795\n",
            "Epoch 15/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4744 - acc: 0.7361 - val_loss: 0.4706 - val_acc: 0.7804\n",
            "Epoch 16/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4735 - acc: 0.7383 - val_loss: 0.4687 - val_acc: 0.7906\n",
            "Epoch 17/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4662 - acc: 0.7457 - val_loss: 0.4757 - val_acc: 0.7905\n",
            "Epoch 18/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4645 - acc: 0.7444 - val_loss: 0.4739 - val_acc: 0.7987\n",
            "Epoch 19/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4593 - acc: 0.7515 - val_loss: 0.4765 - val_acc: 0.8144\n",
            "Epoch 20/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4576 - acc: 0.7525 - val_loss: 0.4975 - val_acc: 0.8049\n",
            "Epoch 21/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4517 - acc: 0.7577 - val_loss: 0.4712 - val_acc: 0.8190\n",
            "Epoch 22/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4509 - acc: 0.7552 - val_loss: 0.4937 - val_acc: 0.8146\n",
            "Epoch 23/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4475 - acc: 0.7568 - val_loss: 0.4847 - val_acc: 0.8125\n",
            "Epoch 24/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4474 - acc: 0.7530 - val_loss: 0.4862 - val_acc: 0.8429\n",
            "Epoch 25/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4399 - acc: 0.7683 - val_loss: 0.4846 - val_acc: 0.7819\n",
            "Epoch 26/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4408 - acc: 0.7603 - val_loss: 0.4894 - val_acc: 0.8304\n",
            "Epoch 27/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4377 - acc: 0.7686 - val_loss: 0.4998 - val_acc: 0.7978\n",
            "Epoch 28/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4336 - acc: 0.7640 - val_loss: 0.4887 - val_acc: 0.8146\n",
            "Epoch 29/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4313 - acc: 0.7667 - val_loss: 0.4799 - val_acc: 0.8256\n",
            "Epoch 30/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4310 - acc: 0.7689 - val_loss: 0.4941 - val_acc: 0.8254\n",
            "Epoch 31/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4249 - acc: 0.7696 - val_loss: 0.5021 - val_acc: 0.8303\n",
            "Epoch 32/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4260 - acc: 0.7766 - val_loss: 0.5076 - val_acc: 0.8298\n",
            "Epoch 33/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4196 - acc: 0.7783 - val_loss: 0.5120 - val_acc: 0.8258\n",
            "Epoch 34/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4178 - acc: 0.7764 - val_loss: 0.5151 - val_acc: 0.8520\n",
            "Epoch 35/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4148 - acc: 0.7800 - val_loss: 0.5350 - val_acc: 0.8262\n",
            "Epoch 36/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4126 - acc: 0.7774 - val_loss: 0.5144 - val_acc: 0.8339\n",
            "Epoch 37/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4131 - acc: 0.7772 - val_loss: 0.5166 - val_acc: 0.8404\n",
            "Epoch 38/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4069 - acc: 0.7786 - val_loss: 0.5111 - val_acc: 0.8372\n",
            "Epoch 39/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4093 - acc: 0.7803 - val_loss: 0.5316 - val_acc: 0.8435\n",
            "Epoch 40/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3994 - acc: 0.7859 - val_loss: 0.5363 - val_acc: 0.8311\n",
            "Epoch 41/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4072 - acc: 0.7769 - val_loss: 0.5284 - val_acc: 0.8328\n",
            "Epoch 42/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3938 - acc: 0.7863 - val_loss: 0.5312 - val_acc: 0.8511\n",
            "Epoch 43/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4015 - acc: 0.7855 - val_loss: 0.5453 - val_acc: 0.8307\n",
            "Epoch 44/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4004 - acc: 0.7852 - val_loss: 0.5427 - val_acc: 0.8492\n",
            "Epoch 45/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3922 - acc: 0.7885 - val_loss: 0.5464 - val_acc: 0.8453\n",
            "Epoch 46/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3896 - acc: 0.7918 - val_loss: 0.5557 - val_acc: 0.8429\n",
            "Epoch 47/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3910 - acc: 0.7919 - val_loss: 0.5618 - val_acc: 0.8314\n",
            "Epoch 48/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3899 - acc: 0.7911 - val_loss: 0.5633 - val_acc: 0.8274\n",
            "Epoch 49/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3847 - acc: 0.7959 - val_loss: 0.5916 - val_acc: 0.8492\n",
            "Epoch 50/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3874 - acc: 0.7947 - val_loss: 0.5351 - val_acc: 0.8493\n",
            "Epoch 51/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3863 - acc: 0.7932 - val_loss: 0.5441 - val_acc: 0.8387\n",
            "Epoch 52/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3867 - acc: 0.7929 - val_loss: 0.5302 - val_acc: 0.8518\n",
            "Epoch 53/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3791 - acc: 0.7981 - val_loss: 0.5590 - val_acc: 0.8362\n",
            "Epoch 54/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3773 - acc: 0.7993 - val_loss: 0.5830 - val_acc: 0.8441\n",
            "Epoch 55/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3800 - acc: 0.7977 - val_loss: 0.5957 - val_acc: 0.8505\n",
            "Epoch 56/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3752 - acc: 0.8003 - val_loss: 0.5867 - val_acc: 0.8551\n",
            "Epoch 57/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3743 - acc: 0.8022 - val_loss: 0.5686 - val_acc: 0.8593\n",
            "Epoch 58/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3764 - acc: 0.8007 - val_loss: 0.5714 - val_acc: 0.8566\n",
            "Epoch 59/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3727 - acc: 0.8045 - val_loss: 0.5943 - val_acc: 0.8465\n",
            "Epoch 60/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3779 - acc: 0.8010 - val_loss: 0.5662 - val_acc: 0.8551\n",
            "Epoch 61/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3736 - acc: 0.8030 - val_loss: 0.5320 - val_acc: 0.8567\n",
            "Epoch 62/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3695 - acc: 0.8038 - val_loss: 0.5687 - val_acc: 0.8715\n",
            "Epoch 63/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3656 - acc: 0.8097 - val_loss: 0.5879 - val_acc: 0.8722\n",
            "Epoch 64/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3700 - acc: 0.8063 - val_loss: 0.5874 - val_acc: 0.8593\n",
            "Epoch 65/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3719 - acc: 0.8058 - val_loss: 0.5926 - val_acc: 0.8655\n",
            "Epoch 66/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3693 - acc: 0.8080 - val_loss: 0.6042 - val_acc: 0.8457\n",
            "Epoch 67/80\n",
            "88411/88411 [==============================] - 4s 47us/step - loss: 0.3666 - acc: 0.8063 - val_loss: 0.5609 - val_acc: 0.8419\n",
            "Epoch 68/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3701 - acc: 0.8038 - val_loss: 0.6126 - val_acc: 0.8373\n",
            "Epoch 69/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3632 - acc: 0.8102 - val_loss: 0.5921 - val_acc: 0.8724\n",
            "Epoch 70/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3638 - acc: 0.8097 - val_loss: 0.6043 - val_acc: 0.8661\n",
            "Epoch 71/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3608 - acc: 0.8120 - val_loss: 0.6206 - val_acc: 0.8605\n",
            "Epoch 72/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3604 - acc: 0.8125 - val_loss: 0.6012 - val_acc: 0.8673\n",
            "Epoch 73/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3572 - acc: 0.8131 - val_loss: 0.5810 - val_acc: 0.8690\n",
            "Epoch 74/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3582 - acc: 0.8123 - val_loss: 0.6361 - val_acc: 0.8760\n",
            "Epoch 75/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3614 - acc: 0.8119 - val_loss: 0.6279 - val_acc: 0.8656\n",
            "Epoch 76/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3574 - acc: 0.8161 - val_loss: 0.6475 - val_acc: 0.8703\n",
            "Epoch 77/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3514 - acc: 0.8184 - val_loss: 0.6241 - val_acc: 0.8669\n",
            "Epoch 78/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3566 - acc: 0.8147 - val_loss: 0.6215 - val_acc: 0.8800\n",
            "Epoch 79/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3565 - acc: 0.8143 - val_loss: 0.6413 - val_acc: 0.8711\n",
            "Epoch 80/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3509 - acc: 0.8175 - val_loss: 0.6907 - val_acc: 0.8909\n",
            "14661/14661 [==============================] - 0s 13us/step\n",
            "Test loss: 26.47%\n",
            "Test accuracy: 89.68%\n",
            "14661/14661 [==============================] - 0s 30us/step\n",
            "\n",
            "FOLD: 8\n",
            "Train on 88411 samples, validate on 43547 samples\n",
            "Epoch 1/80\n",
            "88411/88411 [==============================] - 5s 57us/step - loss: 0.6144 - acc: 0.6057 - val_loss: 0.4463 - val_acc: 0.6470\n",
            "Epoch 2/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5645 - acc: 0.6797 - val_loss: 0.4283 - val_acc: 0.7557\n",
            "Epoch 3/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5445 - acc: 0.6911 - val_loss: 0.4273 - val_acc: 0.7378\n",
            "Epoch 4/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5298 - acc: 0.6938 - val_loss: 0.4207 - val_acc: 0.7843\n",
            "Epoch 5/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5187 - acc: 0.7010 - val_loss: 0.4206 - val_acc: 0.7933\n",
            "Epoch 6/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.5121 - acc: 0.7154 - val_loss: 0.4239 - val_acc: 0.7598\n",
            "Epoch 7/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.5060 - acc: 0.7048 - val_loss: 0.4280 - val_acc: 0.7756\n",
            "Epoch 8/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4984 - acc: 0.7148 - val_loss: 0.4255 - val_acc: 0.7911\n",
            "Epoch 9/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4966 - acc: 0.7180 - val_loss: 0.4342 - val_acc: 0.7884\n",
            "Epoch 10/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4923 - acc: 0.7245 - val_loss: 0.4295 - val_acc: 0.7772\n",
            "Epoch 11/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4864 - acc: 0.7256 - val_loss: 0.4436 - val_acc: 0.7789\n",
            "Epoch 12/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4819 - acc: 0.7297 - val_loss: 0.4216 - val_acc: 0.7897\n",
            "Epoch 13/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4771 - acc: 0.7318 - val_loss: 0.4291 - val_acc: 0.7989\n",
            "Epoch 14/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4754 - acc: 0.7373 - val_loss: 0.4274 - val_acc: 0.7963\n",
            "Epoch 15/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4689 - acc: 0.7367 - val_loss: 0.4356 - val_acc: 0.8002\n",
            "Epoch 16/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4660 - acc: 0.7422 - val_loss: 0.4467 - val_acc: 0.7933\n",
            "Epoch 17/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4630 - acc: 0.7423 - val_loss: 0.4461 - val_acc: 0.7852\n",
            "Epoch 18/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4620 - acc: 0.7442 - val_loss: 0.4429 - val_acc: 0.7651\n",
            "Epoch 19/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4568 - acc: 0.7457 - val_loss: 0.4470 - val_acc: 0.7945\n",
            "Epoch 20/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4525 - acc: 0.7529 - val_loss: 0.4494 - val_acc: 0.7730\n",
            "Epoch 21/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4508 - acc: 0.7508 - val_loss: 0.4531 - val_acc: 0.7857\n",
            "Epoch 22/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4431 - acc: 0.7569 - val_loss: 0.4714 - val_acc: 0.7838\n",
            "Epoch 23/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4493 - acc: 0.7523 - val_loss: 0.4436 - val_acc: 0.8177\n",
            "Epoch 24/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4361 - acc: 0.7635 - val_loss: 0.4600 - val_acc: 0.8081\n",
            "Epoch 25/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4364 - acc: 0.7598 - val_loss: 0.4619 - val_acc: 0.8066\n",
            "Epoch 26/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4358 - acc: 0.7600 - val_loss: 0.4685 - val_acc: 0.7876\n",
            "Epoch 27/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4370 - acc: 0.7609 - val_loss: 0.4557 - val_acc: 0.8071\n",
            "Epoch 28/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4269 - acc: 0.7663 - val_loss: 0.4753 - val_acc: 0.8200\n",
            "Epoch 29/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4285 - acc: 0.7704 - val_loss: 0.4643 - val_acc: 0.8089\n",
            "Epoch 30/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4253 - acc: 0.7695 - val_loss: 0.4695 - val_acc: 0.8331\n",
            "Epoch 31/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4173 - acc: 0.7734 - val_loss: 0.4831 - val_acc: 0.8176\n",
            "Epoch 32/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4157 - acc: 0.7717 - val_loss: 0.4816 - val_acc: 0.8012\n",
            "Epoch 33/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4138 - acc: 0.7745 - val_loss: 0.4764 - val_acc: 0.7940\n",
            "Epoch 34/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4176 - acc: 0.7695 - val_loss: 0.4601 - val_acc: 0.8228\n",
            "Epoch 35/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4093 - acc: 0.7749 - val_loss: 0.4758 - val_acc: 0.8290\n",
            "Epoch 36/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4070 - acc: 0.7772 - val_loss: 0.4884 - val_acc: 0.8246\n",
            "Epoch 37/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4011 - acc: 0.7796 - val_loss: 0.4842 - val_acc: 0.8340\n",
            "Epoch 38/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4077 - acc: 0.7786 - val_loss: 0.4936 - val_acc: 0.8361\n",
            "Epoch 39/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4037 - acc: 0.7821 - val_loss: 0.4773 - val_acc: 0.8287\n",
            "Epoch 40/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4029 - acc: 0.7827 - val_loss: 0.5268 - val_acc: 0.8129\n",
            "Epoch 41/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3987 - acc: 0.7831 - val_loss: 0.5175 - val_acc: 0.8151\n",
            "Epoch 42/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3902 - acc: 0.7879 - val_loss: 0.5254 - val_acc: 0.8106\n",
            "Epoch 43/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3945 - acc: 0.7846 - val_loss: 0.5008 - val_acc: 0.8294\n",
            "Epoch 44/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3912 - acc: 0.7824 - val_loss: 0.5391 - val_acc: 0.8237\n",
            "Epoch 45/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3891 - acc: 0.7881 - val_loss: 0.5383 - val_acc: 0.8319\n",
            "Epoch 46/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3886 - acc: 0.7890 - val_loss: 0.5435 - val_acc: 0.8190\n",
            "Epoch 47/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3883 - acc: 0.7905 - val_loss: 0.4993 - val_acc: 0.8176\n",
            "Epoch 48/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3886 - acc: 0.7912 - val_loss: 0.5120 - val_acc: 0.8135\n",
            "Epoch 49/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3841 - acc: 0.7929 - val_loss: 0.5086 - val_acc: 0.8290\n",
            "Epoch 50/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3839 - acc: 0.7899 - val_loss: 0.5400 - val_acc: 0.8341\n",
            "Epoch 51/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3827 - acc: 0.7922 - val_loss: 0.5177 - val_acc: 0.8373\n",
            "Epoch 52/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3799 - acc: 0.7947 - val_loss: 0.5165 - val_acc: 0.8366\n",
            "Epoch 53/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3800 - acc: 0.7936 - val_loss: 0.5331 - val_acc: 0.8409\n",
            "Epoch 54/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3683 - acc: 0.8023 - val_loss: 0.5610 - val_acc: 0.8413\n",
            "Epoch 55/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3749 - acc: 0.7987 - val_loss: 0.5651 - val_acc: 0.8285\n",
            "Epoch 56/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3721 - acc: 0.8019 - val_loss: 0.5449 - val_acc: 0.8396\n",
            "Epoch 57/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3775 - acc: 0.7987 - val_loss: 0.5167 - val_acc: 0.8109\n",
            "Epoch 58/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3763 - acc: 0.7969 - val_loss: 0.5353 - val_acc: 0.8284\n",
            "Epoch 59/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3741 - acc: 0.8003 - val_loss: 0.5446 - val_acc: 0.8258\n",
            "Epoch 60/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3669 - acc: 0.8039 - val_loss: 0.5506 - val_acc: 0.8399\n",
            "Epoch 61/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3717 - acc: 0.7997 - val_loss: 0.5394 - val_acc: 0.8418\n",
            "Epoch 62/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3628 - acc: 0.8057 - val_loss: 0.5783 - val_acc: 0.8363\n",
            "Epoch 63/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3659 - acc: 0.8036 - val_loss: 0.5774 - val_acc: 0.8511\n",
            "Epoch 64/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3669 - acc: 0.8044 - val_loss: 0.5792 - val_acc: 0.8331\n",
            "Epoch 65/80\n",
            "88411/88411 [==============================] - 4s 47us/step - loss: 0.3621 - acc: 0.8094 - val_loss: 0.5722 - val_acc: 0.8244\n",
            "Epoch 66/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3590 - acc: 0.8075 - val_loss: 0.6021 - val_acc: 0.8284\n",
            "Epoch 67/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3635 - acc: 0.8078 - val_loss: 0.5769 - val_acc: 0.8282\n",
            "Epoch 68/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3603 - acc: 0.8083 - val_loss: 0.6078 - val_acc: 0.8333\n",
            "Epoch 69/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3612 - acc: 0.8082 - val_loss: 0.5983 - val_acc: 0.8296\n",
            "Epoch 70/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3553 - acc: 0.8136 - val_loss: 0.6260 - val_acc: 0.8284\n",
            "Epoch 71/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3611 - acc: 0.8075 - val_loss: 0.5853 - val_acc: 0.8174\n",
            "Epoch 72/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3481 - acc: 0.8133 - val_loss: 0.6149 - val_acc: 0.8282\n",
            "Epoch 73/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3610 - acc: 0.8047 - val_loss: 0.6327 - val_acc: 0.8234\n",
            "Epoch 74/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3547 - acc: 0.8148 - val_loss: 0.6310 - val_acc: 0.8268\n",
            "Epoch 75/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3533 - acc: 0.8115 - val_loss: 0.6017 - val_acc: 0.8303\n",
            "Epoch 76/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3566 - acc: 0.8134 - val_loss: 0.6112 - val_acc: 0.8291\n",
            "Epoch 77/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3566 - acc: 0.8113 - val_loss: 0.6332 - val_acc: 0.8310\n",
            "Epoch 78/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3555 - acc: 0.8117 - val_loss: 0.6357 - val_acc: 0.8237\n",
            "Epoch 79/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3514 - acc: 0.8126 - val_loss: 0.6265 - val_acc: 0.8304\n",
            "Epoch 80/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.3537 - acc: 0.8164 - val_loss: 0.6361 - val_acc: 0.8378\n",
            "14661/14661 [==============================] - 0s 14us/step\n",
            "Test loss: 29.26%\n",
            "Test accuracy: 86.11%\n",
            "14661/14661 [==============================] - 1s 36us/step\n",
            "\n",
            "FOLD: 9\n",
            "Train on 88411 samples, validate on 43547 samples\n",
            "Epoch 1/80\n",
            "88411/88411 [==============================] - 5s 59us/step - loss: 0.6135 - acc: 0.6084 - val_loss: 0.4326 - val_acc: 0.6630\n",
            "Epoch 2/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.5657 - acc: 0.6641 - val_loss: 0.4406 - val_acc: 0.6451\n",
            "Epoch 3/80\n",
            "88411/88411 [==============================] - 4s 47us/step - loss: 0.5460 - acc: 0.6804 - val_loss: 0.4361 - val_acc: 0.6789\n",
            "Epoch 4/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5330 - acc: 0.6895 - val_loss: 0.4417 - val_acc: 0.6945\n",
            "Epoch 5/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5229 - acc: 0.6947 - val_loss: 0.4302 - val_acc: 0.7128\n",
            "Epoch 6/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5140 - acc: 0.7002 - val_loss: 0.4326 - val_acc: 0.7528\n",
            "Epoch 7/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5083 - acc: 0.7050 - val_loss: 0.4337 - val_acc: 0.7486\n",
            "Epoch 8/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.5038 - acc: 0.7042 - val_loss: 0.4309 - val_acc: 0.7780\n",
            "Epoch 9/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4934 - acc: 0.7189 - val_loss: 0.4356 - val_acc: 0.7403\n",
            "Epoch 10/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4909 - acc: 0.7125 - val_loss: 0.4375 - val_acc: 0.7885\n",
            "Epoch 11/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4904 - acc: 0.7176 - val_loss: 0.4419 - val_acc: 0.7736\n",
            "Epoch 12/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4851 - acc: 0.7160 - val_loss: 0.4446 - val_acc: 0.7684\n",
            "Epoch 13/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4802 - acc: 0.7239 - val_loss: 0.4571 - val_acc: 0.7744\n",
            "Epoch 14/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4732 - acc: 0.7329 - val_loss: 0.4696 - val_acc: 0.7579\n",
            "Epoch 15/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4749 - acc: 0.7297 - val_loss: 0.4541 - val_acc: 0.7642\n",
            "Epoch 16/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4715 - acc: 0.7370 - val_loss: 0.4608 - val_acc: 0.7724\n",
            "Epoch 17/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4655 - acc: 0.7425 - val_loss: 0.4635 - val_acc: 0.7757\n",
            "Epoch 18/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4615 - acc: 0.7425 - val_loss: 0.4613 - val_acc: 0.7842\n",
            "Epoch 19/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4582 - acc: 0.7516 - val_loss: 0.4811 - val_acc: 0.7583\n",
            "Epoch 20/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4556 - acc: 0.7495 - val_loss: 0.4920 - val_acc: 0.7576\n",
            "Epoch 21/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4536 - acc: 0.7459 - val_loss: 0.4678 - val_acc: 0.7827\n",
            "Epoch 22/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4477 - acc: 0.7601 - val_loss: 0.4949 - val_acc: 0.7781\n",
            "Epoch 23/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4441 - acc: 0.7562 - val_loss: 0.5125 - val_acc: 0.7654\n",
            "Epoch 24/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4426 - acc: 0.7565 - val_loss: 0.5089 - val_acc: 0.7817\n",
            "Epoch 25/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4375 - acc: 0.7628 - val_loss: 0.5113 - val_acc: 0.7928\n",
            "Epoch 26/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4373 - acc: 0.7617 - val_loss: 0.4982 - val_acc: 0.7526\n",
            "Epoch 27/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4336 - acc: 0.7630 - val_loss: 0.5217 - val_acc: 0.8065\n",
            "Epoch 28/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4348 - acc: 0.7694 - val_loss: 0.5246 - val_acc: 0.7727\n",
            "Epoch 29/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4275 - acc: 0.7753 - val_loss: 0.5046 - val_acc: 0.7587\n",
            "Epoch 30/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4235 - acc: 0.7704 - val_loss: 0.5210 - val_acc: 0.7705\n",
            "Epoch 31/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4229 - acc: 0.7740 - val_loss: 0.5243 - val_acc: 0.7629\n",
            "Epoch 32/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4217 - acc: 0.7699 - val_loss: 0.4853 - val_acc: 0.8143\n",
            "Epoch 33/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4192 - acc: 0.7751 - val_loss: 0.5198 - val_acc: 0.8035\n",
            "Epoch 34/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4189 - acc: 0.7771 - val_loss: 0.5319 - val_acc: 0.7922\n",
            "Epoch 35/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4169 - acc: 0.7752 - val_loss: 0.5230 - val_acc: 0.7799\n",
            "Epoch 36/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4162 - acc: 0.7767 - val_loss: 0.5117 - val_acc: 0.8062\n",
            "Epoch 37/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4139 - acc: 0.7808 - val_loss: 0.4844 - val_acc: 0.7841\n",
            "Epoch 38/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4098 - acc: 0.7854 - val_loss: 0.5384 - val_acc: 0.7798\n",
            "Epoch 39/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4042 - acc: 0.7827 - val_loss: 0.5391 - val_acc: 0.8177\n",
            "Epoch 40/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4033 - acc: 0.7818 - val_loss: 0.5468 - val_acc: 0.8328\n",
            "Epoch 41/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4024 - acc: 0.7846 - val_loss: 0.5199 - val_acc: 0.8179\n",
            "Epoch 42/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4016 - acc: 0.7864 - val_loss: 0.5314 - val_acc: 0.8002\n",
            "Epoch 43/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3995 - acc: 0.7880 - val_loss: 0.5498 - val_acc: 0.8147\n",
            "Epoch 44/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4020 - acc: 0.7851 - val_loss: 0.5491 - val_acc: 0.8171\n",
            "Epoch 45/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3921 - acc: 0.7911 - val_loss: 0.5298 - val_acc: 0.8171\n",
            "Epoch 46/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3890 - acc: 0.7952 - val_loss: 0.5594 - val_acc: 0.7927\n",
            "Epoch 47/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3958 - acc: 0.7936 - val_loss: 0.5259 - val_acc: 0.8074\n",
            "Epoch 48/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3929 - acc: 0.7940 - val_loss: 0.5863 - val_acc: 0.7770\n",
            "Epoch 49/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3919 - acc: 0.7935 - val_loss: 0.5545 - val_acc: 0.8266\n",
            "Epoch 50/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3835 - acc: 0.7997 - val_loss: 0.5422 - val_acc: 0.8024\n",
            "Epoch 51/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3909 - acc: 0.7927 - val_loss: 0.5541 - val_acc: 0.8216\n",
            "Epoch 52/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3807 - acc: 0.7993 - val_loss: 0.5610 - val_acc: 0.8341\n",
            "Epoch 53/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3874 - acc: 0.7972 - val_loss: 0.5369 - val_acc: 0.8294\n",
            "Epoch 54/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3806 - acc: 0.8027 - val_loss: 0.5593 - val_acc: 0.8279\n",
            "Epoch 55/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3829 - acc: 0.7965 - val_loss: 0.5615 - val_acc: 0.8261\n",
            "Epoch 56/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3799 - acc: 0.8016 - val_loss: 0.5917 - val_acc: 0.8320\n",
            "Epoch 57/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3785 - acc: 0.8033 - val_loss: 0.5669 - val_acc: 0.8253\n",
            "Epoch 58/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3743 - acc: 0.8006 - val_loss: 0.5644 - val_acc: 0.8296\n",
            "Epoch 59/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3802 - acc: 0.8030 - val_loss: 0.5274 - val_acc: 0.8469\n",
            "Epoch 60/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3742 - acc: 0.8029 - val_loss: 0.5817 - val_acc: 0.8364\n",
            "Epoch 61/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3730 - acc: 0.8047 - val_loss: 0.5927 - val_acc: 0.8243\n",
            "Epoch 62/80\n",
            "88411/88411 [==============================] - 4s 47us/step - loss: 0.3676 - acc: 0.8075 - val_loss: 0.5706 - val_acc: 0.8332\n",
            "Epoch 63/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3695 - acc: 0.8075 - val_loss: 0.5945 - val_acc: 0.8209\n",
            "Epoch 64/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3695 - acc: 0.8077 - val_loss: 0.5840 - val_acc: 0.8290\n",
            "Epoch 65/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3680 - acc: 0.8070 - val_loss: 0.5854 - val_acc: 0.8379\n",
            "Epoch 66/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3693 - acc: 0.8085 - val_loss: 0.5783 - val_acc: 0.8099\n",
            "Epoch 67/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3619 - acc: 0.8124 - val_loss: 0.6119 - val_acc: 0.8460\n",
            "Epoch 68/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3666 - acc: 0.8137 - val_loss: 0.5629 - val_acc: 0.8366\n",
            "Epoch 69/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3680 - acc: 0.8102 - val_loss: 0.5685 - val_acc: 0.8465\n",
            "Epoch 70/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3618 - acc: 0.8140 - val_loss: 0.5991 - val_acc: 0.8460\n",
            "Epoch 71/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3603 - acc: 0.8179 - val_loss: 0.5741 - val_acc: 0.8437\n",
            "Epoch 72/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3683 - acc: 0.8127 - val_loss: 0.5885 - val_acc: 0.8661\n",
            "Epoch 73/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3607 - acc: 0.8169 - val_loss: 0.5700 - val_acc: 0.8605\n",
            "Epoch 74/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3568 - acc: 0.8162 - val_loss: 0.5981 - val_acc: 0.8600\n",
            "Epoch 75/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3642 - acc: 0.8136 - val_loss: 0.5848 - val_acc: 0.8387\n",
            "Epoch 76/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3591 - acc: 0.8146 - val_loss: 0.6112 - val_acc: 0.8456\n",
            "Epoch 77/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3529 - acc: 0.8209 - val_loss: 0.6054 - val_acc: 0.8546\n",
            "Epoch 78/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3490 - acc: 0.8199 - val_loss: 0.6391 - val_acc: 0.8336\n",
            "Epoch 79/80\n",
            "88411/88411 [==============================] - 4s 48us/step - loss: 0.3536 - acc: 0.8198 - val_loss: 0.6103 - val_acc: 0.8276\n",
            "Epoch 80/80\n",
            "88411/88411 [==============================] - 4s 47us/step - loss: 0.3553 - acc: 0.8169 - val_loss: 0.6015 - val_acc: 0.8500\n",
            "14661/14661 [==============================] - 0s 14us/step\n",
            "Test loss: 29.18%\n",
            "Test accuracy: 88.11%\n",
            "14661/14661 [==============================] - 1s 37us/step\n",
            "\n",
            "FOLD: 10\n",
            "Train on 88411 samples, validate on 43547 samples\n",
            "Epoch 1/80\n",
            "88411/88411 [==============================] - 5s 61us/step - loss: 0.6176 - acc: 0.6243 - val_loss: 0.4607 - val_acc: 0.5424\n",
            "Epoch 2/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.5683 - acc: 0.6629 - val_loss: 0.4564 - val_acc: 0.5994\n",
            "Epoch 3/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.5469 - acc: 0.6839 - val_loss: 0.4458 - val_acc: 0.6290\n",
            "Epoch 4/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.5314 - acc: 0.7027 - val_loss: 0.4494 - val_acc: 0.6506\n",
            "Epoch 5/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.5218 - acc: 0.7143 - val_loss: 0.4443 - val_acc: 0.6427\n",
            "Epoch 6/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.5161 - acc: 0.7123 - val_loss: 0.4403 - val_acc: 0.6618\n",
            "Epoch 7/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.5060 - acc: 0.7184 - val_loss: 0.4493 - val_acc: 0.6842\n",
            "Epoch 8/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4985 - acc: 0.7211 - val_loss: 0.4436 - val_acc: 0.6845\n",
            "Epoch 9/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4966 - acc: 0.7253 - val_loss: 0.4484 - val_acc: 0.6745\n",
            "Epoch 10/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4922 - acc: 0.7261 - val_loss: 0.4547 - val_acc: 0.6815\n",
            "Epoch 11/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4838 - acc: 0.7317 - val_loss: 0.4489 - val_acc: 0.6958\n",
            "Epoch 12/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4810 - acc: 0.7391 - val_loss: 0.4503 - val_acc: 0.7008\n",
            "Epoch 13/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4783 - acc: 0.7395 - val_loss: 0.4490 - val_acc: 0.7029\n",
            "Epoch 14/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4658 - acc: 0.7445 - val_loss: 0.4657 - val_acc: 0.7271\n",
            "Epoch 15/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4700 - acc: 0.7450 - val_loss: 0.4484 - val_acc: 0.7635\n",
            "Epoch 16/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4715 - acc: 0.7449 - val_loss: 0.4451 - val_acc: 0.7451\n",
            "Epoch 17/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4620 - acc: 0.7528 - val_loss: 0.4445 - val_acc: 0.7366\n",
            "Epoch 18/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4614 - acc: 0.7528 - val_loss: 0.4539 - val_acc: 0.7646\n",
            "Epoch 19/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4552 - acc: 0.7584 - val_loss: 0.4457 - val_acc: 0.7860\n",
            "Epoch 20/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4544 - acc: 0.7637 - val_loss: 0.4548 - val_acc: 0.7556\n",
            "Epoch 21/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4498 - acc: 0.7616 - val_loss: 0.4628 - val_acc: 0.7529\n",
            "Epoch 22/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4444 - acc: 0.7729 - val_loss: 0.4751 - val_acc: 0.7385\n",
            "Epoch 23/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4394 - acc: 0.7680 - val_loss: 0.4582 - val_acc: 0.7315\n",
            "Epoch 24/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4363 - acc: 0.7671 - val_loss: 0.4666 - val_acc: 0.7693\n",
            "Epoch 25/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4357 - acc: 0.7745 - val_loss: 0.4608 - val_acc: 0.7866\n",
            "Epoch 26/80\n",
            "88411/88411 [==============================] - 4s 44us/step - loss: 0.4286 - acc: 0.7762 - val_loss: 0.4861 - val_acc: 0.7820\n",
            "Epoch 27/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4344 - acc: 0.7782 - val_loss: 0.4646 - val_acc: 0.7500\n",
            "Epoch 28/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4263 - acc: 0.7789 - val_loss: 0.5261 - val_acc: 0.7507\n",
            "Epoch 29/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4184 - acc: 0.7850 - val_loss: 0.4924 - val_acc: 0.7868\n",
            "Epoch 30/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4204 - acc: 0.7797 - val_loss: 0.5099 - val_acc: 0.8080\n",
            "Epoch 31/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4222 - acc: 0.7827 - val_loss: 0.4893 - val_acc: 0.7900\n",
            "Epoch 32/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4165 - acc: 0.7863 - val_loss: 0.4781 - val_acc: 0.7784\n",
            "Epoch 33/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4153 - acc: 0.7801 - val_loss: 0.4929 - val_acc: 0.8033\n",
            "Epoch 34/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4148 - acc: 0.7826 - val_loss: 0.4768 - val_acc: 0.8185\n",
            "Epoch 35/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4122 - acc: 0.7859 - val_loss: 0.4900 - val_acc: 0.8252\n",
            "Epoch 36/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4063 - acc: 0.7894 - val_loss: 0.5035 - val_acc: 0.7770\n",
            "Epoch 37/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4002 - acc: 0.7896 - val_loss: 0.5137 - val_acc: 0.7908\n",
            "Epoch 38/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.4053 - acc: 0.7878 - val_loss: 0.5150 - val_acc: 0.7817\n",
            "Epoch 39/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.4006 - acc: 0.7899 - val_loss: 0.5155 - val_acc: 0.7869\n",
            "Epoch 40/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3970 - acc: 0.7926 - val_loss: 0.5498 - val_acc: 0.7927\n",
            "Epoch 41/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3976 - acc: 0.7949 - val_loss: 0.4947 - val_acc: 0.8191\n",
            "Epoch 42/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3944 - acc: 0.7963 - val_loss: 0.5234 - val_acc: 0.7985\n",
            "Epoch 43/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3941 - acc: 0.7964 - val_loss: 0.5188 - val_acc: 0.8103\n",
            "Epoch 44/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3920 - acc: 0.7980 - val_loss: 0.5297 - val_acc: 0.7877\n",
            "Epoch 45/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3972 - acc: 0.7966 - val_loss: 0.4906 - val_acc: 0.7843\n",
            "Epoch 46/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3870 - acc: 0.7978 - val_loss: 0.5146 - val_acc: 0.7887\n",
            "Epoch 47/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3855 - acc: 0.8027 - val_loss: 0.5283 - val_acc: 0.7962\n",
            "Epoch 48/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3845 - acc: 0.7998 - val_loss: 0.5533 - val_acc: 0.8001\n",
            "Epoch 49/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3850 - acc: 0.7998 - val_loss: 0.5548 - val_acc: 0.8040\n",
            "Epoch 50/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3765 - acc: 0.8049 - val_loss: 0.5485 - val_acc: 0.8129\n",
            "Epoch 51/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3787 - acc: 0.8031 - val_loss: 0.5582 - val_acc: 0.8115\n",
            "Epoch 52/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3774 - acc: 0.8039 - val_loss: 0.5312 - val_acc: 0.8061\n",
            "Epoch 53/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3782 - acc: 0.8034 - val_loss: 0.5103 - val_acc: 0.7999\n",
            "Epoch 54/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3749 - acc: 0.8041 - val_loss: 0.5385 - val_acc: 0.7891\n",
            "Epoch 55/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3733 - acc: 0.8065 - val_loss: 0.5614 - val_acc: 0.8096\n",
            "Epoch 56/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3685 - acc: 0.8102 - val_loss: 0.5618 - val_acc: 0.8065\n",
            "Epoch 57/80\n",
            "88411/88411 [==============================] - 4s 48us/step - loss: 0.3678 - acc: 0.8081 - val_loss: 0.5828 - val_acc: 0.8076\n",
            "Epoch 58/80\n",
            "88411/88411 [==============================] - 4s 49us/step - loss: 0.3701 - acc: 0.8076 - val_loss: 0.5558 - val_acc: 0.8384\n",
            "Epoch 59/80\n",
            "88411/88411 [==============================] - 4s 48us/step - loss: 0.3645 - acc: 0.8106 - val_loss: 0.5433 - val_acc: 0.8147\n",
            "Epoch 60/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3637 - acc: 0.8105 - val_loss: 0.5798 - val_acc: 0.7961\n",
            "Epoch 61/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3675 - acc: 0.8061 - val_loss: 0.5790 - val_acc: 0.8272\n",
            "Epoch 62/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3676 - acc: 0.8086 - val_loss: 0.5819 - val_acc: 0.8178\n",
            "Epoch 63/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3676 - acc: 0.8082 - val_loss: 0.5671 - val_acc: 0.8206\n",
            "Epoch 64/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3618 - acc: 0.8113 - val_loss: 0.6215 - val_acc: 0.8147\n",
            "Epoch 65/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3586 - acc: 0.8135 - val_loss: 0.5906 - val_acc: 0.8171\n",
            "Epoch 66/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3654 - acc: 0.8097 - val_loss: 0.5797 - val_acc: 0.8099\n",
            "Epoch 67/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3638 - acc: 0.8157 - val_loss: 0.5827 - val_acc: 0.8199\n",
            "Epoch 68/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3571 - acc: 0.8182 - val_loss: 0.5881 - val_acc: 0.8147\n",
            "Epoch 69/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3608 - acc: 0.8137 - val_loss: 0.6170 - val_acc: 0.7990\n",
            "Epoch 70/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3622 - acc: 0.8145 - val_loss: 0.6116 - val_acc: 0.8302\n",
            "Epoch 71/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3607 - acc: 0.8155 - val_loss: 0.5898 - val_acc: 0.8225\n",
            "Epoch 72/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3578 - acc: 0.8190 - val_loss: 0.6254 - val_acc: 0.8116\n",
            "Epoch 73/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3561 - acc: 0.8181 - val_loss: 0.6101 - val_acc: 0.8110\n",
            "Epoch 74/80\n",
            "88411/88411 [==============================] - 4s 49us/step - loss: 0.3516 - acc: 0.8194 - val_loss: 0.5907 - val_acc: 0.8358\n",
            "Epoch 75/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3537 - acc: 0.8179 - val_loss: 0.6282 - val_acc: 0.8231\n",
            "Epoch 76/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3491 - acc: 0.8223 - val_loss: 0.6335 - val_acc: 0.8353\n",
            "Epoch 77/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3498 - acc: 0.8222 - val_loss: 0.6362 - val_acc: 0.8277\n",
            "Epoch 78/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3527 - acc: 0.8173 - val_loss: 0.6337 - val_acc: 0.8342\n",
            "Epoch 79/80\n",
            "88411/88411 [==============================] - 4s 46us/step - loss: 0.3445 - acc: 0.8225 - val_loss: 0.6807 - val_acc: 0.8269\n",
            "Epoch 80/80\n",
            "88411/88411 [==============================] - 4s 45us/step - loss: 0.3458 - acc: 0.8251 - val_loss: 0.5987 - val_acc: 0.8116\n",
            "14661/14661 [==============================] - 0s 14us/step\n",
            "Test loss: 32.92%\n",
            "Test accuracy: 84.14%\n",
            "14661/14661 [==============================] - 1s 39us/step\n",
            "MEAN ACCURACY: 86.26% (STANDARD DEVIATION: +/- 2.24%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gAdSdADmUm5S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_vL2BWwjIgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.save('my_model1_cv.h5')\n",
        "\n",
        "#model = load_model('my_model1_cv.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}