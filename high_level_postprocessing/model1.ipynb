{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FG2511/ARE/blob/master/high_level_postprocessing/model1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hu-_5aP7LlL6",
        "colab_type": "code",
        "outputId": "cc7e13b0-21a0-472c-da8f-04498235bb59",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@File name: model1.ipynb\n",
        "@Created on 2018-12-20\n",
        "@Authors: Federica Gerina, Francesca Moi, Silvia Maria Massa\n",
        "@Description: Given a time-series dataset that contains minute-by-minute data \n",
        "about different kind of gases, collected by the uHoo air quality sensor, train\n",
        "a NN that classifies if a minute belongs to the class \"Pasto\" (1) otherwise to\n",
        "the class \"Other\" (0).\n",
        "'''\n",
        "\n",
        "!pip install liac-arff\n",
        "\n",
        "import arff\n",
        "import numpy as np\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Dropout, LeakyReLU, BatchNormalization, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import sys\n",
        "sys.path.append('local_modules')\n",
        "\n",
        "#import postprocessing_sliding\n",
        "#import postprocessing_Silvia\n",
        "#import plotting\n",
        "\n",
        "import more_itertools"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (2.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJ0SubdGw6LA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#fix random seed for reproducibility\n",
        "seed = 5\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKvmDiR9NgBO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@Description: generate a multilayer perceptron with LeakyRelu as activation\n",
        "function.\n",
        "@param: \n",
        "  - shape : int, the shape of the input\n",
        "  - n_features: int, the number of features given\n",
        "'''\n",
        "\n",
        "#MODELLO 1\n",
        "#REGOLA: input/2, input, 2*input, 1\n",
        "#layers TUTTE LE FEATURE: 57, 113, 226, 1 \n",
        "#layers TIME CO2 TEMP: 21, 41, 82, 1 \n",
        "#layers TIME CO2 TEMP PM25/TVOC: 30, 59, 118, 1 \n",
        "#layers TIME CO2 TEMP PM25 TVOC: 39, 77, 154, 1 \n",
        "\n",
        "\n",
        "def generate_model_leaky(shape, n_features):\n",
        "\n",
        "  units_1 = int(n_features/2)\n",
        "  units_2 = n_features\n",
        "  units_3 = n_features*2\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(Dense(units_1, input_dim=shape, kernel_initializer='random_uniform',  use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha = 0.2))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(units_2, kernel_initializer='random_uniform',  use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha = 0.2))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(units_3, kernel_initializer='random_uniform',  use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha = 0.2))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  #print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GNvDfgeB13JC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@Description: generate a multilayer perceptron with Relu as activation\n",
        "function.\n",
        "@param: \n",
        "  - shape : int, the shape of the input\n",
        "  - n_features: int, the number of features given\n",
        "'''\n",
        "\n",
        "#MODELLO 2\n",
        "#REGOLA: a= input, b= a*2/3+c, c= b*2/3+1\n",
        "#layers TUTTE LE FEATURE: 113, 229, 153, 1\n",
        "#layers TIME CO2 TEMP: 41, 85, 57, 1 \n",
        "#layers TIME CO2 TEMP PM25/TVOC: 59, 121, 81, 1 \n",
        "#layers TIME CO2 TEMP PM25 TVOC: 77, 157, 105, 1 \n",
        "\n",
        "def generate_model(shape, n_features):\n",
        "  \n",
        "  a = np.array([[1,0,0],[-(2/3),1,-1],[0,-(2/3),1]])\n",
        "  b = np.array([n_features,0,1])\n",
        "  x = np.linalg.solve(a, b)\n",
        "\n",
        "  units_1 = int(x[0])\n",
        "  units_2 = int(x[1])\n",
        "  units_3 = int(x[2])\n",
        "\n",
        "  model = Sequential()\n",
        " \n",
        "  model.add(Dense(units_1, input_dim=shape, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  model.add(Dense(units_2, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  model.add(Dense(units_3, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  #print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o99ibbgGHANE",
        "outputId": "71a08bad-390c-4b06-ef3b-02a9216598d9",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 799
        }
      },
      "cell_type": "code",
      "source": [
        "#@title SCEGLI IL DATASET E IL MODELLO\n",
        "\n",
        "'''\n",
        "@Description: MAIN\n",
        "'''\n",
        "\n",
        "#LOAD DATA\n",
        "print(\"Loading data...\")\n",
        "\n",
        "dataset = '/root/data/uHooComplete_featureDataset.arff' #@param {type:\"string\"}\n",
        "\n",
        "with open (dataset, encoding='utf-8') as f:\n",
        "  dataDictionary = arff.load(f)\n",
        "\n",
        "data = np.array(dataDictionary['data'])\n",
        "print(\"DATASET LOADED\")\n",
        "\n",
        "#CONVERTING VALUES\n",
        "print(\"\\nConverting values...\")\n",
        "for i in data:\n",
        "  if(i[-1] == 'Other'): i[-1] = 0\n",
        "  elif(i[-1] == 'Pasto') : i[-1] = 1\n",
        "\n",
        "dataset = data.astype('float32')\n",
        "print(\"CONVERSION DONE\")\n",
        "\n",
        "#SPLIT INTO INPUT (X) AND OUTPUT (Y) VARIABLES\n",
        "s = dataset.shape[-1]\n",
        "#print(s)\n",
        "X = dataset[:,0:s-1]\n",
        "Y = dataset[:,s-1]\n",
        "\n",
        "#print(s-1)\n",
        "\n",
        "n_features = s-1\n",
        "\n",
        "#SPLIT INTO TRAINING, VALIDATION AND TEST SETS\n",
        "print(\"\\nSplit into training, validation and test sets...\")\n",
        "\n",
        "train_rate = 80\n",
        "val_rate = 10\n",
        "train = round(int((dataset.shape[0]*train_rate)/100))\n",
        "val = round(int((dataset.shape[0]*(train_rate+val_rate))/100))\n",
        "\n",
        "train_data = X[:train]\n",
        "train_label = Y[:train]\n",
        "\n",
        "val_data = X[train+1:val]\n",
        "val_label = Y[train+1:val]\n",
        "\n",
        "test_data = X[val+1:]\n",
        "test_label = Y[val+1:]\n",
        "print(\"DATASET SPLITTED\")\n",
        "\n",
        "#COMPUTE CLASS WEIGHT\n",
        "labels = np.unique(train_label)\n",
        "classWeight = compute_class_weight('balanced', labels, train_label)\n",
        "classWeight = dict(zip(labels,classWeight))\n",
        "\n",
        "#GENERATE MODEL\n",
        "print(\"\\nGenerate model...\")\n",
        "\n",
        "modello = 1 #@param {type:\"integer\"}\n",
        "\n",
        "if modello==1 :\n",
        "  model = generate_model_leaky(train_data.shape[-1], n_features)\n",
        "elif modello==2:\n",
        "  model = generate_model(train_data.shape[-1], n_features)\n",
        "\n",
        "#OPTIMIZERS\n",
        "adm = optimizers.Adam(lr=0.0001)\n",
        "\n",
        "#COMPILE MODEL\n",
        "print(\"\\nCompile model...\")\n",
        "model.compile(loss='binary_crossentropy', optimizer = adm , metrics=['accuracy'])\n",
        "\n",
        "#EARLY STOPPING\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
        "\n",
        "#FIT MODEL\n",
        "print(\"\\nFit model...\")\n",
        "history = model.fit(train_data, train_label, epochs=10, validation_data = (val_data, val_label), batch_size = 128, shuffle = True, class_weight = classWeight, verbose=1, callbacks = [es])\n",
        "\n",
        "#EVALUATE MODEL\n",
        "print(\"\\nEvaluate model...\")\n",
        "scores_test = model.evaluate(test_data, test_label, batch_size=128, verbose = 1)\n",
        "print(\"Test loss: %.2f%%\" % (scores_test[0] * 100))\n",
        "print(\"Test accuracy: %.2f%%\" % (scores_test[1] * 100))\n",
        "\n",
        "#CALCULATE PREDICTIONS\n",
        "print(\"\\nCalculate predictions...\")\n",
        "pred = model.predict_classes(test_data, batch_size=128, verbose=0)\n",
        "flat_pred = [item for sublist in pred for item in sublist]\n",
        "\n",
        "#CONFUSION MATRIX\n",
        "print(\"\\nCompute confusion matrix...\")\n",
        "y_true = test_label\n",
        "y_pred = pred\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "print(\"TN\", tn)\n",
        "print(\"FP\", fp)\n",
        "print(\"FN\", fn)\n",
        "print(\"TP\", tp)\n",
        "other = 100*tn/(tn+fp)\n",
        "pasto = 100*tp/(fn+tp)\n",
        "print(\"Other corretti: %.2f %%\" % other)\n",
        "print(\"Pasto corretti: %.2f %%\" % pasto)\n",
        "\n",
        "time = []\n",
        "for i in test_data:\n",
        "  time.append(i[-1])"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "DATASET LOADED\n",
            "\n",
            "Converting values...\n",
            "CONVERSION DONE\n",
            "\n",
            "Split into training, validation and test sets...\n",
            "DATASET SPLITTED\n",
            "\n",
            "Generate model...\n",
            "\n",
            "Compile model...\n",
            "\n",
            "Fit model...\n",
            "Train on 280392 samples, validate on 35048 samples\n",
            "Epoch 1/10\n",
            "280392/280392 [==============================] - 16s 57us/step - loss: 0.5406 - acc: 0.7602 - val_loss: 0.4569 - val_acc: 0.8495\n",
            "Epoch 2/10\n",
            "280392/280392 [==============================] - 14s 52us/step - loss: 0.4439 - acc: 0.8305 - val_loss: 0.4144 - val_acc: 0.8491\n",
            "Epoch 3/10\n",
            "280392/280392 [==============================] - 15s 52us/step - loss: 0.4135 - acc: 0.8315 - val_loss: 0.3705 - val_acc: 0.8508\n",
            "Epoch 4/10\n",
            "280392/280392 [==============================] - 15s 52us/step - loss: 0.3997 - acc: 0.8312 - val_loss: 0.3747 - val_acc: 0.8449\n",
            "Epoch 5/10\n",
            "280392/280392 [==============================] - 15s 53us/step - loss: 0.3930 - acc: 0.8285 - val_loss: 0.3624 - val_acc: 0.8502\n",
            "Epoch 6/10\n",
            "280392/280392 [==============================] - 20s 70us/step - loss: 0.3888 - acc: 0.8279 - val_loss: 0.3958 - val_acc: 0.8303\n",
            "Epoch 7/10\n",
            "280392/280392 [==============================] - 14s 52us/step - loss: 0.3821 - acc: 0.8274 - val_loss: 0.3631 - val_acc: 0.8515\n",
            "\n",
            "Evaluate model...\n",
            "35049/35049 [==============================] - 1s 17us/step\n",
            "Test loss: 48.23%\n",
            "Test accuracy: 81.87%\n",
            "\n",
            "Calculate predictions...\n",
            "\n",
            "Compute confusion matrix...\n",
            "TN 26944\n",
            "FP 6037\n",
            "FN 317\n",
            "TP 1751\n",
            "Other corretti: 81.70 %\n",
            "Pasto corretti: 84.67 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "LHjWSCzC97Un",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 444
        },
        "outputId": "fe44fe90-2e60-4995-ac17-fe388c486d4b"
      },
      "cell_type": "code",
      "source": [
        "label_time = (test_label,time)\n",
        "pred_time = (pred,time)\n",
        "\n",
        "for j in range(0,3):\n",
        "  if j == 0: \n",
        "    lim_inf = 330\n",
        "    lim_sup = 630\n",
        "    activity = 'colazione'\n",
        "  if j == 1: \n",
        "    lim_inf = 720\n",
        "    lim_sup = 900\n",
        "    activity = 'pranzo'\n",
        "  if j == 2: \n",
        "    lim_inf = 1111\n",
        "    lim_sup = 1439\n",
        "    activity = 'cena'\n",
        "    \n",
        "  #prendo le label che ci indicano l'attività svolta solo nella finestra di tempo compresa tra lim_inf e lim_sup \n",
        "  real= []\n",
        "\n",
        "  i = 0 \n",
        "  while i < len(label_time[0]):\n",
        "    if label_time[1][i]> lim_inf and label_time[1][i]<lim_sup:\n",
        "      real.append(label_time[0][i])\n",
        "    i = i+1\n",
        "\n",
        "  #prendo le predizioni che ci indicano l'attività svolta solo nella finestra di tempo compresa tra lim_inf e lim_sup\n",
        "  pred = []\n",
        "\n",
        "  i = 0 \n",
        "  while i < len(pred_time[0]):\n",
        "    if pred_time[1][i]>lim_inf and pred_time[1][i]<lim_sup:\n",
        "      pred.append(pred_time[0][i])\n",
        "    i = i+1\n",
        "\n",
        "  #calcolo la matrice di confusione solo per il pasto indicato dalla variabile activity\n",
        "  print(\"\\nCompute confusion matrix senza sw \" + activity)\n",
        "  y_true = real\n",
        "  y_true = np.array(y_true,dtype=np.int)\n",
        "  n_y_pred = pred\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, n_y_pred).ravel()\n",
        "  print(\"TN\", tn)\n",
        "  print(\"FP\", fp)\n",
        "  print(\"FN\", fn)\n",
        "  print(\"TP\", tp)\n",
        "  other = 100*tn/(tn+fp)\n",
        "  pasto = 100*tp/(fn+tp)\n",
        "  print(\"Other corretti: %.2f %%\" % other)\n",
        "  print(\"Pasto corretti: %.2f %%\" % pasto)\n"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Compute confusion matrix senza sw colazione\n",
            "TN 5643\n",
            "FP 1246\n",
            "FN 47\n",
            "TP 328\n",
            "Other corretti: 81.91 %\n",
            "Pasto corretti: 87.47 %\n",
            "\n",
            "Compute confusion matrix senza sw pranzo\n",
            "TN 2606\n",
            "FP 1089\n",
            "FN 126\n",
            "TP 638\n",
            "Other corretti: 70.53 %\n",
            "Pasto corretti: 83.51 %\n",
            "\n",
            "Compute confusion matrix senza sw cena\n",
            "TN 5169\n",
            "FP 1879\n",
            "FN 98\n",
            "TP 616\n",
            "Other corretti: 73.34 %\n",
            "Pasto corretti: 86.27 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "7yQfjJpuwKM4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#calcolo le sliding windows per ogni tipologia di pasto (colazione, pranzo, cena). \n",
        "#per ogni sliding windows mi salvo il minuto centrale come identificatore dell'attività che si è realmente svolta in quella finestra di tempo\n",
        "\n",
        "#estrazione sliding windows di 5 minuti nelle ore in cui c'è la colazione\n",
        "col = list(more_itertools.windowed(test_label,n=5, step=1))\n",
        "time_col = list(more_itertools.windowed(time,n=5, step=1))\n",
        "lista = (col,time_col)\n",
        "\n",
        "sw_col_real= []\n",
        "\n",
        "i = 0 \n",
        "while i < len(lista[0]):\n",
        "  if lista[1][i][0]>330 and lista[1][i][4]<630:\n",
        "    sw_col_real.append(lista[0][i][2])\n",
        "  i = i+1\n",
        "  \n",
        "#estrazione sliding windows di 30 minuti nelle ore in cui c'è il pranzo e la cena  \n",
        "pasto = list(more_itertools.windowed(test_label,n=31, step=1))\n",
        "time_pasto = list(more_itertools.windowed(time,n=31, step=1))\n",
        "lista = (pasto,time_pasto)\n",
        "\n",
        "sw_pranzo_real = []\n",
        "sw_cena_real = []\n",
        "\n",
        "i = 0 \n",
        "while i < len(lista[0]):\n",
        "  if lista[1][i][0]>720 and lista[1][i][30]<900:\n",
        "    sw_pranzo_real.append(lista[0][i][15])\n",
        "  if lista[1][i][0]>1111 and lista[1][i][30]<1439:\n",
        "    sw_cena_real.append(lista[0][i][15])\n",
        "  i = i+1\n",
        "  \n",
        "#print(sw_col_real)\n",
        "#print(sw_pranzo_real)\n",
        "#print(sw_cena_real)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "q05qIye6FjFz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#estrazione sliding windows di 5 minuti nelle ore in cui ci dovrebbe essere la colazione\n",
        "pred_col = list(more_itertools.windowed(pred,n=5, step=1))\n",
        "time_col = list(more_itertools.windowed(time,n=5, step=1))\n",
        "lista = (pred_col,time_col)\n",
        "\n",
        "sw_col= []\n",
        "\n",
        "i = 0 \n",
        "while i < len(lista[0]):\n",
        "  if lista[1][i][0]>330 and lista[1][i][4]<630:\n",
        "    sw_col.append(lista[0][i])\n",
        "  i = i+1\n",
        "\n",
        "#estrazione sliding windows di 30 minuti nelle ore in cui ci dovrebbe essere il pranzo e la cena  \n",
        "pred_pasto = list(more_itertools.windowed(pred,n=31, step=1))\n",
        "time_pasto = list(more_itertools.windowed(time,n=31, step=1))\n",
        "lista = (pred_pasto,time_pasto)\n",
        "\n",
        "sw_pranzo = []\n",
        "sw_cena = []\n",
        "\n",
        "i = 0 \n",
        "while i < len(lista[0]):\n",
        "  if lista[1][i][0]>720 and lista[1][i][30]<900:\n",
        "    sw_pranzo.append(lista[0][i])\n",
        "  if lista[1][i][0]>1111 and lista[1][i][30]<1439:\n",
        "    sw_cena.append(lista[0][i])\n",
        "  i = i+1\n",
        "    \n",
        "#creazione di tre array in cui si inserisce il minuto centrale di una sw se questa ci sembra una colazione, un pranzo o una cena    \n",
        "result_col = [];\n",
        "result_pranzo = [];\n",
        "result_cena = [];\n",
        "\n",
        "for j in range(0,3):\n",
        "  if j == 0: \n",
        "    windowsList = sw_col\n",
        "    centro = 2\n",
        "    min_pasto = 3\n",
        "  if j == 1: \n",
        "    windowsList = sw_pranzo\n",
        "    centro = 15\n",
        "    min_pasto = 20\n",
        "  if j == 2: \n",
        "    windowsList = sw_cena\n",
        "    centro = 15\n",
        "    min_pasto = 20\n",
        "  \n",
        "  result = []\n",
        "  i = 0 \n",
        "  while i < len(windowsList): \n",
        "    count = 0\n",
        "\n",
        "    z = 0  \n",
        "    while z < len(windowsList[i]):\n",
        "      if windowsList[i][z] == 1 :\n",
        "        count = count + 1\n",
        "      z = z + 1\n",
        "\n",
        "    if count > min_pasto:\n",
        "      result.append(1)\n",
        "    else:\n",
        "      result.append(0)\n",
        "\n",
        "    i = i + 1\n",
        "  \n",
        "  if j == 0:\n",
        "    result_col = result\n",
        "  if j == 1:\n",
        "    result_pranzo = result\n",
        "  if j == 2:\n",
        "    result_cena = result\n",
        "\n",
        "\n",
        "#print(result_col)\n",
        "#print(result_pranzo)\n",
        "#print(result_cena)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zaNEiQ2FzjOs",
        "colab_type": "code",
        "outputId": "db8da967-8f69-431b-bd19-9ecdb451d01b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 648
        }
      },
      "cell_type": "code",
      "source": [
        "print(\"\\nCompute confusion matrix colazione...\")\n",
        "y_true = sw_col_real\n",
        "y_true = np.array(y_true,dtype=np.int)\n",
        "n_y_pred = result_col\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, n_y_pred).ravel()\n",
        "print(\"TN\", tn)\n",
        "print(\"FP\", fp)\n",
        "print(\"FN\", fn)\n",
        "print(\"TP\", tp)\n",
        "other = 100*tn/(tn+fp)\n",
        "pasto = 100*tp/(fn+tp)\n",
        "print(\"Other corretti: %.2f %%\" % other)\n",
        "print(\"Pasto corretti: %.2f %%\" % pasto)\n",
        "\n",
        "print(\"\\nCompute NEW confusion matrix pranzo...\")\n",
        "y_true = sw_pranzo_real\n",
        "y_true = np.array(y_true,dtype=np.int)\n",
        "n_y_pred = result_pranzo\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, n_y_pred).ravel()\n",
        "print(\"TN\", tn)\n",
        "print(\"FP\", fp)\n",
        "print(\"FN\", fn)\n",
        "print(\"TP\", tp)\n",
        "other = 100*tn/(tn+fp)\n",
        "pasto = 100*tp/(fn+tp)\n",
        "print(\"Other corretti: %.2f %%\" % other)\n",
        "print(\"Pasto corretti: %.2f %%\" % pasto)\n",
        "\n",
        "print(\"\\nCompute NEW confusion matrix cena...\")\n",
        "y_true = sw_cena_real\n",
        "y_true = np.array(y_true,dtype=np.int)\n",
        "n_y_pred = result_cena\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, n_y_pred).ravel()\n",
        "print(\"TN\", tn)\n",
        "print(\"FP\", fp)\n",
        "print(\"FN\", fn)\n",
        "print(\"TP\", tp)\n",
        "other = 100*tn/(tn+fp)\n",
        "pasto = 100*tp/(fn+tp)\n",
        "print(\"Other corretti: %.2f %%\" % other)\n",
        "print(\"Pasto corretti: %.2f %%\" % pasto)\n"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Compute confusion matrix colazione...\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-22-8123032c2d6e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0my_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mint\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mn_y_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mresult_col\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfusion_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_y_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"TN\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"FP\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36mconfusion_matrix\u001b[0;34m(y_true, y_pred, labels, sample_weight)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m     \"\"\"\n\u001b[0;32m--> 253\u001b[0;31m     \u001b[0my_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_targets\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0my_type\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m\"binary\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"%s is not supported\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/metrics/classification.py\u001b[0m in \u001b[0;36m_check_targets\u001b[0;34m(y_true, y_pred)\u001b[0m\n\u001b[1;32m     69\u001b[0m     \u001b[0my_pred\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0marray\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mindicator\u001b[0m \u001b[0mmatrix\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m     \"\"\"\n\u001b[0;32m---> 71\u001b[0;31m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m     \u001b[0mtype_true\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m     \u001b[0mtype_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/sklearn/utils/validation.py\u001b[0m in \u001b[0;36mcheck_consistent_length\u001b[0;34m(*arrays)\u001b[0m\n\u001b[1;32m    233\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0muniques\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    234\u001b[0m         raise ValueError(\"Found input variables with inconsistent numbers of\"\n\u001b[0;32m--> 235\u001b[0;31m                          \" samples: %r\" % [int(l) for l in lengths])\n\u001b[0m\u001b[1;32m    236\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Found input variables with inconsistent numbers of samples: [7260, 1535]"
          ]
        }
      ]
    },
    {
      "metadata": {
        "id": "ivXVv6yGJBqx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#@title SCEGLI maxWidth per postprocessing_Silvia\n",
        "'''\n",
        "@Description: POST PROCESSING\n",
        "'''\n",
        "\n",
        "#maxWidth = 3 #@param {type:\"integer\"}\n",
        "\n",
        "#new_pred = postprocessing_sliding.sliding_windows_time(flat_pred, time)\n",
        "#new_pred = postprocessing_sliding.sliding_windows_time_mod(flat_pred, time)\n",
        "#new_pred = postprocessing_Silvia.setWidth(maxWidth,flat_pred)\n",
        "\n",
        "#CONFUSION MATRIX\n",
        "\"\"\"\n",
        "print(\"\\nCompute NEW confusion matrix...\")\n",
        "y_true = test_label\n",
        "n_y_pred = new_pred\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, n_y_pred).ravel()\n",
        "print(\"TN\", tn)\n",
        "print(\"FP\", fp)\n",
        "print(\"FN\", fn)\n",
        "print(\"TP\", tp)\n",
        "other = 100*tn/(tn+fp)\n",
        "pasto = 100*tp/(fn+tp)\n",
        "print(\"Other corretti: %.2f %%\" % other)\n",
        "print(\"Pasto corretti: %.2f %%\" % pasto)\n",
        "\"\"\""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Pj40Swm8_98K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@Description: PLOTTING\n",
        "'''\n",
        "'''\n",
        "plotting.plot_model_results(history)\n",
        "plotting.plot_co2_temp(flat_pred, val)\n",
        "'''"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5L-xXizgnw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.save('my_model1.h5')\n",
        "#model = load_model('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}