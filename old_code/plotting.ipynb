{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "plotting.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FG2511/ARE/blob/master/plotting.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "1Ilc-L-J-kUd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!mkdir -p local_modules/plotting"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DW-jHI8V5nUj",
        "colab_type": "code",
        "outputId": "d4155ccc-caca-421b-e15b-b82d783014a8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "cell_type": "code",
      "source": [
        "%%writefile local_modules/plotting/__init__.py\n",
        "\n",
        "import arff\n",
        "import csv\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import legend\n",
        "\n",
        "def plot_model_results(history):\n",
        "  # summarize history for accuracy\n",
        "  plt.plot(history.history['acc'])\n",
        "  plt.plot(history.history['val_acc'])\n",
        "  plt.title('model accuracy')\n",
        "  plt.ylabel('accuracy')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "\n",
        "  # summarize history for loss\n",
        "  plt.plot(history.history['loss'])\n",
        "  plt.plot(history.history['val_loss'])\n",
        "  plt.title('model loss')\n",
        "  plt.ylabel('loss')\n",
        "  plt.xlabel('epoch')\n",
        "  plt.legend(['train', 'test'], loc='upper left')\n",
        "  plt.show()\n",
        "  \n",
        "def plot_co2_temp(pred,val,post_pred):\n",
        "  \n",
        "  #LOAD SENSOR DATA\n",
        "  datasetSensor = '/root/data/uHooComplete_featureDataset_Reduced.arff'\n",
        "\n",
        "  with open (datasetSensor, encoding='utf-8') as fs:\n",
        "    dataSensor = arff.load(fs)\n",
        "\n",
        "  dataS = np.array(dataSensor['data'])\n",
        "\n",
        "  #CONVERTING VALUES\n",
        "  for i in dataS:\n",
        "    if(i[-1] == 'Other'): i[-1] = 0\n",
        "    else : i[-1] = 1\n",
        "\n",
        "  #TEST SENSOR DATA  \n",
        "  dataT = dataS[val+1:]\n",
        "\n",
        "  new_rows = []\n",
        "\n",
        "  for i,z,x in zip(dataT, pred, post_pred):\n",
        "    new_dict = {}\n",
        "    new_dict['Datetime'] = i[2]\n",
        "    new_dict['Temperature'] = i[0]\n",
        "    new_dict['CO2'] =  i[1]\n",
        "    new_dict['Actual'] = i[-1]\n",
        "    new_dict['Predicted'] = z\n",
        "    new_dict['Post_Predicted'] = x\n",
        "\n",
        "    new_rows.append(new_dict)\n",
        "\n",
        "\n",
        "  keys = new_rows[0].keys()\n",
        "\n",
        "\n",
        "  with open(\"/root/data/out.csv\", \"w\", newline='') as o:\n",
        "    w = csv.DictWriter(o, keys)\n",
        "    w.writeheader()\n",
        "    w.writerows(new_rows)\n",
        "    \n",
        "\n",
        "def plot_co2_temp_cross(pred, dimSplit, startIndex, finishIndex, i):\n",
        "  \n",
        "  #LOAD SENSOR DATA\n",
        "  datasetSensor = '/root/data/6_uHoo_featureDataset_Reduced.arff'\n",
        "\n",
        "  with open (datasetSensor, encoding='utf-8') as fs:\n",
        "    dataSensor = arff.load(fs)\n",
        "\n",
        "  dataS = np.array(dataSensor['data'])\n",
        "\n",
        "  #CONVERTING VALUES\n",
        "  for y in dataS:\n",
        "    if(y[-1] == 'Other'): y[-1] = 0\n",
        "    else : y[-1] = 1\n",
        "  \n",
        "  #TEST SENSOR DATA \n",
        "  dataT = dataS[startIndex:finishIndex, :]\n",
        "  startIndex = startIndex + dimSplit\n",
        "  finishIndex = dimSplit + finishIndex\n",
        "\n",
        "  new_rows = []\n",
        "\n",
        "  for i,z in zip(dataT, pred):\n",
        "    new_dict = {}\n",
        "    new_dict['Datetime'] = i[2]\n",
        "    new_dict['Temperature'] = i[0]\n",
        "    new_dict['CO2'] =  i[1]\n",
        "    new_dict['Actual'] = i[-1]\n",
        "    new_dict['Predicted'] = z\n",
        "\n",
        "    new_rows.append(new_dict)\n",
        "\n",
        "  keys = new_rows[0].keys()\n",
        "  \n",
        "  s = \"/root/data/out{}.csv\".format(i)\n",
        "\n",
        "  with open(s, \"w\", newline='') as o:\n",
        "    w = csv.DictWriter(o, keys)\n",
        "    w.writeheader()\n",
        "    w.writerows(new_rows)\n",
        "    \n",
        "    \n",
        "def plot_co2_temp_complete_dataset(pred,post_pred):\n",
        "  \n",
        "  #LOAD SENSOR DATA\n",
        "  datasetSensor = '/root/data/uHooComplete_featureDataset_Reduced.arff'\n",
        "\n",
        "  with open (datasetSensor, encoding='utf-8') as fs:\n",
        "    dataSensor = arff.load(fs)\n",
        "\n",
        "  dataS = np.array(dataSensor['data'])\n",
        "\n",
        "  #CONVERTING VALUES\n",
        "  for i in dataS:\n",
        "    if(i[-1] == 'Other'): i[-1] = 0\n",
        "    else : i[-1] = 1\n",
        "\n",
        "  new_rows = []\n",
        "\n",
        "  for i,z,x in zip(dataS, pred, post_pred):\n",
        "    new_dict = {}\n",
        "    new_dict['Datetime'] = i[2]\n",
        "    new_dict['Temperature'] = i[0]\n",
        "    new_dict['CO2'] =  i[1]\n",
        "    new_dict['Actual'] = i[-1]\n",
        "    new_dict['Predicted'] = z\n",
        "    new_dict['Post_Predicted'] = x\n",
        "\n",
        "    new_rows.append(new_dict)\n",
        "\n",
        "\n",
        "  keys = new_rows[0].keys()\n",
        "\n",
        "\n",
        "  with open(\"/root/data/out.csv\", \"w\", newline='') as o:\n",
        "    w = csv.DictWriter(o, keys)\n",
        "    w.writeheader()\n",
        "    w.writerows(new_rows)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Writing local_modules/plotting/__init__.py\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}
