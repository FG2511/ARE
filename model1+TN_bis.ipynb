{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1_final.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FG2511/ARE/blob/master/model1%2BTN_bis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hu-_5aP7LlL6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "23fdd6ee-e5e9-43fb-adc5-c9d4d8c638fa"
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@File name: model1.ipynb\n",
        "@Created on 2018-12-20\n",
        "@Authors: Federica Gerina, Francesca Moi, Silvia Maria Massa\n",
        "@Description: Given a time-series dataset that contains minute-by-minute data \n",
        "about different kind of gases, collected by the uHoo air quality sensor, train\n",
        "a NN that classifies if a minute belongs to the class \"Pasto\" (1) otherwise to\n",
        "the class \"Other\" (0).\n",
        "'''\n",
        "\n",
        "!pip install liac-arff\n",
        "\n",
        "import arff\n",
        "import numpy as np\n",
        "from keras import optimizers\n",
        "from keras.callbacks import EarlyStopping\n",
        "from sklearn.utils import compute_class_weight\n",
        "\n",
        "import sys\n",
        "sys.path.append('local_modules')\n",
        "\n",
        "import mlp\n",
        "import postprocessing_sw\n",
        "#import cooking_inst_mod\n",
        "import utils\n",
        "\n",
        "#fix random seed for reproducibility\n",
        "seed = 5\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (2.4.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o99ibbgGHANE",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 935
        },
        "outputId": "d624297b-b014-4533-cc57-f46b6be0d6b6"
      },
      "cell_type": "code",
      "source": [
        "#@title CHOOSE\n",
        "\n",
        "'''\n",
        "@Description: MAIN\n",
        "'''\n",
        "\n",
        "#LOAD DATA\n",
        "print(\"Loading data...\")\n",
        "\n",
        "dataset = '/root/data/uHooComplete_featureDataset_Past_Only.arff' #@param {type:\"string\"}\n",
        "\n",
        "with open (dataset, encoding='utf-8') as f:\n",
        "  dataDictionary = arff.load(f)\n",
        "\n",
        "data = np.array(dataDictionary['data'])\n",
        "print(\"DATASET LOADED\")\n",
        "\n",
        "#CONVERTING VALUES\n",
        "print(\"\\nConverting values...\")\n",
        "for i in data:\n",
        "  if(i[-1] == 'Other'): i[-1] = 0\n",
        "  elif(i[-1] == 'Pasto') : i[-1] = 1\n",
        "\n",
        "dataset = data.astype('float32')\n",
        "print(\"CONVERSION DONE\")\n",
        "\n",
        "#SPLIT INTO INPUT (X) AND OUTPUT (Y) VARIABLES\n",
        "s = dataset.shape[-1]\n",
        "\n",
        "X = dataset[:,0:s-1]\n",
        "Y = dataset[:,s-1]\n",
        "\n",
        "n_features = s-1\n",
        "\n",
        "#SPLIT INTO TRAINING, VALIDATION AND TEST SETS\n",
        "print(\"\\nSplit into training, validation and test sets...\")\n",
        "\n",
        "train_rate = 80\n",
        "val_rate = 10\n",
        "train = round(int((dataset.shape[0]*train_rate)/100))\n",
        "val = round(int((dataset.shape[0]*(train_rate+val_rate))/100))\n",
        "\n",
        "train_data = X[:train]\n",
        "train_label = Y[:train]\n",
        "\n",
        "val_data = X[train+1:val]\n",
        "val_label = Y[train+1:val]\n",
        "\n",
        "test_data = X[val+1:]\n",
        "test_label = Y[val+1:]\n",
        "print(\"DATASET SPLITTED\")\n",
        "\n",
        "#COMPUTE CLASS WEIGHT\n",
        "labels = np.unique(train_label)\n",
        "classWeight = compute_class_weight('balanced', labels, train_label)\n",
        "classWeight = dict(zip(labels,classWeight))\n",
        "\n",
        "#GENERATE MODEL\n",
        "print(\"\\nGenerate model...\")\n",
        "model = mlp.generate_model_leaky(train_data.shape[-1], n_features)\n",
        "\n",
        "#OPTIMIZERS\n",
        "adm = optimizers.Adam(lr=0.0001)\n",
        "\n",
        "#COMPILE MODEL\n",
        "print(\"\\nCompile model...\")\n",
        "model.compile(loss='binary_crossentropy', optimizer = adm , metrics=['accuracy'])\n",
        "\n",
        "#EARLY STOPPING\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
        "\n",
        "#FIT MODEL\n",
        "print(\"\\nFit model...\")\n",
        "history = model.fit(train_data, train_label, epochs=10, validation_data = (val_data, val_label), batch_size = 128, shuffle = True, class_weight = classWeight, verbose=1, callbacks = [es])\n",
        "\n",
        "#EVALUATE MODEL\n",
        "print(\"\\nEvaluate model...\")\n",
        "scores_test = model.evaluate(test_data, test_label, batch_size=128, verbose = 1)\n",
        "print(\"Test loss: %.2f%%\" % (scores_test[0] * 100))\n",
        "print(\"Test accuracy: %.2f%%\" % (scores_test[1] * 100))\n",
        "\n",
        "#CALCULATE PREDICTIONS\n",
        "print(\"\\nCalculate predictions...\")\n",
        "pred = model.predict_classes(test_data, batch_size=128, verbose=0)\n",
        "flat_pred = [item for sublist in pred for item in sublist]\n",
        "\n",
        "#CONFUSION MATRIX BEFORE POST PROCESSING\n",
        "print(\"\\n\\nCompute confusion matrix BEFORE POST PROCESSING...\")\n",
        "utils.compute_metrics(test_label, flat_pred)\n",
        "\n",
        "#STORE DATETIME\n",
        "time = []\n",
        "for i in test_data:\n",
        "  time.append(i[-5])"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "DATASET LOADED\n",
            "\n",
            "Converting values...\n",
            "CONVERSION DONE\n",
            "\n",
            "Split into training, validation and test sets...\n",
            "DATASET SPLITTED\n",
            "\n",
            "Generate model...\n",
            "\n",
            "Compile model...\n",
            "\n",
            "Fit model...\n",
            "Train on 280392 samples, validate on 35048 samples\n",
            "Epoch 1/10\n",
            "280392/280392 [==============================] - 12s 42us/step - loss: 0.6438 - acc: 0.6835 - val_loss: 0.7909 - val_acc: 0.4462\n",
            "Epoch 2/10\n",
            "280392/280392 [==============================] - 10s 37us/step - loss: 0.5483 - acc: 0.7411 - val_loss: 0.7575 - val_acc: 0.4492\n",
            "Epoch 3/10\n",
            "280392/280392 [==============================] - 9s 33us/step - loss: 0.5157 - acc: 0.7504 - val_loss: 0.7421 - val_acc: 0.4573\n",
            "Epoch 4/10\n",
            "280392/280392 [==============================] - 10s 35us/step - loss: 0.4995 - acc: 0.7529 - val_loss: 0.7047 - val_acc: 0.5406\n",
            "Epoch 5/10\n",
            "280392/280392 [==============================] - 10s 36us/step - loss: 0.4920 - acc: 0.7583 - val_loss: 0.7125 - val_acc: 0.5175\n",
            "Epoch 6/10\n",
            "280392/280392 [==============================] - 10s 36us/step - loss: 0.4812 - acc: 0.7615 - val_loss: 0.6844 - val_acc: 0.5631\n",
            "Epoch 7/10\n",
            "280392/280392 [==============================] - 10s 36us/step - loss: 0.4764 - acc: 0.7638 - val_loss: 0.6452 - val_acc: 0.6098\n",
            "Epoch 8/10\n",
            "280392/280392 [==============================] - 11s 37us/step - loss: 0.4735 - acc: 0.7647 - val_loss: 0.5971 - val_acc: 0.6495\n",
            "Epoch 9/10\n",
            "280392/280392 [==============================] - 10s 36us/step - loss: 0.4681 - acc: 0.7646 - val_loss: 0.5749 - val_acc: 0.6738\n",
            "Epoch 10/10\n",
            "280392/280392 [==============================] - 10s 34us/step - loss: 0.4637 - acc: 0.7676 - val_loss: 0.5495 - val_acc: 0.6861\n",
            "\n",
            "Evaluate model...\n",
            "35049/35049 [==============================] - 0s 9us/step\n",
            "Test loss: 58.58%\n",
            "Test accuracy: 68.10%\n",
            "\n",
            "Calculate predictions...\n",
            "\n",
            "\n",
            "Compute confusion matrix BEFORE POST PROCESSING...\n",
            "TN 22157\n",
            "FP 10824\n",
            "FN 356\n",
            "TP 1712\n",
            "ACCURACY: 68.10 %\n",
            "TRUE NEGATIVE RATE (SPECIFICITY): 67.18 %\n",
            "TRUE POSITIVE RATE (RECALL): 82.79 %\n",
            "PRECISION: 13.66 %\n",
            "F1 SCORE: 23.45 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "hdkk1t9J6oTb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "937501a6-9067-4c2d-903c-bbfe77f7496c"
      },
      "cell_type": "code",
      "source": [
        "#POST PROCESSING WITH SLIDING WINDOWS (MINUTE BY MINUTE)\n",
        "new_pred = postprocessing_sw.sliding_windows(flat_pred,35)\n",
        "\n",
        "#CONFUSION MATRIX AFTER POST PROCESSING\n",
        "print(\"\\n\\nCompute NEW confusion matrix AFTER POST PROCESSING...\")\n",
        "utils.compute_metrics(test_label, new_pred)\n"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "SLIDING WINDOWS FUNCTION...\n",
            "\n",
            "\n",
            "Compute NEW confusion matrix AFTER POST PROCESSING...\n",
            "TN 22431\n",
            "FP 10550\n",
            "FN 312\n",
            "TP 1756\n",
            "ACCURACY: 69.01 %\n",
            "TRUE NEGATIVE RATE (SPECIFICITY): 68.01 %\n",
            "TRUE POSITIVE RATE (RECALL): 84.91 %\n",
            "PRECISION: 14.27 %\n",
            "F1 SCORE: 24.43 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "zN3qfOeFxhK1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def get_precision_recall_f1(p, r): \n",
        "  index_pred = []\n",
        "  index_real = []\n",
        "\n",
        "  prediction_meals = []\n",
        "  real_meals = []\n",
        "\n",
        "  #p = flat_pred\n",
        "  #r = test_label\n",
        "\n",
        "  #COSTRUZIONE LISTE DI INDICI\n",
        "\n",
        "  #Una lista di pasti predetti e una di pasti reali\n",
        "\n",
        "  for i in range(0, len(p)-1):\n",
        "    if p[i] == 1:\n",
        "      index_pred.append(i)\n",
        "      if (p[i+1] == 0): \n",
        "        if(len(index_pred)>5):        \n",
        "          prediction_meals.append(index_pred)\n",
        "        index_pred = []\n",
        "    if r[i] == 1:\n",
        "      index_real.append(i)\n",
        "      if (r[i+1] == 0): \n",
        "        real_meals.append(index_real)\n",
        "        index_real = []\n",
        "\n",
        "  #Una lista di other predetti e una di other reali\n",
        "  prediction_others = []\n",
        "  real_others = []\n",
        "\n",
        "  index_pred = []\n",
        "  index_real = []\n",
        "\n",
        "  for i in range(0, len(p)):\n",
        "    if p[i] == 0:\n",
        "      index_pred.append(i)\n",
        "      if ((i+1) in range(0, len(p)) and p[i+1] == 1) or (i+1) not in range(0, len(p)): \n",
        "        prediction_others.append(index_pred)\n",
        "        index_pred = []\n",
        "    if r[i] == 0:\n",
        "      index_real.append(i)\n",
        "      if ((i+1) in range(0, len(p)) and r[i+1] == 1) or (i+1) not in range(0, len(p)): \n",
        "        real_others.append(index_real)\n",
        "        index_real = []\n",
        " \n",
        "  \n",
        "  \n",
        "  #Ricerca delle intersezioni, e quindi dei true positive e dei false positive\n",
        "\n",
        "  intersection = [] #contiene 1 se per un pasto reale j è stata già segnata un'intersezione \n",
        "  tp = 0\n",
        "  fp = 0\n",
        "\n",
        "  for i in range(0, len(real_meals)): #inizializzazione a 0 per l'array di intersezioni\n",
        "    intersection.append(0)\n",
        "\n",
        "  for i in range(0, len(real_meals)): #per ogni pasto predetto\n",
        "    flag_found = 0 #per tenere conto se l'intersezione è già stata trovata all'interno dei pasti reali\n",
        "    count_int = 0 #tiene conto del numero di intersezioni che un pasto predetto ha con i pasti reali (per il caso in cui un pasto pred intersechi due pasti reali)\n",
        "\n",
        "    for j in range(0, len(prediction_meals)):# per ogni pasto reale    \n",
        "      flag_visited = 0 #tiene conto se un pasto di prediction meals è già stato analizzato (per il caso in cui due pasti pred intersechino un unico pasto reale)\n",
        "\n",
        "      for x in real_meals[i]: #per ogni minuto di pasto controllo se esiste un'intersezione dentro real meals\n",
        "\n",
        "        if x in prediction_meals[j]: #se c'è l'intersezione        \n",
        "\n",
        "          if intersection[i]==0: #ciò significa che non è mai stata trovata un intersezione per il pasto reale j-esimo\n",
        "\n",
        "            if count_int == 0: #controlla che non siano ancora state trovate intersezioni  \n",
        "              count_int = count_int + 1\n",
        "              intersection[i] = 1\n",
        "              flag_visited = 1 #imposta il flag a uno per indicare che il pasto reale è stato già analizzato e per non contare più di una volta il tp trovato\n",
        "              flag_found = 1 #imposta il flag a uno per indicare che il pasto predetto è stato trovato nei pasti reali\n",
        "              tp=tp+1\n",
        "\n",
        "            elif count_int > 0: #caso in cui un pasto pred interseca due pasti reali e quindi un tp è già stato trovato in precedenza (produce un falso positivo e un vero positivo)           \n",
        "              intersection[i] = 1\n",
        "              flag_visited = 1 #imposta il flag a uno per indicare che il pasto reale è stato già analizzato e per non contare più di una volta il tp e il fp trovati\n",
        "              flag_found = 1            \n",
        "              fp=fp+1\n",
        "              tp=tp+1\n",
        "\n",
        "          elif flag_visited == 0: #caso in cui l'intersezione per il pasto reale j-esimo è già stata trovata ma tale pasto non è ancora stato analizzato con il pasto predetto i-esimo\n",
        "                                  #risolve il caso in cui più pasti pred intersecano un unico pasto reale\n",
        "            flag_found = 1\n",
        "            flag_visited = 1\n",
        "    #end for j\n",
        " \n",
        "    \n",
        "  #Ricerca falsi negativi\n",
        "\n",
        "  fn = 0\n",
        "\n",
        "  for i in range(0, len(real_meals)): #per ogni pasto reale\n",
        "    j=0\n",
        "    flag_found = 0\n",
        "    while j in range(0, len(prediction_meals)) and flag_found==0: # per ogni pasto predetto finchè non viene trovato tra questi l'intersezione con il pasto i-esimo\n",
        "\n",
        "      for x in real_meals[i]: #per ogni minuto di pasto controllo se esiste un'intersezione dentro prediction_meals\n",
        "\n",
        "        if x in prediction_meals[j]: #se c'è l'intersezione        \n",
        "          flag_found = 1 #imposta il flag a uno per indicare che il pasto reale è stato trovato nei pasti predetti\n",
        "\n",
        "      j = j + 1  \n",
        "    #end while j\n",
        "\n",
        "    if flag_found == 0: #se l'intersezione del pasto reale non è stata trovata nei pasti predetti siamo in corrispondenza di un falso negativo\n",
        "      fn=fn+1\n",
        "      \n",
        "      \n",
        "      \n",
        "  #Ricerca true negative\n",
        "  #A TN occurs when a predicted instance of ``other'' does not contain a actual ``cooking'' instance.\n",
        "  '''\n",
        "  tn=0\n",
        "  \n",
        "  for i in range(0, len(predicted_others)):\n",
        "    j=0\n",
        "    flag_found = 0\n",
        "    while j in range(0, len(real_meals)) and flag_found==0: \n",
        "      \n",
        "      for x in predicted_others[i]:\n",
        "        \n",
        "        if x in real_meals[j]:         \n",
        "          flag_found = 1\n",
        "\n",
        "      j = j + 1  \n",
        "\n",
        "    if flag_found == 0: \n",
        "      tn=tn+1\n",
        " \n",
        " '''\n",
        "  #Ricerca true negative\n",
        "  #A TN occurs when a actual instance of ``other'' does not contain a predicted ``cooking'' instance.\n",
        "  \n",
        "  tn=0\n",
        "  \n",
        "  for i in range(0, len(real_others)):\n",
        "    j=0\n",
        "    flag_found = 0\n",
        "    while j in range(0, len(prediction_meals)) and flag_found==0: \n",
        "      \n",
        "      for x in real_others[i]:\n",
        "        \n",
        "        if x in prediction_meals[j]:         \n",
        "          flag_found = 1\n",
        "\n",
        "      j = j + 1  \n",
        "\n",
        "    if flag_found == 0: \n",
        "      tn=tn+1\n",
        "      \n",
        "  #Ricerca falsi positivi\n",
        "  \n",
        "  for i in range(0, len(real_others)):\n",
        "    j=0\n",
        "    flag_found = 0\n",
        "    while j in range(0, len(prediction_meals)) and flag_found==0: \n",
        "\n",
        "      for x in real_others[i]:\n",
        "\n",
        "        if x in prediction_meals[j]:         \n",
        "          flag_found = 1\n",
        "\n",
        "      j = j + 1  \n",
        "\n",
        "    if flag_found == 1: \n",
        "      fp=fp+1\n",
        "      \n",
        "\n",
        "  print(\"N° pasti reali:\", len(real_meals))\n",
        "  print(\"N° other reali:\", len(real_others))\n",
        "  print(\"N° pasti predetti:\", len(prediction_meals))\n",
        "  print(\"N° other predetti:\", len(prediction_others))\n",
        "\n",
        "  print(\"TP:\", tp)\n",
        "  print(\"FP:\", fp)\n",
        "  print(\"FN:\", fn)\n",
        "  print(\"TN:\", tn)\n",
        "  \n",
        "\n",
        "  somma = tp+fp\n",
        "  precision = (tp/(tp+fp))*100\n",
        "  TPR = (tp/(tp+fn))*100\n",
        "  TNR = (tn/(tn+fp))*100\n",
        "  F1 = 2*((precision*TPR)/(precision+TPR))\n",
        "  acc = (tp+tn)/(tp+tn+fp+fn)*100\n",
        "  print(\"Recall: %.2f %%\" % TPR)\n",
        "  print(\"Specificity: %.2f %%\" % TNR)\n",
        "  print(\"Accuracy: %.2f %%\" % acc)\n",
        "  \n",
        "  print(\"Precision: %.2f %%\" % precision)\n",
        "  print(\"F1 score: %.2f %%\" % F1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EHk6Ho1b1ZiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 527
        },
        "outputId": "ab5ce329-c9f9-40ec-c9c3-418352824871"
      },
      "cell_type": "code",
      "source": [
        "#COOKING INSTANCE MODALITY\n",
        "\n",
        "#before post-processing\n",
        "print(\"\\nCOOKING INSTANCE MODALITY BEFORE POST PROCESSING\")\n",
        "#cooking_inst_mod.get_precision_recall_f1(flat_pred,test_label)\n",
        "get_precision_recall_f1(flat_pred,test_label)\n",
        "#after post-processing\n",
        "print(\"\\nCOOKING INSTANCE MODALITY AFTER POST PROCESSING\")\n",
        "#cooking_inst_mod.get_precision_recall_f1(new_pred,test_label)\n",
        "get_precision_recall_f1(new_pred,test_label)"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "COOKING INSTANCE MODALITY BEFORE POST PROCESSING\n",
            "N° pasti reali: 82\n",
            "N° other reali: 82\n",
            "N° pasti predetti: 296\n",
            "N° other predetti: 1130\n",
            "TP: 73\n",
            "FP: 80\n",
            "FN: 9\n",
            "TN: 2\n",
            "Recall: 89.02 %\n",
            "Specificity: 2.44 %\n",
            "Accuracy: 45.73 %\n",
            "Precision: 47.71 %\n",
            "F1 score: 62.13 %\n",
            "\n",
            "COOKING INSTANCE MODALITY AFTER POST PROCESSING\n",
            "N° pasti reali: 82\n",
            "N° other reali: 82\n",
            "N° pasti predetti: 133\n",
            "N° other predetti: 141\n",
            "TP: 71\n",
            "FP: 80\n",
            "FN: 11\n",
            "TN: 2\n",
            "Recall: 86.59 %\n",
            "Specificity: 2.44 %\n",
            "Accuracy: 44.51 %\n",
            "Precision: 47.02 %\n",
            "F1 score: 60.94 %\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}