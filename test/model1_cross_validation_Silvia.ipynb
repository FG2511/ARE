{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1_cross_validation.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FG2511/ARE/blob/master/model1_cross_validation_Silvia.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "5xC7KT-lYae2",
        "colab_type": "code",
        "outputId": "4afc1097-c1bf-42fe-dc31-6ba9af206f29",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 52
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@File name: model1.ipynb\n",
        "@Created on 2018-12-20\n",
        "@Authors: Federica Gerina, Francesca Moi, Silvia Maria Massa\n",
        "@Description: Given a time-series dataset that contains minute-by-minute data \n",
        "about different kind of gases, collected by the uHoo air quality sensor, train\n",
        "a NN that classifies if a minute belongs to the class \"Pasto\" (1) otherwise to\n",
        "the class \"Other\" (0).\n",
        "'''\n",
        "\n",
        "!pip install liac-arff\n",
        "\n",
        "import arff\n",
        "import csv\n",
        "\n",
        "import math\n",
        "\n",
        "'''Provides a high-performance multidimensional array object, \n",
        "and tools for working with these arrays'''\n",
        "import numpy as np\n",
        "'''Save an array to a text file.'''\n",
        "from numpy import savetxt\n",
        "\n",
        "'''Providing high-performance, easy-to-use data structures and data analysis tools'''\n",
        "import pandas as pd\n",
        "'''Two-dimensional size-mutable, \n",
        "potentially heterogeneous tabular data structure with labeled axes (rows and columns). \n",
        "Arithmetic operations align on both row and column labels.'''\n",
        "from pandas import DataFrame\n",
        "'''Read CSV file into DataFrame.\n",
        "Supports optionally iterating or breaking of the file into chunks.'''\n",
        "from pandas import read_csv\n",
        "'''Concatenate pandas objects along a particular axis with optional set logic along the other axes.\n",
        "Can also add a layer of hierarchical indexing on the concatenation axis, \n",
        "which may be useful if the labels are the same (or overlapping) on the passed axis number'''\n",
        "from pandas import concat\n",
        "\n",
        "from keras import optimizers\n",
        "'''Linear stack of layers.'''\n",
        "from keras.models import Sequential\n",
        "'''Loads a model saved via save_model.'''\n",
        "from keras.models import load_model\n",
        "'''Dense: just your regular densely-connected NN layer.\n",
        "Dropout: applies Dropout to the input.'''\n",
        "from keras.layers import Dense, Dropout, BatchNormalization,Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "from keras.preprocessing import sequence\n",
        "\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import legend\n",
        "\n",
        "# fix random seed for reproducibility\n",
        "seed = 7\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (2.3.1)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "HWFtL_iIYf25",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def generate_model(shape):\n",
        "  \n",
        "  model = Sequential()\n",
        " \n",
        "  '''model.add(Dense(113, input_dim=shape, kernel_initializer='random_uniform',  bias_initializer='zeros', activation='relu'))'''\n",
        "  model.add(Dense(113, input_dim=shape, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  '''model.add(Dense(229, kernel_initializer='random_uniform',  bias_initializer='zeros', activation='relu'))'''\n",
        "  model.add(Dense(229, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  '''model.add(Dense(153, kernel_initializer='random_uniform',  bias_initializer='zeros', activation='relu'))'''\n",
        "  model.add(Dense(153, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  \n",
        "  #print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "lUfQeqZVYk7H",
        "colab_type": "code",
        "outputId": "2f02d0c4-e814-43ff-8cdb-78dee324e95d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 87
        }
      },
      "cell_type": "code",
      "source": [
        "#LOAD DATA\n",
        "print(\"Loading data...\")\n",
        "\n",
        "dataset = '/root/data/6_uHoo_featureDataset.arff'\n",
        "\n",
        "with open (dataset, encoding='utf-8') as f:\n",
        "  dataDictionary = arff.load(f)\n",
        "\n",
        "data = np.array(dataDictionary['data'])\n",
        "print(\"DATASET LOADED\")\n",
        "\n",
        "#CONVERTING VALUES\n",
        "print(\"Converting values...\")\n",
        "for i in data:\n",
        "  if(i[-1] == 'Other'): i[-1] = 0\n",
        "  elif(i[-1] == 'Pasto') : i[-1] = 1\n",
        "\n",
        "dataset = data.astype('float32')\n",
        "print(\"CONVERSION DONE\")\n",
        "\n",
        "#SPLIT INTO INPUT (X) AND OUTPUT (Y) VARIABLES\n",
        "s = dataset.shape[-1]\n",
        "X = dataset[:,0:s-1]\n",
        "Y = dataset[:,s-1]"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "DATASET LOADED\n",
            "Converting values...\n",
            "CONVERSION DONE\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "fpBXmGFPYoHA",
        "colab_type": "code",
        "outputId": "f8173196-7688-4eb4-b02a-f82df74e0440",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 3590
        }
      },
      "cell_type": "code",
      "source": [
        "#OPTIMIZERS\n",
        "#sgd = optimizers.SGD(lr=0.0001)\n",
        "adm = optimizers.Adam(lr=0.0001)\n",
        "#ada = optimizers.Adadelta(lr=0.0001)\n",
        "#rms = optimizers.RMSprop(lr=0.001)\n",
        "\n",
        "#DEFINE 10-FOLD CROSS-VALIDATION\n",
        "kfold = KFold(n_splits=10, shuffle=False)\n",
        "cvscores = []\n",
        "predictions = []\n",
        "tpTot = []\n",
        "tnTot = []\n",
        "\n",
        "dimSplit = math.floor(len(dataset[:,0])/10)\n",
        "startIndex = 0\n",
        "finishIndex = dimSplit-1\n",
        "\n",
        "i = 1\n",
        "\n",
        "for train, test in kfold.split(X, Y):\n",
        "  print(\"\\nFOLD: %d\" %i)\n",
        "  \n",
        "  #COMPUTE CLASS WEIGHT\n",
        "  labels = np.unique(Y[train])\n",
        "  classWeight = compute_class_weight('balanced', labels, Y[train])\n",
        "  classWeight = dict(zip(labels,classWeight))\n",
        "  \n",
        "  #GENERATE MODEL\n",
        "  model = generate_model(X[train].shape[-1])\n",
        "\n",
        "  #COMPILE MODEL\n",
        "  model.compile(loss = 'binary_crossentropy', optimizer = adm , metrics=['accuracy'])\n",
        "  \n",
        "  #EARLY STOPPING\n",
        "  #es = EarlyStopping(monitor='val_acc', min_delta=0, patience=2, verbose=0, mode='auto')\n",
        "  \n",
        "  #FIT MODEL\n",
        "  history = model.fit(X[train], Y[train], epochs=4, batch_size = 128, shuffle = True, verbose=1, class_weight = classWeight) #callbacks = [es])\n",
        "\n",
        "  #EVALUATE MODEL\n",
        "  scores_test = model.evaluate(X[test], Y[test], batch_size= 128, verbose = 1)\n",
        "  print(\"Test loss: %.2f%%\" % (scores_test[0] * 100))\n",
        "  print(\"Test accuracy: %.2f%%\" % (scores_test[1] * 100))\n",
        "  \n",
        "  cvscores.append(scores_test[1] * 100)\n",
        "  \n",
        "  #CALCULATE PREDICTIONS AND SAVE IN A CSV FILE\n",
        "  pred = model.predict_classes(X[test], batch_size=128, verbose=1)\n",
        "  predictions.append([i,pred])\n",
        "  \n",
        "  #LOAD SENSORE DATA\n",
        "  datasetSensor = '/root/data/6_uHoo_featureDataset_Reduced.arff'\n",
        "\n",
        "  with open (datasetSensor, encoding='utf-8') as fs:\n",
        "    dataSensor = arff.load(fs)\n",
        "\n",
        "  dataS = np.array(dataSensor['data'])\n",
        "\n",
        "  #CONVERTING VALUES\n",
        "  for y in dataS:\n",
        "    if(y[-1] == 'Other'): y[-1] = 0\n",
        "    else : y[-1] = 1\n",
        "  \n",
        "  #TEST DATA SENSOR \n",
        "  dataT = dataS[startIndex:finishIndex, :]\n",
        "  startIndex = startIndex + dimSplit\n",
        "  finishIndex = dimSplit + finishIndex\n",
        "\n",
        "  new_rows = []\n",
        "\n",
        "  for x,j,z in zip(dataT, Y[test], pred):\n",
        "    new_dict = {}\n",
        "    new_dict['Temperature'] = x[0]\n",
        "    new_dict['CO2'] =  x[1]\n",
        "    new_dict['Actual'] = j\n",
        "    new_dict['Predicted'] = z\n",
        "\n",
        "    new_rows.append(new_dict)\n",
        "\n",
        "  keys = new_rows[0].keys()\n",
        "  \n",
        "  s = \"/root/data/out{}.csv\".format(i)\n",
        "\n",
        "  with open(s, \"w\", newline='') as o:\n",
        "    w = csv.DictWriter(o, keys)\n",
        "    w.writeheader()\n",
        "    w.writerows(new_rows)\n",
        " \n",
        "  #CONFUSION MATRIX\n",
        "  y_true = Y[test]\n",
        "  y_pred = pred\n",
        "  tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "  print(\"TN\", tn)\n",
        "  print(\"FP\", fp)\n",
        "  print(\"FN\", fn)\n",
        "  print(\"TP\", tp)\n",
        "  other = 100*tn/(tn+fp)\n",
        "  pasto = 100*tp/(fn+tp)\n",
        "  print(\"Other corretti: %.2f %%\" % other)\n",
        "  print(\"Pasto corretti: %.2f %%\" % pasto)\n",
        "  \n",
        "  tpTot.append(pasto)\n",
        "  tnTot.append(other)\n",
        "  \n",
        "  i = i+1\n",
        "\n",
        "print(\"MEAN ACCURACY: %.2f%% (STANDARD DEVIATION: +/- %.2f%%)\" % (np.mean(cvscores), np.std(cvscores)))\n",
        "print(\"MEAN TP: %.2f%% (STANDARD DEVIATION: +/- %.2f%%)\" % (np.mean(tpTot), np.std(tpTot)))\n",
        "print(\"MEAN TN: %.2f%% (STANDARD DEVIATION: +/- %.2f%%)\" % (np.mean(tnTot), np.std(tnTot)))\n"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "FOLD: 1\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 13s 61us/step - loss: 0.4296 - acc: 0.7830\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 12s 58us/step - loss: 0.3591 - acc: 0.8215\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 12s 59us/step - loss: 0.3329 - acc: 0.8342\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 12s 57us/step - loss: 0.3112 - acc: 0.8469\n",
            "22993/22993 [==============================] - 1s 22us/step\n",
            "Test loss: 25.47%\n",
            "Test accuracy: 89.58%\n",
            "22993/22993 [==============================] - 0s 21us/step\n",
            "TN 19990\n",
            "FP 1896\n",
            "FN 499\n",
            "TP 608\n",
            "Other corretti: 91.34 %\n",
            "Pasto corretti: 54.92 %\n",
            "\n",
            "FOLD: 2\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 14s 68us/step - loss: 0.4153 - acc: 0.7885\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 13s 62us/step - loss: 0.3512 - acc: 0.8229\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 12s 58us/step - loss: 0.3285 - acc: 0.8352\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 13s 61us/step - loss: 0.3133 - acc: 0.8447\n",
            "22993/22993 [==============================] - 1s 26us/step\n",
            "Test loss: 40.17%\n",
            "Test accuracy: 79.21%\n",
            "22993/22993 [==============================] - 1s 24us/step\n",
            "TN 17476\n",
            "FP 4619\n",
            "FN 161\n",
            "TP 737\n",
            "Other corretti: 79.09 %\n",
            "Pasto corretti: 82.07 %\n",
            "\n",
            "FOLD: 3\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 13s 64us/step - loss: 0.4192 - acc: 0.7830\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 12s 59us/step - loss: 0.3567 - acc: 0.8192\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 12s 60us/step - loss: 0.3341 - acc: 0.8311\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 12s 60us/step - loss: 0.3188 - acc: 0.8411\n",
            "22993/22993 [==============================] - 1s 29us/step\n",
            "Test loss: 32.52%\n",
            "Test accuracy: 85.60%\n",
            "22993/22993 [==============================] - 1s 27us/step\n",
            "TN 18566\n",
            "FP 2838\n",
            "FN 472\n",
            "TP 1117\n",
            "Other corretti: 86.74 %\n",
            "Pasto corretti: 70.30 %\n",
            "\n",
            "FOLD: 4\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 14s 69us/step - loss: 0.4206 - acc: 0.7801\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 13s 62us/step - loss: 0.3567 - acc: 0.8205\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 12s 59us/step - loss: 0.3318 - acc: 0.8315\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 12s 59us/step - loss: 0.3187 - acc: 0.8388\n",
            "22993/22993 [==============================] - 1s 31us/step\n",
            "Test loss: 32.82%\n",
            "Test accuracy: 83.58%\n",
            "22993/22993 [==============================] - 1s 30us/step\n",
            "TN 18134\n",
            "FP 3497\n",
            "FN 278\n",
            "TP 1084\n",
            "Other corretti: 83.83 %\n",
            "Pasto corretti: 79.59 %\n",
            "\n",
            "FOLD: 5\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 14s 67us/step - loss: 0.4260 - acc: 0.7746\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 13s 60us/step - loss: 0.3586 - acc: 0.8133\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 12s 60us/step - loss: 0.3340 - acc: 0.8285\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 12s 58us/step - loss: 0.3182 - acc: 0.8378\n",
            "22993/22993 [==============================] - 1s 35us/step\n",
            "Test loss: 29.25%\n",
            "Test accuracy: 86.87%\n",
            "22993/22993 [==============================] - 1s 33us/step\n",
            "TN 19211\n",
            "FP 2746\n",
            "FN 273\n",
            "TP 763\n",
            "Other corretti: 87.49 %\n",
            "Pasto corretti: 73.65 %\n",
            "\n",
            "FOLD: 6\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 14s 66us/step - loss: 0.4177 - acc: 0.7800\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 12s 60us/step - loss: 0.3590 - acc: 0.8150\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 12s 60us/step - loss: 0.3353 - acc: 0.8282\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 13s 62us/step - loss: 0.3225 - acc: 0.8340\n",
            "22993/22993 [==============================] - 1s 39us/step\n",
            "Test loss: 35.88%\n",
            "Test accuracy: 81.34%\n",
            "22993/22993 [==============================] - 1s 37us/step\n",
            "TN 18380\n",
            "FP 4190\n",
            "FN 100\n",
            "TP 323\n",
            "Other corretti: 81.44 %\n",
            "Pasto corretti: 76.36 %\n",
            "\n",
            "FOLD: 7\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 14s 67us/step - loss: 0.4214 - acc: 0.7742\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 12s 60us/step - loss: 0.3610 - acc: 0.8133\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 13s 65us/step - loss: 0.3364 - acc: 0.8270\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 12s 60us/step - loss: 0.3215 - acc: 0.8366\n",
            "22993/22993 [==============================] - 1s 41us/step\n",
            "Test loss: 46.63%\n",
            "Test accuracy: 75.72%\n",
            "22993/22993 [==============================] - 1s 38us/step\n",
            "TN 16692\n",
            "FP 5426\n",
            "FN 157\n",
            "TP 718\n",
            "Other corretti: 75.47 %\n",
            "Pasto corretti: 82.06 %\n",
            "\n",
            "FOLD: 8\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 15s 74us/step - loss: 0.4261 - acc: 0.7803\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 14s 66us/step - loss: 0.3600 - acc: 0.8147\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 13s 61us/step - loss: 0.3351 - acc: 0.8299\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 13s 61us/step - loss: 0.3227 - acc: 0.8382\n",
            "22993/22993 [==============================] - 1s 43us/step\n",
            "Test loss: 35.80%\n",
            "Test accuracy: 83.27%\n",
            "22993/22993 [==============================] - 1s 41us/step\n",
            "TN 18176\n",
            "FP 3612\n",
            "FN 234\n",
            "TP 971\n",
            "Other corretti: 83.42 %\n",
            "Pasto corretti: 80.58 %\n",
            "\n",
            "FOLD: 9\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 14s 69us/step - loss: 0.4267 - acc: 0.7735\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 13s 62us/step - loss: 0.3627 - acc: 0.8123\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 13s 61us/step - loss: 0.3378 - acc: 0.8278\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 12s 60us/step - loss: 0.3211 - acc: 0.8363\n",
            "22993/22993 [==============================] - 2s 84us/step\n",
            "Test loss: 34.35%\n",
            "Test accuracy: 82.92%\n",
            "22993/22993 [==============================] - 2s 93us/step\n",
            "TN 18137\n",
            "FP 3644\n",
            "FN 284\n",
            "TP 928\n",
            "Other corretti: 83.27 %\n",
            "Pasto corretti: 76.57 %\n",
            "\n",
            "FOLD: 10\n",
            "Epoch 1/4\n",
            "206937/206937 [==============================] - 15s 73us/step - loss: 0.4058 - acc: 0.7937\n",
            "Epoch 2/4\n",
            "206937/206937 [==============================] - 13s 63us/step - loss: 0.3444 - acc: 0.8267\n",
            "Epoch 3/4\n",
            "206937/206937 [==============================] - 13s 65us/step - loss: 0.3255 - acc: 0.8370\n",
            "Epoch 4/4\n",
            "206937/206937 [==============================] - 13s 62us/step - loss: 0.3088 - acc: 0.8463\n",
            "22993/22993 [==============================] - 1s 50us/step\n",
            "Test loss: 31.24%\n",
            "Test accuracy: 85.42%\n",
            "22993/22993 [==============================] - 1s 47us/step\n",
            "TN 19377\n",
            "FP 2808\n",
            "FN 544\n",
            "TP 264\n",
            "Other corretti: 87.34 %\n",
            "Pasto corretti: 32.67 %\n",
            "MEAN ACCURACY: 83.35% (STANDARD DEVIATION: +/- 3.75%)\n",
            "MEAN TP: 70.88% (STANDARD DEVIATION: +/- 14.85%)\n",
            "MEAN TN: 83.94% (STANDARD DEVIATION: +/- 4.35%)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "gAdSdADmUm5S",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "3_vL2BWwjIgo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.save('my_model1_cv.h5')\n",
        "\n",
        "#model = load_model('my_model1_cv.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
