{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "model1.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/FG2511/ARE/blob/master/model1_provePostProcessing_Franci.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "hu-_5aP7LlL6",
        "colab_type": "code",
        "outputId": "30656989-2a19-4e2f-8a40-aa64c990e977",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        }
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@File name: model1.ipynb\n",
        "@Created on 2018-12-20\n",
        "@Authors: Federica Gerina, Francesca Moi, Silvia Maria Massa\n",
        "@Description: Given a time-series dataset that contains minute-by-minute data \n",
        "about different kind of gases, collected by the uHoo air quality sensor, train\n",
        "a NN that classifies if a minute belongs to the class \"Pasto\" (1) otherwise to\n",
        "the class \"Other\" (0).\n",
        "'''\n",
        "\n",
        "!pip install liac-arff\n",
        "\n",
        "import arff\n",
        "import numpy as np\n",
        "\n",
        "from keras import optimizers\n",
        "from keras.models import Sequential\n",
        "from keras.models import load_model\n",
        "from keras.layers import Dense, Dropout, LeakyReLU, BatchNormalization, Activation\n",
        "from keras.callbacks import EarlyStopping\n",
        "\n",
        "from sklearn.utils import compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix\n",
        "\n",
        "import sys\n",
        "sys.path.append('local_modules')\n",
        "\n",
        "import postprocessing_sliding\n",
        "#import postprocessing_Silvia\n",
        "#import plotting"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: liac-arff in /usr/local/lib/python3.6/dist-packages (2.4.0)\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "metadata": {
        "id": "DJ0SubdGw6LA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#fix random seed for reproducibility\n",
        "seed = 5\n",
        "np.random.seed(seed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "yKvmDiR9NgBO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@Description: generate a multilayer perceptron with LeakyRelu as activation\n",
        "function.\n",
        "@param: \n",
        "  - shape : int, the shape of the input\n",
        "  - n_features: int, the number of features given\n",
        "'''\n",
        "\n",
        "#MODELLO 1\n",
        "#REGOLA: input/2, input, 2*input, 1\n",
        "#layers TUTTE LE FEATURE: 57, 113, 226, 1 \n",
        "#layers TIME CO2 TEMP: 21, 41, 82, 1 \n",
        "#layers TIME CO2 TEMP PM25/TVOC: 30, 59, 118, 1 \n",
        "#layers TIME CO2 TEMP PM25 TVOC: 39, 77, 154, 1 \n",
        "\n",
        "\n",
        "def generate_model_leaky(shape, n_features):\n",
        "\n",
        "  units_1 = int(n_features/2)\n",
        "  units_2 = n_features\n",
        "  units_3 = n_features*2\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(BatchNormalization())\n",
        "  \n",
        "  model.add(Dense(units_1, input_dim=shape, kernel_initializer='random_uniform',  use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha = 0.2))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(units_2, kernel_initializer='random_uniform',  use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha = 0.2))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(units_3, kernel_initializer='random_uniform',  use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(LeakyReLU(alpha = 0.2))\n",
        "  model.add(Dropout(0.5))\n",
        "  \n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  #print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GNvDfgeB13JC",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@Description: generate a multilayer perceptron with Relu as activation\n",
        "function.\n",
        "@param: \n",
        "  - shape : int, the shape of the input\n",
        "  - n_features: int, the number of features given\n",
        "'''\n",
        "\n",
        "#MODELLO 2\n",
        "#REGOLA: a= input, b= a*2/3+c, c= b*2/3+1\n",
        "#layers TUTTE LE FEATURE: 113, 229, 153, 1\n",
        "#layers TIME CO2 TEMP: 41, 85, 57, 1 \n",
        "#layers TIME CO2 TEMP PM25/TVOC: 59, 121, 81, 1 \n",
        "#layers TIME CO2 TEMP PM25 TVOC: 77, 157, 105, 1 \n",
        "\n",
        "def generate_model(shape, n_features):\n",
        "  \n",
        "  a = np.array([[1,0,0],[-(2/3),1,-1],[0,-(2/3),1]])\n",
        "  b = np.array([n_features,0,1])\n",
        "  x = np.linalg.solve(a, b)\n",
        "\n",
        "  units_1 = int(x[0])\n",
        "  units_2 = int(x[1])\n",
        "  units_3 = int(x[2])\n",
        "\n",
        "  model = Sequential()\n",
        " \n",
        "  model.add(Dense(units_1, input_dim=shape, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  model.add(Dense(units_2, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  model.add(Dense(units_3, kernel_initializer='random_uniform', use_bias = False))\n",
        "  model.add(BatchNormalization())\n",
        "  model.add(Activation('relu'))\n",
        "  model.add(Dropout(0,5))\n",
        "  \n",
        "  model.add(Dense(1, activation='sigmoid'))\n",
        "  #print(model.summary())\n",
        "\n",
        "  return model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "o99ibbgGHANE",
        "outputId": "08fb261a-e294-4211-bc2c-8dd907e6860d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 810
        }
      },
      "cell_type": "code",
      "source": [
        "#@title SCEGLI IL DATASET E IL MODELLO\n",
        "\n",
        "'''\n",
        "@Description: MAIN\n",
        "'''\n",
        "\n",
        "#LOAD DATA\n",
        "print(\"Loading data...\")\n",
        "\n",
        "dataset = '/root/data/6_uHoo_featureDataset.arff' #@param {type:\"string\"}\n",
        "\n",
        "with open (dataset, encoding='utf-8') as f:\n",
        "  dataDictionary = arff.load(f)\n",
        "\n",
        "data = np.array(dataDictionary['data'])\n",
        "print(\"DATASET LOADED\")\n",
        "\n",
        "#CONVERTING VALUES\n",
        "print(\"\\nConverting values...\")\n",
        "for i in data:\n",
        "  if(i[-1] == 'Other'): i[-1] = 0\n",
        "  elif(i[-1] == 'Pasto') : i[-1] = 1\n",
        "\n",
        "dataset = data.astype('float32')\n",
        "print(\"CONVERSION DONE\")\n",
        "\n",
        "#SPLIT INTO INPUT (X) AND OUTPUT (Y) VARIABLES\n",
        "s = dataset.shape[-1]\n",
        "#print(s)\n",
        "X = dataset[:,0:s-1]\n",
        "Y = dataset[:,s-1]\n",
        "\n",
        "#print(s-1)\n",
        "\n",
        "n_features = s-1\n",
        "\n",
        "#SPLIT INTO TRAINING, VALIDATION AND TEST SETS\n",
        "print(\"\\nSplit into training, validation and test sets...\")\n",
        "\n",
        "train_rate = 80\n",
        "val_rate = 10\n",
        "train = round(int((dataset.shape[0]*train_rate)/100))\n",
        "val = round(int((dataset.shape[0]*(train_rate+val_rate))/100))\n",
        "\n",
        "train_data = X[:train]\n",
        "train_label = Y[:train]\n",
        "\n",
        "val_data = X[train+1:val]\n",
        "val_label = Y[train+1:val]\n",
        "\n",
        "test_data = X[val+1:]\n",
        "test_label = Y[val+1:]\n",
        "print(\"DATASET SPLITTED\")\n",
        "\n",
        "#COMPUTE CLASS WEIGHT\n",
        "labels = np.unique(train_label)\n",
        "classWeight = compute_class_weight('balanced', labels, train_label)\n",
        "classWeight = dict(zip(labels,classWeight))\n",
        "\n",
        "#GENERATE MODEL\n",
        "print(\"\\nGenerate model...\")\n",
        "\n",
        "modello = 1 #@param {type:\"integer\"}\n",
        "\n",
        "if modello==1 :\n",
        "  model = generate_model_leaky(train_data.shape[-1], n_features)\n",
        "elif modello==2:\n",
        "  model = generate_model(train_data.shape[-1], n_features)\n",
        "\n",
        "#OPTIMIZERS\n",
        "adm = optimizers.Adam(lr=0.0001)\n",
        "\n",
        "#COMPILE MODEL\n",
        "print(\"\\nCompile model...\")\n",
        "model.compile(loss='binary_crossentropy', optimizer = adm , metrics=['accuracy'])\n",
        "\n",
        "#EARLY STOPPING\n",
        "es = EarlyStopping(monitor='val_loss', min_delta=0, patience=2, verbose=0, mode='auto')\n",
        "\n",
        "#FIT MODEL\n",
        "print(\"\\nFit model...\")\n",
        "history = model.fit(train_data, train_label, epochs=20, validation_data = (val_data, val_label), batch_size = 128, shuffle = True, class_weight = classWeight, verbose=1, callbacks = [es])\n",
        "\n",
        "#EVALUATE MODEL\n",
        "print(\"\\nEvaluate model...\")\n",
        "scores_test = model.evaluate(test_data, test_label, batch_size=128, verbose = 1)\n",
        "print(\"Test loss: %.2f%%\" % (scores_test[0] * 100))\n",
        "print(\"Test accuracy: %.2f%%\" % (scores_test[1] * 100))\n",
        "\n",
        "#CALCULATE PREDICTIONS\n",
        "print(\"\\nCalculate predictions...\")\n",
        "pred = model.predict_classes(test_data, batch_size=128, verbose=0)\n",
        "flat_pred = [item for sublist in pred for item in sublist]\n",
        "\n",
        "#CONFUSION MATRIX\n",
        "print(\"\\nCompute confusion matrix...\")\n",
        "y_true = test_label\n",
        "y_pred = pred\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, y_pred).ravel()\n",
        "print(\"TN\", tn)\n",
        "print(\"FP\", fp)\n",
        "print(\"FN\", fn)\n",
        "print(\"TP\", tp)\n",
        "other = 100*tn/(tn+fp)\n",
        "pasto = 100*tp/(fn+tp)\n",
        "print(\"Other corretti: %.2f %%\" % other)\n",
        "print(\"Pasto corretti: %.2f %%\" % pasto)"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading data...\n",
            "DATASET LOADED\n",
            "\n",
            "Converting values...\n",
            "CONVERSION DONE\n",
            "\n",
            "Split into training, validation and test sets...\n",
            "DATASET SPLITTED\n",
            "\n",
            "Generate model...\n",
            "\n",
            "Compile model...\n",
            "\n",
            "Fit model...\n",
            "Train on 183944 samples, validate on 22992 samples\n",
            "Epoch 1/20\n",
            "183944/183944 [==============================] - 13s 68us/step - loss: 0.5441 - acc: 0.7484 - val_loss: 0.3478 - val_acc: 0.8911\n",
            "Epoch 2/20\n",
            "183944/183944 [==============================] - 11s 60us/step - loss: 0.4249 - acc: 0.8312 - val_loss: 0.2893 - val_acc: 0.8826\n",
            "Epoch 3/20\n",
            "183944/183944 [==============================] - 11s 60us/step - loss: 0.3861 - acc: 0.8375 - val_loss: 0.2682 - val_acc: 0.8738\n",
            "Epoch 4/20\n",
            "183944/183944 [==============================] - 11s 61us/step - loss: 0.3636 - acc: 0.8390 - val_loss: 0.2391 - val_acc: 0.8837\n",
            "Epoch 5/20\n",
            "183944/183944 [==============================] - 11s 59us/step - loss: 0.3526 - acc: 0.8394 - val_loss: 0.2372 - val_acc: 0.8785\n",
            "Epoch 6/20\n",
            "183944/183944 [==============================] - 11s 60us/step - loss: 0.3452 - acc: 0.8400 - val_loss: 0.2253 - val_acc: 0.8839\n",
            "Epoch 7/20\n",
            "183944/183944 [==============================] - 12s 63us/step - loss: 0.3414 - acc: 0.8379 - val_loss: 0.2681 - val_acc: 0.8550\n",
            "Epoch 8/20\n",
            "183944/183944 [==============================] - 11s 61us/step - loss: 0.3356 - acc: 0.8357 - val_loss: 0.2342 - val_acc: 0.8745\n",
            "\n",
            "Evaluate model...\n",
            "22992/22992 [==============================] - 0s 18us/step\n",
            "Test loss: 31.96%\n",
            "Test accuracy: 85.65%\n",
            "\n",
            "Calculate predictions...\n",
            "\n",
            "Compute confusion matrix...\n",
            "TN 19392\n",
            "FP 2799\n",
            "FN 501\n",
            "TP 300\n",
            "Other corretti: 87.39 %\n",
            "Pasto corretti: 37.45 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "ivXVv6yGJBqx",
        "colab_type": "code",
        "outputId": "f5974df4-7882-4606-cbf7-29500745cf31",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        }
      },
      "cell_type": "code",
      "source": [
        "#@title SCEGLI maxWidth\n",
        "'''\n",
        "@Description: POST PROCESSING\n",
        "'''\n",
        "\n",
        "maxWidth = 3 #@param {type:\"integer\"}\n",
        "\n",
        "new_pred = postprocessing_sliding.sliding_windows(flat_pred)\n",
        "#new_pred = postprocessing_Silvia.setWidth(maxWidth,flat_pred)\n",
        "\n",
        "#CONFUSION MATRIX\n",
        "print(\"\\nCompute NEW confusion matrix...\")\n",
        "y_true = test_label\n",
        "n_y_pred = new_pred\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, n_y_pred).ravel()\n",
        "print(\"TN\", tn)\n",
        "print(\"FP\", fp)\n",
        "print(\"FN\", fn)\n",
        "print(\"TP\", tp)\n",
        "other = 100*tn/(tn+fp)\n",
        "pasto = 100*tp/(fn+tp)\n",
        "print(\"Other corretti: %.2f %%\" % other)\n",
        "print(\"Pasto corretti: %.2f %%\" % pasto)"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AFTER FIRST SW\n",
            "\n",
            "Compute NEW confusion matrix...\n",
            "TN 19394\n",
            "FP 2797\n",
            "FN 498\n",
            "TP 303\n",
            "Other corretti: 87.40 %\n",
            "Pasto corretti: 37.83 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "4-XsF45J4rcU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "time=[]\n",
        "for i in test_data:\n",
        "  time.append(i[-5])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "k_PUny7Pq241",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "c2e7868b-6c54-40c1-de31-b94a984d3ec2"
      },
      "cell_type": "code",
      "source": [
        "#Correzione degli other tra mezzanotte e le 5:00\n",
        "new_pred2 = new_pred\n",
        "i = 0 \n",
        "while i < len(new_pred2):\n",
        "  if time[i]<=330 or 1020<=time[i]<1080:\n",
        "    new_pred2[i] = 0\n",
        "  i = i+1\n",
        "\n",
        "#CONFUSION MATRIX\n",
        "print(\"\\nCompute NEW confusion matrix...\")\n",
        "y_true = test_label\n",
        "n_y_pred = new_pred2\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, n_y_pred).ravel()\n",
        "print(\"TN\", tn)\n",
        "print(\"FP\", fp)\n",
        "print(\"FN\", fn)\n",
        "print(\"TP\", tp)\n",
        "other = 100*tn/(tn+fp)\n",
        "pasto = 100*tp/(fn+tp)\n",
        "print(\"Other corretti: %.2f %%\" % other)\n",
        "print(\"Pasto corretti: %.2f %%\" % pasto)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AFTER other bla bla\n",
            "\n",
            "Compute NEW confusion matrix...\n",
            "TN 19527\n",
            "FP 2664\n",
            "FN 498\n",
            "TP 303\n",
            "Other corretti: 88.00 %\n",
            "Pasto corretti: 37.83 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MB54pKKq9CkY",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 168
        },
        "outputId": "9986fbf0-1a93-47ec-d1ac-554fbf238dc9"
      },
      "cell_type": "code",
      "source": [
        "import more_itertools\n",
        "\n",
        "pasto = list(more_itertools.windowed(new_pred2, n=31, step=1))\n",
        "time_pasto = list(more_itertools.windowed(time, n=31, step=1))\n",
        "lista = (pasto,time_pasto)\n",
        "\n",
        "result = []\n",
        "result = result + new_pred2[0:15]\n",
        "\n",
        "i = 0\n",
        "\n",
        "while i < len(lista[0]):\n",
        "  \n",
        "  if (lista[1][i][0]>=660 and lista[1][i][30]<1020) or (lista[1][i][0]>=1080 and lista[1][i][30]<1439):\n",
        "\n",
        "    count = 0\n",
        "    z = 0  \n",
        "    \n",
        "    while z < len(lista[0][i]): \n",
        "      if lista[0][i][z] == 1 :\n",
        "        count = count + 1\n",
        "      z = z + 1\n",
        "\n",
        "    if count > 17:\n",
        "      result.append(1)\n",
        "    else:\n",
        "      result.append(0)\n",
        "      \n",
        "  else:\n",
        "    result.append(lista[0][i][15])\n",
        "           \n",
        "  i = i+1\n",
        "  \n",
        "result = result + new_pred2[len(new_pred2)-15:]\n",
        "\n",
        "#CONFUSION MATRIX\n",
        "print(\"\\nCompute NEW confusion matrix...\")\n",
        "y_true = test_label\n",
        "n_y_pred = result\n",
        "tn, fp, fn, tp = confusion_matrix(y_true, n_y_pred).ravel()\n",
        "print(\"TN\", tn)\n",
        "print(\"FP\", fp)\n",
        "print(\"FN\", fn)\n",
        "print(\"TP\", tp)\n",
        "other = 100*tn/(tn+fp)\n",
        "pasto = 100*tp/(fn+tp)\n",
        "print(\"Other corretti: %.2f %%\" % other)\n",
        "print(\"Pasto corretti: %.2f %%\" % pasto)\n"
      ],
      "execution_count": 61,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total\n",
            "\n",
            "Compute NEW confusion matrix...\n",
            "TN 19741\n",
            "FP 2450\n",
            "FN 513\n",
            "TP 288\n",
            "Other corretti: 88.96 %\n",
            "Pasto corretti: 35.96 %\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "Pj40Swm8_98K",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "'''\n",
        "@Description: PLOTTING\n",
        "'''\n",
        "\n",
        "plotting.plot_model_results(history)\n",
        "plotting.plot_co2_temp(flat_pred, val)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "C5L-xXizgnw5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#model.save('my_model1.h5')\n",
        "#model = load_model('my_model.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}
